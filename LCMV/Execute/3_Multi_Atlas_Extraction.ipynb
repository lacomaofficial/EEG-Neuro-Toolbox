{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55f28313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "from tqdm import tqdm\n",
    "import os, time, pickle\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from nilearn import datasets, image\n",
    "\n",
    "# Set MNE to only show warnings and errors\n",
    "mne.set_log_level('warning')\n",
    "\n",
    "class LCMVSourceEstimator:\n",
    "    def __init__(self, config):\n",
    "        \"\"\"\n",
    "        Initialize the LCMV Source Estimator with configuration.\n",
    "        \n",
    "        Parameters:\n",
    "        config (dict): Configuration dictionary containing all necessary parameters\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "        self.project_base = Path(config['project_base'])\n",
    "        self.subject_id = config['subject_id']\n",
    "        self.task = config['task']\n",
    "        \n",
    "        # GLOBAL directory for shared resources (fsaverage)\n",
    "        self.global_subjects_dir = self.project_base / 'derivatives/lcmv'\n",
    "        \n",
    "        # SUBJECT-SPECIFIC directory for output\n",
    "        self.subject_output = self.project_base / f'derivatives/lcmv/{self.subject_id}_{self.task}'\n",
    "        self.subject_output.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    def parse_gpsc(self, filepath):\n",
    "        \"\"\"Parse .gpsc file and normalize coordinates to center the origin.\"\"\"\n",
    "        channels = []\n",
    "        with open(filepath, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "        for line in lines:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) < 4:\n",
    "                continue\n",
    "            name = parts[0]\n",
    "            try:\n",
    "                x, y, z = map(float, parts[1:4])\n",
    "                channels.append((name, x, y, z))\n",
    "            except ValueError:\n",
    "                continue\n",
    "        return channels\n",
    "\n",
    "    def run_enhanced_computation(self):\n",
    "        \"\"\"Run the complete enhanced LCMV pipeline with improved coregistration\"\"\"\n",
    "        print(\"=\"*60)\n",
    "        print(f\"🎯 ENHANCED LCMV SOURCE ESTIMATION - Subject: {self.subject_id}\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        print(\"\\n=== Loading Data ===\")\n",
    "        ica_file = self.project_base / self.config['ica_file_path']\n",
    "        gpsc_file = self.project_base / self.config['gpsc_file_path']\n",
    "\n",
    "        if not ica_file.exists():\n",
    "            raise FileNotFoundError(f\"ICA file not found: {ica_file}\")\n",
    "        if not gpsc_file.exists():\n",
    "            raise FileNotFoundError(f\"GPSC file not found: {gpsc_file}\")\n",
    "\n",
    "        # Load data\n",
    "        raw = mne.io.read_raw_fif(ica_file, preload=True)\n",
    "        sfreq = raw.info['sfreq']\n",
    "        duration_min = raw.n_times / sfreq / 60\n",
    "        print(f\"Data: {duration_min:.1f}min, {sfreq}Hz, {raw.n_times} samples\")\n",
    "\n",
    "        # === ENHANCED PREPROCESSING PIPELINE ===\n",
    "        print(\"\\n=== Enhanced Preprocessing Pipeline ===\")\n",
    "        \n",
    "        # Rename channels to match .gpsc file\n",
    "        channel_map = {str(i): f'E{i}' for i in range(1, 281)}\n",
    "        channel_map['REF CZ'] = 'Cz'\n",
    "        \n",
    "        # Only rename existing channels\n",
    "        existing_channels = set(raw.info['ch_names'])\n",
    "        valid_channel_map = {}\n",
    "        for old_name, new_name in channel_map.items():\n",
    "            if old_name in existing_channels:\n",
    "                valid_channel_map[old_name] = new_name\n",
    "        \n",
    "        if valid_channel_map:\n",
    "            raw.rename_channels(valid_channel_map)\n",
    "            print(f\"Renamed {len(valid_channel_map)} channels\")\n",
    "        \n",
    "  \n",
    "\n",
    "        # === ENHANCED MONTAGE CREATION ===\n",
    "        print(\"\\n=== Creating Enhanced Montage with Coordinate Normalization ===\")\n",
    "        \n",
    "        # Parse .gpsc file\n",
    "        channels = self.parse_gpsc(gpsc_file)\n",
    "        \n",
    "        if not channels:\n",
    "            raise ValueError(\"No valid channels found in .gpsc file\")\n",
    "        \n",
    "        # Normalize coordinates to center the origin (enhanced method)\n",
    "        gpsc_array = np.array([ch[1:4] for ch in channels])\n",
    "        mean_pos = np.mean(gpsc_array, axis=0)\n",
    "        print(f\"Original mean position (mm): {mean_pos}\")\n",
    "        \n",
    "        # Normalize and convert to meters\n",
    "        channels_normalized = [(ch[0], ch[1] - mean_pos[0], ch[2] - mean_pos[1], ch[3] - mean_pos[2]) \n",
    "                              for ch in channels]\n",
    "        ch_pos = {ch[0]: np.array(ch[1:4]) / 1000.0 for ch in channels_normalized}\n",
    "        \n",
    "        # Check fiducials\n",
    "        required_fids = ['FidNz', 'FidT9', 'FidT10']\n",
    "        missing = [fid for fid in required_fids if fid not in ch_pos]\n",
    "        if missing:\n",
    "            raise ValueError(f\"Missing fiducials: {missing}\")\n",
    "\n",
    "        # Create montage with normalized coordinates\n",
    "        montage = mne.channels.make_dig_montage(\n",
    "            ch_pos=ch_pos,\n",
    "            nasion=ch_pos['FidNz'],\n",
    "            lpa=ch_pos['FidT9'],\n",
    "            rpa=ch_pos['FidT10'],\n",
    "            coord_frame='head'\n",
    "        )\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        # Apply montage and preprocessing\n",
    "        raw.set_montage(montage, on_missing='warn')\n",
    "        raw = raw.pick(['eeg', 'stim'], exclude=raw.info['bads'])\n",
    "\n",
    "        print(\"\\n🔍 Checking EEG reference status...\")\n",
    "        print(f\"custom_ref_applied: {raw.info['custom_ref_applied']}\")\n",
    "        print(f\"n_projs: {len(raw.info['projs'])}\")\n",
    "        print(f\"proj_applied: {raw.proj}\")\n",
    "\n",
    "        # --- Ensure average reference projection is present ---\n",
    "        if not any(p['desc'] == 'average' for p in raw.info['projs']):\n",
    "            print(\"📎 No average reference projection found. Applying it...\")\n",
    "            raw.set_eeg_reference('average', projection=True)\n",
    "        else:\n",
    "            print(\"✅ Average reference projection already in place.\")\n",
    "\n",
    "        # --- Apply projections if not already applied ---\n",
    "        if not raw.proj:\n",
    "            print(\"🎯 Applying EEG average reference projection...\")\n",
    "            raw.apply_proj()\n",
    "        else:\n",
    "            print(\"💡 Projections already applied.\")\n",
    "\n",
    "        print(\"✓ Enhanced preprocessing complete (reference now valid for inverse modeling)\")\n",
    "\n",
    "        print(f\"Enhanced montage applied:\")\n",
    "        print(f\"FidNz (nasion): {ch_pos['FidNz']}\")\n",
    "        print(f\"FidT9 (lpa): {ch_pos['FidT9']}\")\n",
    "        print(f\"FidT10 (rpa): {ch_pos['FidT10']}\")\n",
    "\n",
    "        # === SOURCE SPACE SETUP ===\n",
    "        print(\"\\n=== Source Space Setup ===\")\n",
    "        subject = 'fsaverage'\n",
    "\n",
    "        # Download fsaverage if needed\n",
    "        bem_file = self.global_subjects_dir / 'fsaverage' / 'bem' / 'fsaverage-5120-5120-5120-bem-sol.fif'\n",
    "        bem_head = self.global_subjects_dir / 'fsaverage' / 'bem' / 'fsaverage-head-dense.fif'\n",
    "        src_file = self.global_subjects_dir / 'fsaverage-vol-5mm-src.fif'\n",
    "\n",
    "        if not bem_file.exists() or not bem_head.exists():\n",
    "            print(\"Downloading fsaverage to GLOBAL directory...\")\n",
    "            mne.datasets.fetch_fsaverage(subjects_dir=self.global_subjects_dir, verbose=False)\n",
    "\n",
    "        # === ENHANCED COREGISTRATION ===\n",
    "        print(\"\\n=== Running Enhanced Coregistration ===\")\n",
    "        trans_file = self.subject_output / 'fsaverage-trans.fif'\n",
    "\n",
    "        try:\n",
    "            # Initialize coregistration with normalized coordinates\n",
    "            coreg = mne.coreg.Coregistration(\n",
    "                raw.info,\n",
    "                subject=subject,\n",
    "                subjects_dir=self.global_subjects_dir,\n",
    "                fiducials={\n",
    "                    'nasion': ch_pos['FidNz'],\n",
    "                    'lpa': ch_pos['FidT9'],\n",
    "                    'rpa': ch_pos['FidT10']\n",
    "                }\n",
    "            )\n",
    "\n",
    "            # Step 1: Fit with fiducials first\n",
    "            print(\"1/3: Fitting with fiducials...\")\n",
    "            coreg.fit_fiducials(verbose=False)\n",
    "\n",
    "            # Step 2: Use EEG channels as head shape points for ICP\n",
    "            print(\"2/3: Using EEG channels as head shape points for ICP...\")\n",
    "            coreg.fit_icp(n_iterations=6, nasion_weight=2.0, verbose=False)\n",
    "            \n",
    "            # Remove outliers\n",
    "            print(\"   Removing outlier points...\")\n",
    "            dists = coreg.compute_dig_mri_distances()\n",
    "            n_excluded = np.sum(dists > 5.0/1000)\n",
    "            \n",
    "            if n_excluded > 0:\n",
    "                print(f\"   Excluding {n_excluded} outlier points (distance > 5mm)\")\n",
    "                coreg.omit_head_shape_points(distance=5.0/1000)\n",
    "            else:\n",
    "                print(\"   No outlier points to exclude\")\n",
    "                \n",
    "            # Step 3: Final refinement with higher weight on nasion\n",
    "            print(\"3/3: Final ICP refinement...\")\n",
    "            coreg.fit_icp(n_iterations=20, nasion_weight=10.0, verbose=False)\n",
    "\n",
    "            # Save transformation\n",
    "            trans = coreg.trans\n",
    "            mne.write_trans(trans_file, trans, overwrite=True)\n",
    "            print(f\"✓ Enhanced coregistration successful: {trans_file}\")\n",
    "\n",
    "            # Compute and display error metrics\n",
    "            dists = coreg.compute_dig_mri_distances() * 1000  # mm\n",
    "            mean_err = np.mean(dists)\n",
    "            median_err = np.median(dists)\n",
    "            max_err = np.max(dists)\n",
    "            \n",
    "            print(f\"\\nCoregistration Error (mm):\")\n",
    "            print(f\"Mean: {mean_err:.2f}, Median: {median_err:.2f}, Max: {max_err:.2f}\")\n",
    "\n",
    "            if mean_err > 5.0:\n",
    "                print(f\"⚠️  WARNING: Mean error = {mean_err:.2f}mm > 5mm\")\n",
    "            else:\n",
    "                print(\"✅ Enhanced coregistration error acceptable\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Enhanced coregistration failed: {e}\")\n",
    "            print(\"Using identity transformation as fallback\")\n",
    "            trans = mne.Transform('head', 'mri', np.eye(4))\n",
    "            mne.write_trans(trans_file, trans, overwrite=True)\n",
    "\n",
    "        # === SOURCE SPACE CREATION ===\n",
    "        print(\"\\n=== Creating Source Space ===\")\n",
    "        if not src_file.exists():\n",
    "            print(\"Creating volume source space...\")\n",
    "            src = mne.setup_volume_source_space(\n",
    "                subject, subjects_dir=self.global_subjects_dir, pos=5.0, add_interpolator=True\n",
    "            )\n",
    "            src.save(src_file, overwrite=True)\n",
    "        else:\n",
    "            src = mne.read_source_spaces(src_file)\n",
    "\n",
    "        print(f\"Source space: {len(src[0]['vertno'])} active sources out of {src[0]['np']} total points\")\n",
    "\n",
    "        # === FORWARD SOLUTION ===\n",
    "        print(\"\\n=== Creating Forward Solution ===\")\n",
    "        fwd_file = self.subject_output / 'fsaverage-vol-eeg-fwd.fif'\n",
    "        bem = mne.read_bem_solution(bem_file)\n",
    "        fwd = mne.make_forward_solution(\n",
    "            raw.info, trans=trans, src=src, bem=bem, eeg=True, mindist=5.0, n_jobs=self.config['n_jobs']\n",
    "        )\n",
    "        mne.write_forward_solution(fwd_file, fwd, overwrite=True)\n",
    "        print(\"✓ Enhanced source space setup complete\")\n",
    "\n",
    "        # === LCMV BEAMFORMER ===\n",
    "        print(\"\\n=== LCMV Beamformer ===\")\n",
    "\n",
    "        # Compute SINGLE covariance from entire recording (CORRECT FOR CONTINUOUS DATA)\n",
    "        print(\"Computing single covariance from entire recording...\")\n",
    "\n",
    "        cov = mne.compute_raw_covariance(\n",
    "        raw,\n",
    "        method='oas',             # ✅ STATE-OF-THE-ART for long continuous data 'shrunk' or 'oas'\n",
    "        picks='eeg',\n",
    "        rank='info',              # ✅ CRITICAL: Accounts for average reference\n",
    "        n_jobs=self.config['n_jobs'],\n",
    "        verbose=False)\n",
    "\n",
    "\n",
    "\n",
    "        # Create LCMV filters: Same covariance with proper rank handling\n",
    "        print(\"Creating LCMV spatial filters...\")\n",
    "        filters = mne.beamformer.make_lcmv(\n",
    "            info=raw.info, \n",
    "            forward=fwd, \n",
    "            data_cov=cov, \n",
    "            noise_cov=cov,  # Same matrix - correct for continuous data\n",
    "            reg=self.config['reg'],\n",
    "            pick_ori='max-power', \n",
    "            weight_norm='unit-noise-gain', \n",
    "            reduce_rank=True,    # Must be True for average reference\n",
    "            rank='info',         # CORRECT: Use rank information from info object\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "\n",
    "        \n",
    "        # Apply LCMV to continuous data\n",
    "        print(\"Applying LCMV filters to continuous data...\")\n",
    "        stc = mne.beamformer.apply_lcmv_raw(raw=raw, filters=filters)\n",
    "        \n",
    "        # Save STC in H5 format (required for complex data)\n",
    "        print(\"Saving STC in H5 format (required for complex data)...\")\n",
    "        stc_file = self.subject_output / 'source_estimate_LCMV.h5'\n",
    "        stc.save(stc_file, ftype='h5', overwrite=True)\n",
    "        print(f\"✓ STC saved successfully in H5 format: {stc_file}\")\n",
    "\n",
    "        print(f\"✓ LCMV complete: {stc.data.shape} (sources x timepoints)\")\n",
    "        print(f\"✓ STC file saved as: {stc_file}\")\n",
    "\n",
    "        # === SAVE SOURCE SPACE INFORMATION ===\n",
    "        print(\"\\n=== Saving source space information ===\")\n",
    "        \n",
    "        # For volume source spaces, stc.vertices[0] contains the indices of active sources\n",
    "        vertices = stc.vertices[0]\n",
    "        \n",
    "        # Get the active source indices from the source space\n",
    "        active_indices = src[0]['vertno']  # indices of active sources in the full grid\n",
    "        \n",
    "\n",
    "        # Map STC vertices to actual source space positions\n",
    "        # For volume source spaces, stc.vertices are indices into src[0]['vertno']\n",
    "        try:\n",
    "            src_points_m = src[0]['rr'][src[0]['vertno'][vertices]]  # Correct indexing\n",
    "        except IndexError:\n",
    "            print(\"Warning: Indexing failed, falling back to direct indexing\")\n",
    "            src_points_m = src[0]['rr'][vertices]\n",
    "        \n",
    "        src_points_mm = src_points_m * 1000  # Convert to mm\n",
    "        \n",
    "        # Save the correctly indexed source points\n",
    "        np.save(self.subject_output / 'source_space_points_mm.npy', src_points_mm)\n",
    "        \n",
    "        # Verify shapes match\n",
    "        print(f\"STC data shape: {stc.data.shape}\")\n",
    "        print(f\"Source points shape: {src_points_mm.shape}\")\n",
    "        \n",
    "        if src_points_mm.shape[0] != stc.data.shape[0]:\n",
    "            print(f\"WARNING: Shape mismatch detected!\")\n",
    "            n_sources = min(src_points_mm.shape[0], stc.data.shape[0])\n",
    "            src_points_mm = src_points_mm[:n_sources]\n",
    "            print(f\"Using first {n_sources} source points to match STC data\")\n",
    "        \n",
    "        print(f\"✓ Source space points saved: {src_points_mm.shape} points\")\n",
    "        print(f\"   Matches STC data shape: {stc.data.shape[0]} sources\")\n",
    "\n",
    "        # === SAVE DEBUG INFO AND METADATA ===\n",
    "        print(\"\\n=== Saving debug info and metadata ===\")\n",
    "        \n",
    "        # Save debugging info\n",
    "        debug_info = {\n",
    "            'src_vertno': active_indices.tolist(),\n",
    "            'stc_vertices': vertices.tolist(),\n",
    "            'src_np': src[0]['np'],\n",
    "            'n_active_sources': len(active_indices),\n",
    "            'n_stc_vertices': len(vertices),\n",
    "            'coregistration_error_mm': {\n",
    "                'mean': mean_err if 'mean_err' in locals() else None,\n",
    "                'median': median_err if 'median_err' in locals() else None,\n",
    "                'max': max_err if 'max_err' in locals() else None\n",
    "            }\n",
    "        }\n",
    "        with open(self.subject_output / 'debug_source_info.pkl', 'wb') as f:\n",
    "            pickle.dump(debug_info, f)\n",
    "\n",
    "        # Save metadata\n",
    "        metadata = {\n",
    "            'stc_shape': stc.data.shape,\n",
    "            'n_source_points': len(vertices),\n",
    "            'source_space_indices': vertices.tolist(),\n",
    "            'sfreq': sfreq,\n",
    "            'duration_min': duration_min,\n",
    "            'stc_file': str(stc_file),\n",
    "            'src_file': str(src_file),\n",
    "            'subject_output': str(self.subject_output),\n",
    "            'global_subjects_dir': str(self.global_subjects_dir),\n",
    "            'enhanced_coregistration': True,\n",
    "            'coordinate_normalization': 'mean_centered',\n",
    "            'fiducials': {\n",
    "                'FidNz': ch_pos['FidNz'].tolist(),\n",
    "                'FidT9': ch_pos['FidT9'].tolist(),\n",
    "                'FidT10': ch_pos['FidT10'].tolist()\n",
    "            }\n",
    "        }\n",
    "        with open(self.subject_output / 'computation_metadata.pkl', 'wb') as f:\n",
    "            pickle.dump(metadata, f)\n",
    "        \n",
    "        print(f\"✓ Enhanced computation complete and metadata saved\")\n",
    "        print(f\"\\n🎉 ENHANCED LCMV SOURCE ESTIMATION COMPLETE!\")\n",
    "        print(f\"   - Enhanced coregistration with error checking\")\n",
    "        print(f\"   - Proper coordinate normalization\")\n",
    "        print(f\"   - All original outputs maintained\")\n",
    "        print(f\"   - Results saved to: {self.subject_output}\")\n",
    "        \n",
    "        return metadata\n",
    "\n",
    "    def extract_difumo_time_courses(self, stc, src, config, subject_output):\n",
    "        \"\"\"Extract weighted time courses from DiFuMo atlas.\"\"\"\n",
    "        print(\"\\n=== DiFuMo Processing ===\")\n",
    "        atlas = datasets.fetch_atlas_difumo(\n",
    "            dimension=config['dimension'],\n",
    "            resolution_mm=config['resolution_mm']\n",
    "        )\n",
    "        atlas_img = nib.load(atlas.maps)\n",
    "        atlas_shape = atlas_img.shape  # (x, y, z, n_components)\n",
    "        n_components = atlas_shape[3]\n",
    "\n",
    "        # Get source locations in mm\n",
    "        vertices = stc.vertices[0]\n",
    "        src_rr = src[0]['rr'][vertices] * 1000  # m → mm\n",
    "\n",
    "        # Apply MRI RAS transform to get MNI coordinates\n",
    "        try:\n",
    "            trans = src[0]['mri_ras_t']['trans']\n",
    "        except KeyError:\n",
    "            raise ValueError(\"Source space missing 'mri_ras_t' transform. Ensure it's a proper volume source space.\")\n",
    "\n",
    "        mni_coords = image.coord_transform(src_rr[:, 0], src_rr[:, 1], src_rr[:, 2], trans)\n",
    "        src_coords_mni = np.array(mni_coords).T  # (n_sources, 3)\n",
    "\n",
    "        # Convert MNI mm → voxel indices in atlas space\n",
    "        homog = np.column_stack([src_coords_mni, np.ones(len(src_coords_mni))])\n",
    "        vox_coords = (np.linalg.inv(atlas_img.affine) @ homog.T).T[:, :3]\n",
    "        vox_coords = np.round(vox_coords).astype(int)\n",
    "\n",
    "        # Filter valid voxels inside atlas bounds\n",
    "        valid_mask = (\n",
    "            (vox_coords >= 0).all(axis=1) &\n",
    "            (vox_coords[:, 0] < atlas_shape[0]) &\n",
    "            (vox_coords[:, 1] < atlas_shape[1]) &\n",
    "            (vox_coords[:, 2] < atlas_shape[2])\n",
    "        )\n",
    "        valid_indices = np.where(valid_mask)[0]\n",
    "        valid_voxels = vox_coords[valid_mask]\n",
    "\n",
    "        print(f\"Using {len(valid_indices)}/{len(vertices)} sources within atlas bounds\")\n",
    "\n",
    "        # Extract time courses\n",
    "        time_courses = []\n",
    "        component_info = []\n",
    "        threshold = 1e-6\n",
    "\n",
    "        for comp_idx in range(n_components):\n",
    "            if comp_idx % 100 == 0:\n",
    "                print(f\"Processing component {comp_idx + 1}/{n_components}\")\n",
    "\n",
    "            try:\n",
    "                comp_map = atlas_img.slicer[..., comp_idx].get_fdata()\n",
    "                weights, stc_indices = [], []\n",
    "\n",
    "                for i, (x, y, z) in enumerate(valid_voxels):\n",
    "                    prob = comp_map[x, y, z]\n",
    "                    if prob > threshold:\n",
    "                        weights.append(prob)\n",
    "                        stc_indices.append(valid_indices[i])\n",
    "\n",
    "                if weights:\n",
    "                    weights = np.array(weights)\n",
    "                    weights /= weights.sum()  # Normalize\n",
    "                    tc = np.average(stc.data[stc_indices], axis=0, weights=weights)\n",
    "                    info = {\n",
    "                        'component': comp_idx,\n",
    "                        'n_sources': len(stc_indices),\n",
    "                        'max_weight': weights.max(),\n",
    "                        'mean_weight': weights.mean()\n",
    "                    }\n",
    "                else:\n",
    "                    tc = np.zeros(stc.data.shape[1])\n",
    "                    info = {\n",
    "                        'component': comp_idx,\n",
    "                        'n_sources': 0,\n",
    "                        'max_weight': 0.0,\n",
    "                        'mean_weight': 0.0\n",
    "                    }\n",
    "\n",
    "                time_courses.append(tc)\n",
    "                component_info.append(info)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error in component {comp_idx}: {e}\")\n",
    "                time_courses.append(np.zeros(stc.data.shape[1]))\n",
    "                component_info.append({\n",
    "                    'component': comp_idx, 'n_sources': 0, 'max_weight': 0.0, 'mean_weight': 0.0\n",
    "                })\n",
    "\n",
    "        # Summary\n",
    "        valid_comps = sum(1 for info in component_info if info['n_sources'] > 0)\n",
    "        print(f\"✅ {valid_comps}/{n_components} components have at least one source\")\n",
    "\n",
    "        # Save outputs\n",
    "        subject_output = Path(subject_output)\n",
    "        np.save(subject_output / 'difumo_time_courses.npy', np.array(time_courses))\n",
    "        pd.DataFrame(component_info).to_csv(subject_output / 'difumo_component_info.csv', index=False)\n",
    "        print(f\"💾 Saved to: {subject_output}\")\n",
    "\n",
    "        return np.array(time_courses), component_info\n",
    "\n",
    "    def run_difumo_extraction(self, difumo_config=None):\n",
    "        \"\"\"Run DiFuMo time course extraction on existing data.\"\"\"\n",
    "        if difumo_config is None:\n",
    "            difumo_config = {\n",
    "                'dimension': 512,\n",
    "                'resolution_mm': 2  # 2mm resolution for 512-component DiFuMo\n",
    "            }\n",
    "\n",
    "        try:\n",
    "            # --- Set paths ---\n",
    "            subject_output = self.subject_output\n",
    "            stc_base_name = \"source_estimate_LCMV\"  # without extension\n",
    "\n",
    "            # --- AUTODETECT STC FILE (handles .stc, -vl.stc, .h5) ---\n",
    "            stc_file = None\n",
    "            for suffix in ['-vl.stc', '.stc', '.h5']:\n",
    "                candidate = subject_output / f\"{stc_base_name}{suffix}\"\n",
    "                if candidate.exists():\n",
    "                    stc_file = candidate\n",
    "                    break\n",
    "            if not stc_file:\n",
    "                raise FileNotFoundError(f\"STC file not found in {subject_output}\")\n",
    "\n",
    "            # --- LOAD DATA ---\n",
    "            print(f\"🔁 Loading STC: {stc_file}\")\n",
    "            stc = mne.read_source_estimate(stc_file)\n",
    "            print(f\"Loaded STC: {stc.data.shape} (sources × time)\")\n",
    "\n",
    "            # ✅ CORRECTED: Load source space from GLOBAL directory (not subject folder)\n",
    "            src_file = self.global_subjects_dir / \"fsaverage-vol-5mm-src.fif\"\n",
    "\n",
    "            print(f\"🔁 Loading source space: {src_file}\")\n",
    "            if not src_file.exists():\n",
    "                raise FileNotFoundError(f\"Source space not found: {src_file}\")\n",
    "            src = mne.read_source_spaces(src_file)\n",
    "            print(f\"Loaded source space with {len(src[0]['vertno'])} active sources\")\n",
    "            \n",
    "            # --- RUN EXTRACTION ---\n",
    "            time_courses, component_info = self.extract_difumo_time_courses(\n",
    "                stc=stc,\n",
    "                src=src,\n",
    "                config=difumo_config,\n",
    "                subject_output=subject_output\n",
    "            )\n",
    "\n",
    "            print(\"\\n🎉 SUCCESS: DiFuMo time series extraction complete!\")\n",
    "            print(f\"📊 Output shape: {time_courses.shape} (512 components × {time_courses.shape[1]} time points)\")\n",
    "            print(f\"📄 Details saved in:\\n   - {subject_output / 'difumo_time_courses.npy'}\\n   - {subject_output / 'difumo_component_info.csv'}\")\n",
    "\n",
    "            return time_courses, component_info\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error during DiFuMo extraction: {e}\")\n",
    "            raise\n",
    "\n",
    "        \n",
    "    def list_output_files(self):\n",
    "        \"\"\"List all files in the output folder.\"\"\"\n",
    "        print(f\"\\n=== Files in output folder: {self.subject_output} ===\")\n",
    "        for file in os.listdir(self.subject_output):\n",
    "            print(file)\n",
    "        return list(os.listdir(self.subject_output))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "323e43b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Found 12 subjects for DiFuMo extraction.\n",
      "\n",
      "================================================================================\n",
      "🧠 STARTING DIFUMO TIME SERIES EXTRACTION (512 components, 2mm)\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting DiFuMo ROIs:   0%|          | 0/12 [00:00<?, ?subject/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Loading STC: /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-01_bima_full_off/source_estimate_LCMV.h5\n",
      "Loaded STC: (13222, 215473) (sources × time)\n",
      "🔁 Loading source space: /home/jaizor/jaizor/xtra/derivatives/lcmv/fsaverage-vol-5mm-src.fif\n",
      "Loaded source space with 24303 active sources\n",
      "\n",
      "=== DiFuMo Processing ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">fetch_atlas_difumo</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span> Dataset found in <span style=\"color: #800080; text-decoration-color: #800080\">/home/jaizor/nilearn_data/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">difumo_atlases</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34m[\u001b[0m\u001b[34mfetch_atlas_difumo\u001b[0m\u001b[1;34m]\u001b[0m Dataset found in \u001b[35m/home/jaizor/nilearn_data/\u001b[0m\u001b[95mdifumo_atlases\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 13222/13222 sources within atlas bounds\n",
      "Processing component 1/512\n",
      "Processing component 101/512\n",
      "Processing component 201/512\n",
      "Processing component 301/512\n",
      "Processing component 401/512\n",
      "Processing component 501/512\n",
      "✅ 505/512 components have at least one source\n",
      "💾 Saved to: /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-01_bima_full_off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting DiFuMo ROIs:   8%|▊         | 1/12 [06:06<1:07:07, 366.18s/subject]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎉 SUCCESS: DiFuMo time series extraction complete!\n",
      "📊 Output shape: (512, 215473) (512 components × 215473 time points)\n",
      "📄 Details saved in:\n",
      "   - /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-01_bima_full_off/difumo_time_courses.npy\n",
      "   - /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-01_bima_full_off/difumo_component_info.csv\n",
      "\n",
      "=== Files in output folder: /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-01_bima_full_off ===\n",
      "fsaverage-trans.fif\n",
      "source_estimate_LCMV.h5\n",
      "debug_source_info.pkl\n",
      "source_space_points_mm.npy\n",
      "difumo_component_info.csv\n",
      "difumo_time_courses.npy\n",
      "computation_metadata.pkl\n",
      "fsaverage-vol-eeg-fwd.fif\n",
      "✅ DIFUMO SUCCESS: sub-01_bima_full_off.fif\n",
      "🔁 Loading STC: /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-02_bima_full_off/source_estimate_LCMV.h5\n",
      "Loaded STC: (13222, 248466) (sources × time)\n",
      "🔁 Loading source space: /home/jaizor/jaizor/xtra/derivatives/lcmv/fsaverage-vol-5mm-src.fif\n",
      "Loaded source space with 24303 active sources\n",
      "\n",
      "=== DiFuMo Processing ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">fetch_atlas_difumo</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span> Dataset found in <span style=\"color: #800080; text-decoration-color: #800080\">/home/jaizor/nilearn_data/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">difumo_atlases</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34m[\u001b[0m\u001b[34mfetch_atlas_difumo\u001b[0m\u001b[1;34m]\u001b[0m Dataset found in \u001b[35m/home/jaizor/nilearn_data/\u001b[0m\u001b[95mdifumo_atlases\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 13222/13222 sources within atlas bounds\n",
      "Processing component 1/512\n",
      "Processing component 101/512\n",
      "Processing component 201/512\n",
      "Processing component 301/512\n",
      "Processing component 401/512\n",
      "Processing component 501/512\n",
      "✅ 505/512 components have at least one source\n",
      "💾 Saved to: /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-02_bima_full_off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting DiFuMo ROIs:  17%|█▋        | 2/12 [12:16<1:01:24, 368.45s/subject]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎉 SUCCESS: DiFuMo time series extraction complete!\n",
      "📊 Output shape: (512, 248466) (512 components × 248466 time points)\n",
      "📄 Details saved in:\n",
      "   - /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-02_bima_full_off/difumo_time_courses.npy\n",
      "   - /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-02_bima_full_off/difumo_component_info.csv\n",
      "\n",
      "=== Files in output folder: /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-02_bima_full_off ===\n",
      "fsaverage-trans.fif\n",
      "source_estimate_LCMV.h5\n",
      "debug_source_info.pkl\n",
      "source_space_points_mm.npy\n",
      "difumo_component_info.csv\n",
      "difumo_time_courses.npy\n",
      "computation_metadata.pkl\n",
      "fsaverage-vol-eeg-fwd.fif\n",
      "✅ DIFUMO SUCCESS: sub-02_bima_full_off.fif\n",
      "🔁 Loading STC: /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-03_bima_full_off/source_estimate_LCMV.h5\n",
      "Loaded STC: (13222, 126537) (sources × time)\n",
      "🔁 Loading source space: /home/jaizor/jaizor/xtra/derivatives/lcmv/fsaverage-vol-5mm-src.fif\n",
      "Loaded source space with 24303 active sources\n",
      "\n",
      "=== DiFuMo Processing ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">fetch_atlas_difumo</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span> Dataset found in <span style=\"color: #800080; text-decoration-color: #800080\">/home/jaizor/nilearn_data/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">difumo_atlases</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34m[\u001b[0m\u001b[34mfetch_atlas_difumo\u001b[0m\u001b[1;34m]\u001b[0m Dataset found in \u001b[35m/home/jaizor/nilearn_data/\u001b[0m\u001b[95mdifumo_atlases\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 13222/13222 sources within atlas bounds\n",
      "Processing component 1/512\n",
      "Processing component 101/512\n",
      "Processing component 201/512\n",
      "Processing component 301/512\n",
      "Processing component 401/512\n",
      "Processing component 501/512\n",
      "✅ 505/512 components have at least one source\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting DiFuMo ROIs:  25%|██▌       | 3/12 [18:07<54:04, 360.51s/subject]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saved to: /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-03_bima_full_off\n",
      "\n",
      "🎉 SUCCESS: DiFuMo time series extraction complete!\n",
      "📊 Output shape: (512, 126537) (512 components × 126537 time points)\n",
      "📄 Details saved in:\n",
      "   - /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-03_bima_full_off/difumo_time_courses.npy\n",
      "   - /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-03_bima_full_off/difumo_component_info.csv\n",
      "\n",
      "=== Files in output folder: /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-03_bima_full_off ===\n",
      "fsaverage-trans.fif\n",
      "source_estimate_LCMV.h5\n",
      "debug_source_info.pkl\n",
      "source_space_points_mm.npy\n",
      "difumo_component_info.csv\n",
      "difumo_time_courses.npy\n",
      "computation_metadata.pkl\n",
      "fsaverage-vol-eeg-fwd.fif\n",
      "✅ DIFUMO SUCCESS: sub-03_bima_full_off.fif\n",
      "🔁 Loading STC: /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-05_bima_full_off/source_estimate_LCMV.h5\n",
      "Loaded STC: (13222, 263517) (sources × time)\n",
      "🔁 Loading source space: /home/jaizor/jaizor/xtra/derivatives/lcmv/fsaverage-vol-5mm-src.fif\n",
      "Loaded source space with 24303 active sources\n",
      "\n",
      "=== DiFuMo Processing ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">fetch_atlas_difumo</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span> Dataset found in <span style=\"color: #800080; text-decoration-color: #800080\">/home/jaizor/nilearn_data/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">difumo_atlases</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34m[\u001b[0m\u001b[34mfetch_atlas_difumo\u001b[0m\u001b[1;34m]\u001b[0m Dataset found in \u001b[35m/home/jaizor/nilearn_data/\u001b[0m\u001b[95mdifumo_atlases\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 13222/13222 sources within atlas bounds\n",
      "Processing component 1/512\n",
      "Processing component 101/512\n",
      "Processing component 201/512\n",
      "Processing component 301/512\n",
      "Processing component 401/512\n",
      "Processing component 501/512\n",
      "✅ 505/512 components have at least one source\n",
      "💾 Saved to: /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-05_bima_full_off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting DiFuMo ROIs:  33%|███▎      | 4/12 [24:37<49:39, 372.41s/subject]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎉 SUCCESS: DiFuMo time series extraction complete!\n",
      "📊 Output shape: (512, 263517) (512 components × 263517 time points)\n",
      "📄 Details saved in:\n",
      "   - /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-05_bima_full_off/difumo_time_courses.npy\n",
      "   - /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-05_bima_full_off/difumo_component_info.csv\n",
      "\n",
      "=== Files in output folder: /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-05_bima_full_off ===\n",
      "fsaverage-trans.fif\n",
      "source_estimate_LCMV.h5\n",
      "debug_source_info.pkl\n",
      "source_space_points_mm.npy\n",
      "difumo_component_info.csv\n",
      "difumo_time_courses.npy\n",
      "computation_metadata.pkl\n",
      "fsaverage-vol-eeg-fwd.fif\n",
      "✅ DIFUMO SUCCESS: sub-05_bima_full_off.fif\n",
      "🔁 Loading STC: /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-06_bima_full_off/source_estimate_LCMV.h5\n",
      "Loaded STC: (13222, 263523) (sources × time)\n",
      "🔁 Loading source space: /home/jaizor/jaizor/xtra/derivatives/lcmv/fsaverage-vol-5mm-src.fif\n",
      "Loaded source space with 24303 active sources\n",
      "\n",
      "=== DiFuMo Processing ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">fetch_atlas_difumo</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span> Dataset found in <span style=\"color: #800080; text-decoration-color: #800080\">/home/jaizor/nilearn_data/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">difumo_atlases</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34m[\u001b[0m\u001b[34mfetch_atlas_difumo\u001b[0m\u001b[1;34m]\u001b[0m Dataset found in \u001b[35m/home/jaizor/nilearn_data/\u001b[0m\u001b[95mdifumo_atlases\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 13222/13222 sources within atlas bounds\n",
      "Processing component 1/512\n",
      "Processing component 101/512\n",
      "Processing component 201/512\n",
      "Processing component 301/512\n",
      "Processing component 401/512\n",
      "Processing component 501/512\n",
      "✅ 505/512 components have at least one source\n",
      "💾 Saved to: /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-06_bima_full_off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting DiFuMo ROIs:  42%|████▏     | 5/12 [30:54<43:38, 374.06s/subject]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎉 SUCCESS: DiFuMo time series extraction complete!\n",
      "📊 Output shape: (512, 263523) (512 components × 263523 time points)\n",
      "📄 Details saved in:\n",
      "   - /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-06_bima_full_off/difumo_time_courses.npy\n",
      "   - /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-06_bima_full_off/difumo_component_info.csv\n",
      "\n",
      "=== Files in output folder: /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-06_bima_full_off ===\n",
      "fsaverage-trans.fif\n",
      "source_estimate_LCMV.h5\n",
      "debug_source_info.pkl\n",
      "source_space_points_mm.npy\n",
      "difumo_component_info.csv\n",
      "difumo_time_courses.npy\n",
      "computation_metadata.pkl\n",
      "fsaverage-vol-eeg-fwd.fif\n",
      "✅ DIFUMO SUCCESS: sub-06_bima_full_off.fif\n",
      "🔁 Loading STC: /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-07_bima_full_off/source_estimate_LCMV.h5\n",
      "Loaded STC: (13222, 263515) (sources × time)\n",
      "🔁 Loading source space: /home/jaizor/jaizor/xtra/derivatives/lcmv/fsaverage-vol-5mm-src.fif\n",
      "Loaded source space with 24303 active sources\n",
      "\n",
      "=== DiFuMo Processing ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">fetch_atlas_difumo</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span> Dataset found in <span style=\"color: #800080; text-decoration-color: #800080\">/home/jaizor/nilearn_data/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">difumo_atlases</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34m[\u001b[0m\u001b[34mfetch_atlas_difumo\u001b[0m\u001b[1;34m]\u001b[0m Dataset found in \u001b[35m/home/jaizor/nilearn_data/\u001b[0m\u001b[95mdifumo_atlases\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 13222/13222 sources within atlas bounds\n",
      "Processing component 1/512\n",
      "Processing component 101/512\n",
      "Processing component 201/512\n",
      "Processing component 301/512\n",
      "Processing component 401/512\n",
      "Processing component 501/512\n",
      "✅ 505/512 components have at least one source\n",
      "💾 Saved to: /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-07_bima_full_off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting DiFuMo ROIs:  50%|█████     | 6/12 [37:12<37:32, 375.36s/subject]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎉 SUCCESS: DiFuMo time series extraction complete!\n",
      "📊 Output shape: (512, 263515) (512 components × 263515 time points)\n",
      "📄 Details saved in:\n",
      "   - /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-07_bima_full_off/difumo_time_courses.npy\n",
      "   - /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-07_bima_full_off/difumo_component_info.csv\n",
      "\n",
      "=== Files in output folder: /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-07_bima_full_off ===\n",
      "fsaverage-trans.fif\n",
      "source_estimate_LCMV.h5\n",
      "debug_source_info.pkl\n",
      "source_space_points_mm.npy\n",
      "difumo_component_info.csv\n",
      "difumo_time_courses.npy\n",
      "computation_metadata.pkl\n",
      "fsaverage-vol-eeg-fwd.fif\n",
      "✅ DIFUMO SUCCESS: sub-07_bima_full_off.fif\n",
      "🔁 Loading STC: /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-08_bima_full_off/source_estimate_LCMV.h5\n",
      "Loaded STC: (13222, 263481) (sources × time)\n",
      "🔁 Loading source space: /home/jaizor/jaizor/xtra/derivatives/lcmv/fsaverage-vol-5mm-src.fif\n",
      "Loaded source space with 24303 active sources\n",
      "\n",
      "=== DiFuMo Processing ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">fetch_atlas_difumo</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span> Dataset found in <span style=\"color: #800080; text-decoration-color: #800080\">/home/jaizor/nilearn_data/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">difumo_atlases</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34m[\u001b[0m\u001b[34mfetch_atlas_difumo\u001b[0m\u001b[1;34m]\u001b[0m Dataset found in \u001b[35m/home/jaizor/nilearn_data/\u001b[0m\u001b[95mdifumo_atlases\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 13222/13222 sources within atlas bounds\n",
      "Processing component 1/512\n",
      "Processing component 101/512\n",
      "Processing component 201/512\n",
      "Processing component 301/512\n",
      "Processing component 401/512\n",
      "Processing component 501/512\n",
      "✅ 505/512 components have at least one source\n",
      "💾 Saved to: /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-08_bima_full_off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting DiFuMo ROIs:  58%|█████▊    | 7/12 [43:55<32:02, 384.45s/subject]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎉 SUCCESS: DiFuMo time series extraction complete!\n",
      "📊 Output shape: (512, 263481) (512 components × 263481 time points)\n",
      "📄 Details saved in:\n",
      "   - /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-08_bima_full_off/difumo_time_courses.npy\n",
      "   - /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-08_bima_full_off/difumo_component_info.csv\n",
      "\n",
      "=== Files in output folder: /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-08_bima_full_off ===\n",
      "fsaverage-trans.fif\n",
      "source_estimate_LCMV.h5\n",
      "debug_source_info.pkl\n",
      "source_space_points_mm.npy\n",
      "difumo_component_info.csv\n",
      "difumo_time_courses.npy\n",
      "computation_metadata.pkl\n",
      "fsaverage-vol-eeg-fwd.fif\n",
      "✅ DIFUMO SUCCESS: sub-08_bima_full_off.fif\n",
      "🔁 Loading STC: /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-09_bima_full_off/source_estimate_LCMV.h5\n",
      "Loaded STC: (13222, 263506) (sources × time)\n",
      "🔁 Loading source space: /home/jaizor/jaizor/xtra/derivatives/lcmv/fsaverage-vol-5mm-src.fif\n",
      "Loaded source space with 24303 active sources\n",
      "\n",
      "=== DiFuMo Processing ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">fetch_atlas_difumo</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span> Dataset found in <span style=\"color: #800080; text-decoration-color: #800080\">/home/jaizor/nilearn_data/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">difumo_atlases</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34m[\u001b[0m\u001b[34mfetch_atlas_difumo\u001b[0m\u001b[1;34m]\u001b[0m Dataset found in \u001b[35m/home/jaizor/nilearn_data/\u001b[0m\u001b[95mdifumo_atlases\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 13222/13222 sources within atlas bounds\n",
      "Processing component 1/512\n",
      "Processing component 101/512\n",
      "Processing component 201/512\n",
      "Processing component 301/512\n",
      "Processing component 401/512\n",
      "Processing component 501/512\n",
      "✅ 505/512 components have at least one source\n",
      "💾 Saved to: /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-09_bima_full_off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting DiFuMo ROIs:  67%|██████▋   | 8/12 [50:07<25:21, 380.34s/subject]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎉 SUCCESS: DiFuMo time series extraction complete!\n",
      "📊 Output shape: (512, 263506) (512 components × 263506 time points)\n",
      "📄 Details saved in:\n",
      "   - /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-09_bima_full_off/difumo_time_courses.npy\n",
      "   - /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-09_bima_full_off/difumo_component_info.csv\n",
      "\n",
      "=== Files in output folder: /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-09_bima_full_off ===\n",
      "fsaverage-trans.fif\n",
      "source_estimate_LCMV.h5\n",
      "debug_source_info.pkl\n",
      "source_space_points_mm.npy\n",
      "difumo_component_info.csv\n",
      "difumo_time_courses.npy\n",
      "computation_metadata.pkl\n",
      "fsaverage-vol-eeg-fwd.fif\n",
      "✅ DIFUMO SUCCESS: sub-09_bima_full_off.fif\n",
      "🔁 Loading STC: /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-10_bima_full_off/source_estimate_LCMV.h5\n",
      "Loaded STC: (13222, 263524) (sources × time)\n",
      "🔁 Loading source space: /home/jaizor/jaizor/xtra/derivatives/lcmv/fsaverage-vol-5mm-src.fif\n",
      "Loaded source space with 24303 active sources\n",
      "\n",
      "=== DiFuMo Processing ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">fetch_atlas_difumo</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span> Dataset found in <span style=\"color: #800080; text-decoration-color: #800080\">/home/jaizor/nilearn_data/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">difumo_atlases</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34m[\u001b[0m\u001b[34mfetch_atlas_difumo\u001b[0m\u001b[1;34m]\u001b[0m Dataset found in \u001b[35m/home/jaizor/nilearn_data/\u001b[0m\u001b[95mdifumo_atlases\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 13222/13222 sources within atlas bounds\n",
      "Processing component 1/512\n",
      "Processing component 101/512\n",
      "Processing component 201/512\n",
      "Processing component 301/512\n",
      "Processing component 401/512\n",
      "Processing component 501/512\n",
      "✅ 505/512 components have at least one source\n",
      "💾 Saved to: /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-10_bima_full_off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting DiFuMo ROIs:  75%|███████▌  | 9/12 [56:20<18:54, 378.04s/subject]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎉 SUCCESS: DiFuMo time series extraction complete!\n",
      "📊 Output shape: (512, 263524) (512 components × 263524 time points)\n",
      "📄 Details saved in:\n",
      "   - /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-10_bima_full_off/difumo_time_courses.npy\n",
      "   - /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-10_bima_full_off/difumo_component_info.csv\n",
      "\n",
      "=== Files in output folder: /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-10_bima_full_off ===\n",
      "fsaverage-trans.fif\n",
      "source_estimate_LCMV.h5\n",
      "debug_source_info.pkl\n",
      "source_space_points_mm.npy\n",
      "difumo_component_info.csv\n",
      "difumo_time_courses.npy\n",
      "computation_metadata.pkl\n",
      "fsaverage-vol-eeg-fwd.fif\n",
      "✅ DIFUMO SUCCESS: sub-10_bima_full_off.fif\n",
      "🔁 Loading STC: /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-11_bima_full_off/source_estimate_LCMV.h5\n",
      "Loaded STC: (13222, 131679) (sources × time)\n",
      "🔁 Loading source space: /home/jaizor/jaizor/xtra/derivatives/lcmv/fsaverage-vol-5mm-src.fif\n",
      "Loaded source space with 24303 active sources\n",
      "\n",
      "=== DiFuMo Processing ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">fetch_atlas_difumo</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span> Dataset found in <span style=\"color: #800080; text-decoration-color: #800080\">/home/jaizor/nilearn_data/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">difumo_atlases</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34m[\u001b[0m\u001b[34mfetch_atlas_difumo\u001b[0m\u001b[1;34m]\u001b[0m Dataset found in \u001b[35m/home/jaizor/nilearn_data/\u001b[0m\u001b[95mdifumo_atlases\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 13222/13222 sources within atlas bounds\n",
      "Processing component 1/512\n",
      "Processing component 101/512\n",
      "Processing component 201/512\n",
      "Processing component 301/512\n",
      "Processing component 401/512\n",
      "Processing component 501/512\n",
      "✅ 505/512 components have at least one source\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting DiFuMo ROIs:  83%|████████▎ | 10/12 [1:02:20<12:25, 372.60s/subject]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saved to: /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-11_bima_full_off\n",
      "\n",
      "🎉 SUCCESS: DiFuMo time series extraction complete!\n",
      "📊 Output shape: (512, 131679) (512 components × 131679 time points)\n",
      "📄 Details saved in:\n",
      "   - /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-11_bima_full_off/difumo_time_courses.npy\n",
      "   - /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-11_bima_full_off/difumo_component_info.csv\n",
      "\n",
      "=== Files in output folder: /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-11_bima_full_off ===\n",
      "fsaverage-trans.fif\n",
      "source_estimate_LCMV.h5\n",
      "debug_source_info.pkl\n",
      "source_space_points_mm.npy\n",
      "difumo_component_info.csv\n",
      "difumo_time_courses.npy\n",
      "computation_metadata.pkl\n",
      "fsaverage-vol-eeg-fwd.fif\n",
      "✅ DIFUMO SUCCESS: sub-11_bima_full_off.fif\n",
      "🔁 Loading STC: /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-12_bima_full_off/source_estimate_LCMV.h5\n",
      "Loaded STC: (13222, 210656) (sources × time)\n",
      "🔁 Loading source space: /home/jaizor/jaizor/xtra/derivatives/lcmv/fsaverage-vol-5mm-src.fif\n",
      "Loaded source space with 24303 active sources\n",
      "\n",
      "=== DiFuMo Processing ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">fetch_atlas_difumo</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span> Dataset found in <span style=\"color: #800080; text-decoration-color: #800080\">/home/jaizor/nilearn_data/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">difumo_atlases</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34m[\u001b[0m\u001b[34mfetch_atlas_difumo\u001b[0m\u001b[1;34m]\u001b[0m Dataset found in \u001b[35m/home/jaizor/nilearn_data/\u001b[0m\u001b[95mdifumo_atlases\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 13222/13222 sources within atlas bounds\n",
      "Processing component 1/512\n",
      "Processing component 101/512\n",
      "Processing component 201/512\n",
      "Processing component 301/512\n",
      "Processing component 401/512\n",
      "Processing component 501/512\n",
      "✅ 505/512 components have at least one source\n",
      "💾 Saved to: /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-12_bima_full_off\n",
      "\n",
      "🎉 SUCCESS: DiFuMo time series extraction complete!\n",
      "📊 Output shape: (512, 210656) (512 components × 210656 time points)\n",
      "📄 Details saved in:\n",
      "   - /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-12_bima_full_off/difumo_time_courses.npy\n",
      "   - /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-12_bima_full_off/difumo_component_info.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting DiFuMo ROIs:  92%|█████████▏| 11/12 [1:08:22<06:09, 369.36s/subject]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Files in output folder: /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-12_bima_full_off ===\n",
      "fsaverage-trans.fif\n",
      "source_estimate_LCMV.h5\n",
      "debug_source_info.pkl\n",
      "source_space_points_mm.npy\n",
      "difumo_component_info.csv\n",
      "difumo_time_courses.npy\n",
      "computation_metadata.pkl\n",
      "fsaverage-vol-eeg-fwd.fif\n",
      "✅ DIFUMO SUCCESS: sub-12_bima_full_off.fif\n",
      "🔁 Loading STC: /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-14_bima_full_off/source_estimate_LCMV.h5\n",
      "Loaded STC: (13222, 263356) (sources × time)\n",
      "🔁 Loading source space: /home/jaizor/jaizor/xtra/derivatives/lcmv/fsaverage-vol-5mm-src.fif\n",
      "Loaded source space with 24303 active sources\n",
      "\n",
      "=== DiFuMo Processing ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">fetch_atlas_difumo</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span> Dataset found in <span style=\"color: #800080; text-decoration-color: #800080\">/home/jaizor/nilearn_data/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">difumo_atlases</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34m[\u001b[0m\u001b[34mfetch_atlas_difumo\u001b[0m\u001b[1;34m]\u001b[0m Dataset found in \u001b[35m/home/jaizor/nilearn_data/\u001b[0m\u001b[95mdifumo_atlases\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 13222/13222 sources within atlas bounds\n",
      "Processing component 1/512\n",
      "Processing component 101/512\n",
      "Processing component 201/512\n",
      "Processing component 301/512\n",
      "Processing component 401/512\n",
      "Processing component 501/512\n",
      "✅ 505/512 components have at least one source\n",
      "💾 Saved to: /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-14_bima_full_off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting DiFuMo ROIs: 100%|██████████| 12/12 [1:14:35<00:00, 372.95s/subject]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎉 SUCCESS: DiFuMo time series extraction complete!\n",
      "📊 Output shape: (512, 263356) (512 components × 263356 time points)\n",
      "📄 Details saved in:\n",
      "   - /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-14_bima_full_off/difumo_time_courses.npy\n",
      "   - /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-14_bima_full_off/difumo_component_info.csv\n",
      "\n",
      "=== Files in output folder: /home/jaizor/jaizor/xtra/derivatives/lcmv/sub-14_bima_full_off ===\n",
      "fsaverage-trans.fif\n",
      "source_estimate_LCMV.h5\n",
      "debug_source_info.pkl\n",
      "source_space_points_mm.npy\n",
      "difumo_component_info.csv\n",
      "difumo_time_courses.npy\n",
      "computation_metadata.pkl\n",
      "fsaverage-vol-eeg-fwd.fif\n",
      "✅ DIFUMO SUCCESS: sub-14_bima_full_off.fif\n",
      "\n",
      "================================================================================\n",
      "🎉 DIFUMO EXTRACTION COMPLETE\n",
      "================================================================================\n",
      "   Successfully processed: 12\n",
      "   Failed:                0\n",
      "   Output folder: /home/jaizor/jaizor/xtra/derivatives/lcmv/\n",
      "\n",
      "✅ All done! DiFuMo time courses saved in each subject's folder as:\n",
      "   - difumo_time_courses.npy\n",
      "   - difumo_component_info.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- CONFIGURATION (same as before) ---\n",
    "PROJECT_BASE = \"/home/jaizor/jaizor/xtra\"\n",
    "BASE_DERIVATIVES_DIR = Path(PROJECT_BASE) / \"derivatives/eeg\"\n",
    "GPS_FILE_PATH = \"data/ghw280_from_egig.gpsc\"\n",
    "\n",
    "CONFIG_TEMPLATE = {\n",
    "    'project_base': PROJECT_BASE,\n",
    "    'gpsc_file_path': GPS_FILE_PATH,\n",
    "    'reg': 0.01,\n",
    "    'n_jobs': -1,\n",
    "    'skip_difumo': True  # not used in extraction, but kept for consistency\n",
    "}\n",
    "\n",
    "# --- ✅ REUSE YOUR EXISTING SEGMENT DISCOVERY FUNCTION ---\n",
    "def find_all_segment_files(base_dir: Path) -> list:\n",
    "    \"\"\"Find all full BIMA ICA files — structured to be 100% compatible with original crop script.\"\"\"\n",
    "    segments = []\n",
    "    session = \"DBSOFF\"\n",
    "    task_in_path = \"bima\"\n",
    "\n",
    "    for subj_dir in base_dir.iterdir():\n",
    "        if not subj_dir.is_dir() or not subj_dir.name.startswith('sub-'):\n",
    "            continue\n",
    "\n",
    "        subject_id = subj_dir.name\n",
    "        session_folder = subj_dir / f\"{task_in_path}_{session}\"\n",
    "\n",
    "        if not session_folder.exists():\n",
    "            continue\n",
    "\n",
    "        fif_filename = f\"{subject_id}_ses-{session}_task-{task_in_path}_eeg_ica_cleaned_raw.fif\"\n",
    "        fif_file = session_folder / fif_filename\n",
    "\n",
    "        if not fif_file.exists():\n",
    "            continue\n",
    "\n",
    "        fake_filename = f\"{subject_id}_bima_full_off.fif\"\n",
    "\n",
    "        segments.append({\n",
    "            'path': fif_file,\n",
    "            'on_off': \"Off\",\n",
    "            'task': \"ignored\",\n",
    "            'filename': fake_filename\n",
    "        })\n",
    "\n",
    "    return sorted(segments, key=lambda x: x['filename'])\n",
    "\n",
    "# ✅ Keep variable name same as original script\n",
    "CROP_BASE_DIR = BASE_DERIVATIVES_DIR\n",
    "segments = find_all_segment_files(CROP_BASE_DIR)\n",
    "\n",
    "print(f\"🔍 Found {len(segments)} subjects for DiFuMo extraction.\")\n",
    "\n",
    "# --- EXTRACT DIFUMO TIME SERIES ---\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"🧠 STARTING DIFUMO TIME SERIES EXTRACTION (512 components, 2mm)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "success_count = 0\n",
    "failure_count = 0\n",
    "\n",
    "for seg in tqdm(segments, desc=\"Extracting DiFuMo ROIs\", unit=\"subject\"):\n",
    "    filename_no_ext = seg['filename'].replace('.fif', '')\n",
    "    parts = filename_no_ext.split('_')\n",
    "    if len(parts) < 3:\n",
    "        tqdm.write(f\"❌ Invalid filename format: {seg['filename']}\")\n",
    "        failure_count += 1\n",
    "        continue\n",
    "\n",
    "    subject_simple = parts[0]          # e.g., \"sub-01\"\n",
    "    task_name = '_'.join(parts[1:])    # e.g., \"bima_full_off\"\n",
    "    subject_id = subject_simple\n",
    "\n",
    "    # Build config\n",
    "    config = CONFIG_TEMPLATE.copy()\n",
    "    config.update({\n",
    "        'subject_id': subject_id,\n",
    "        'task': task_name,\n",
    "        'ica_file_path': str(seg['path'].relative_to(PROJECT_BASE))\n",
    "    })\n",
    "\n",
    "    try:\n",
    "        estimator = LCMVSourceEstimator(config)\n",
    "\n",
    "        # ✅ EXTRACT DIFUMO — loads existing STC + global source space\n",
    "        time_courses, component_info = estimator.run_difumo_extraction(\n",
    "            difumo_config={\n",
    "                'dimension': 512,      # Change to 64, 128, 256, or 1024 if desired\n",
    "                'resolution_mm': 2     # 2mm for 512-dim; use 3mm for 64/128/256\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Optional: List files to confirm\n",
    "        estimator.list_output_files()\n",
    "\n",
    "        tqdm.write(f\"✅ DIFUMO SUCCESS: {seg['filename']}\")\n",
    "        success_count += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        tqdm.write(f\"❌ DIFUMO FAILED: {seg['filename']} — {e}\")\n",
    "        failure_count += 1\n",
    "\n",
    "# --- FINAL SUMMARY ---\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"🎉 DIFUMO EXTRACTION COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"   Successfully processed: {success_count}\")\n",
    "print(f\"   Failed:                {failure_count}\")\n",
    "print(f\"   Output folder: {PROJECT_BASE}/derivatives/lcmv/\")\n",
    "\n",
    "if failure_count == 0:\n",
    "    print(\"\\n✅ All done! DiFuMo time courses saved in each subject's folder as:\")\n",
    "    print(\"   - difumo_time_courses.npy\")\n",
    "    print(\"   - difumo_component_info.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Xtra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
