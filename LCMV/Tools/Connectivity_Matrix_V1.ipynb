{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2812d380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ultra-fast group connectivity analysis...\n",
      "📥 Loading ROI names...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">fetch_atlas_difumo</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span> Dataset found in <span style=\"color: #800080; text-decoration-color: #800080\">/home/jaizor/nilearn_data/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">difumo_atlases</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34m[\u001b[0m\u001b[34mfetch_atlas_difumo\u001b[0m\u001b[1;34m]\u001b[0m Dataset found in \u001b[35m/home/jaizor/nilearn_data/\u001b[0m\u001b[95mdifumo_atlases\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧬 Found 12 subjects\n",
      "🚀 Processing 12 subjects in parallel using 39 cores...\n",
      "📥 Loaded (512, 126537) from difumo_time_courses.npy\n",
      "📥 Loaded (512, 131679) from difumo_time_courses.npy\n",
      "📥 Loaded (512, 215473) from difumo_time_courses.npy\n",
      "📥 Loaded (512, 210656) from difumo_time_courses.npy\n",
      "📥 Loaded (512, 248466) from difumo_time_courses.npy\n",
      "📥 Loaded (512, 263523) from difumo_time_courses.npy📥 Loaded (512, 263517) from difumo_time_courses.npy\n",
      "\n",
      "📥 Loaded (512, 263356) from difumo_time_courses.npy\n",
      "📥 Loaded (512, 263506) from difumo_time_courses.npy\n",
      "📥 Loaded (512, 263481) from difumo_time_courses.npy📥 Loaded (512, 263515) from difumo_time_courses.npy\n",
      "📥 Loaded (512, 263524) from difumo_time_courses.npy\n",
      "\n",
      "   💾 Saved InPhase_Theta.npy for sub-08\n",
      "   💾 Saved InPhase_Alpha.npy for sub-08\n",
      "   💾 Saved InPhase_Low_Beta.npy for sub-08\n",
      "   💾 Saved InPhase_High_Beta.npy for sub-08\n",
      "   💾 Saved InPhase_Low_Gamma.npy for sub-08\n",
      "   💾 Saved InPhase_High_Gamma.npy for sub-08\n",
      "   💾 Saved OutofPhase_Theta.npy for sub-08\n",
      "   💾 Saved OutofPhase_Alpha.npy for sub-08\n",
      "   💾 Saved OutofPhase_Low_Beta.npy for sub-08\n",
      "   💾 Saved OutofPhase_High_Beta.npy for sub-08\n",
      "   💾 Saved OutofPhase_Low_Gamma.npy for sub-08\n",
      "   💾 Saved OutofPhase_High_Gamma.npy for sub-08\n",
      "✅ sub-08: 12 matrices (1/12)\n",
      "   💾 Saved InPhase_Theta.npy for sub-14\n",
      "   💾 Saved InPhase_Alpha.npy for sub-14\n",
      "   💾 Saved InPhase_Low_Beta.npy for sub-14\n",
      "   💾 Saved InPhase_High_Beta.npy for sub-14\n",
      "   💾 Saved InPhase_Low_Gamma.npy for sub-14\n",
      "   💾 Saved InPhase_High_Gamma.npy for sub-14\n",
      "   💾 Saved OutofPhase_Theta.npy for sub-14\n",
      "   💾 Saved OutofPhase_Alpha.npy for sub-14\n",
      "   💾 Saved OutofPhase_Low_Beta.npy for sub-14\n",
      "   💾 Saved OutofPhase_High_Beta.npy for sub-14\n",
      "   💾 Saved OutofPhase_Low_Gamma.npy for sub-14\n",
      "   💾 Saved OutofPhase_High_Gamma.npy for sub-14\n",
      "✅ sub-14: 12 matrices (2/12)\n",
      "   💾 Saved InPhase_Theta.npy for sub-10\n",
      "   💾 Saved InPhase_Alpha.npy for sub-10\n",
      "   💾 Saved InPhase_Low_Beta.npy for sub-10\n",
      "   💾 Saved InPhase_High_Beta.npy for sub-10\n",
      "   💾 Saved InPhase_Low_Gamma.npy for sub-10\n",
      "   💾 Saved InPhase_High_Gamma.npy for sub-10\n",
      "   💾 Saved OutofPhase_Theta.npy for sub-10\n",
      "   💾 Saved OutofPhase_Alpha.npy for sub-10\n",
      "   💾 Saved OutofPhase_Low_Beta.npy for sub-10\n",
      "   💾 Saved OutofPhase_High_Beta.npy for sub-10\n",
      "   💾 Saved OutofPhase_Low_Gamma.npy for sub-10\n",
      "   💾 Saved OutofPhase_High_Gamma.npy for sub-10\n",
      "✅ sub-10: 12 matrices (3/12)\n",
      "   💾 Saved InPhase_Theta.npy for sub-05\n",
      "   💾 Saved InPhase_Alpha.npy for sub-05\n",
      "   💾 Saved InPhase_Low_Beta.npy for sub-05\n",
      "   💾 Saved InPhase_High_Beta.npy for sub-05\n",
      "   💾 Saved InPhase_Low_Gamma.npy for sub-05\n",
      "   💾 Saved InPhase_High_Gamma.npy for sub-05\n",
      "   💾 Saved OutofPhase_Theta.npy for sub-05\n",
      "   💾 Saved OutofPhase_Alpha.npy for sub-05\n",
      "   💾 Saved OutofPhase_Low_Beta.npy for sub-05\n",
      "   💾 Saved OutofPhase_High_Beta.npy for sub-05\n",
      "   💾 Saved OutofPhase_Low_Gamma.npy for sub-05\n",
      "   💾 Saved OutofPhase_High_Gamma.npy for sub-05\n",
      "✅ sub-05: 12 matrices (4/12)\n",
      "   💾 Saved InPhase_Theta.npy for sub-12\n",
      "   💾 Saved InPhase_Alpha.npy for sub-12\n",
      "   💾 Saved InPhase_Low_Beta.npy for sub-12\n",
      "   💾 Saved InPhase_High_Beta.npy for sub-12\n",
      "   💾 Saved InPhase_Low_Gamma.npy for sub-12\n",
      "   💾 Saved InPhase_High_Gamma.npy for sub-12\n",
      "   💾 Saved OutofPhase_Theta.npy for sub-12\n",
      "   💾 Saved OutofPhase_Alpha.npy for sub-12\n",
      "   💾 Saved OutofPhase_Low_Beta.npy for sub-12\n",
      "   💾 Saved OutofPhase_High_Beta.npy for sub-12\n",
      "   💾 Saved OutofPhase_Low_Gamma.npy for sub-12\n",
      "   💾 Saved OutofPhase_High_Gamma.npy for sub-12\n",
      "✅ sub-12: 12 matrices (5/12)\n",
      "   💾 Saved InPhase_Theta.npy for sub-02\n",
      "   💾 Saved InPhase_Alpha.npy for sub-02\n",
      "   💾 Saved InPhase_Low_Beta.npy for sub-02\n",
      "   💾 Saved InPhase_High_Beta.npy for sub-02\n",
      "   💾 Saved InPhase_Low_Gamma.npy for sub-02\n",
      "   💾 Saved InPhase_High_Gamma.npy for sub-02\n",
      "   💾 Saved OutofPhase_Theta.npy for sub-02\n",
      "   💾 Saved OutofPhase_Alpha.npy for sub-02\n",
      "   💾 Saved OutofPhase_Low_Beta.npy for sub-02\n",
      "   💾 Saved OutofPhase_High_Beta.npy for sub-02\n",
      "   💾 Saved OutofPhase_Low_Gamma.npy for sub-02\n",
      "   💾 Saved OutofPhase_High_Gamma.npy for sub-02\n",
      "✅ sub-02: 12 matrices (6/12)\n",
      "   💾 Saved InPhase_Theta.npy for sub-06\n",
      "   💾 Saved InPhase_Alpha.npy for sub-06\n",
      "   💾 Saved InPhase_Low_Beta.npy for sub-06\n",
      "   💾 Saved InPhase_High_Beta.npy for sub-06\n",
      "   💾 Saved InPhase_Low_Gamma.npy for sub-06\n",
      "   💾 Saved InPhase_High_Gamma.npy for sub-06\n",
      "   💾 Saved OutofPhase_Theta.npy for sub-06\n",
      "   💾 Saved OutofPhase_Alpha.npy for sub-06\n",
      "   💾 Saved OutofPhase_Low_Beta.npy for sub-06\n",
      "   💾 Saved OutofPhase_High_Beta.npy for sub-06\n",
      "   💾 Saved OutofPhase_Low_Gamma.npy for sub-06\n",
      "   💾 Saved OutofPhase_High_Gamma.npy for sub-06\n",
      "✅ sub-06: 12 matrices (7/12)\n",
      "   💾 Saved InPhase_Theta.npy for sub-09\n",
      "   💾 Saved InPhase_Alpha.npy for sub-09\n",
      "   💾 Saved InPhase_Low_Beta.npy for sub-09\n",
      "   💾 Saved InPhase_High_Beta.npy for sub-09\n",
      "   💾 Saved InPhase_Low_Gamma.npy for sub-09\n",
      "   💾 Saved InPhase_High_Gamma.npy for sub-09\n",
      "   💾 Saved OutofPhase_Theta.npy for sub-09\n",
      "   💾 Saved OutofPhase_Alpha.npy for sub-09\n",
      "   💾 Saved OutofPhase_Low_Beta.npy for sub-09\n",
      "   💾 Saved OutofPhase_High_Beta.npy for sub-09\n",
      "   💾 Saved OutofPhase_Low_Gamma.npy for sub-09\n",
      "   💾 Saved OutofPhase_High_Gamma.npy for sub-09\n",
      "✅ sub-09: 12 matrices (8/12)\n",
      "   💾 Saved InPhase_Theta.npy for sub-07\n",
      "   💾 Saved InPhase_Alpha.npy for sub-07\n",
      "   💾 Saved InPhase_Low_Beta.npy for sub-07\n",
      "   💾 Saved InPhase_High_Beta.npy for sub-07\n",
      "   💾 Saved InPhase_Low_Gamma.npy for sub-07\n",
      "   💾 Saved InPhase_High_Gamma.npy for sub-07\n",
      "   💾 Saved OutofPhase_Theta.npy for sub-07\n",
      "   💾 Saved OutofPhase_Alpha.npy for sub-07\n",
      "   💾 Saved OutofPhase_Low_Beta.npy for sub-07\n",
      "   💾 Saved OutofPhase_High_Beta.npy for sub-07\n",
      "   💾 Saved OutofPhase_Low_Gamma.npy for sub-07\n",
      "   💾 Saved OutofPhase_High_Gamma.npy for sub-07\n",
      "✅ sub-07: 12 matrices (9/12)\n",
      "   💾 Saved InPhase_Theta.npy for sub-11\n",
      "   💾 Saved InPhase_Alpha.npy for sub-11\n",
      "   💾 Saved InPhase_Low_Beta.npy for sub-11\n",
      "   💾 Saved InPhase_High_Beta.npy for sub-11\n",
      "   💾 Saved InPhase_Low_Gamma.npy for sub-11\n",
      "   💾 Saved InPhase_High_Gamma.npy for sub-11\n",
      "   💾 Saved OutofPhase_Theta.npy for sub-11\n",
      "   💾 Saved OutofPhase_Alpha.npy for sub-11\n",
      "   💾 Saved OutofPhase_Low_Beta.npy for sub-11\n",
      "   💾 Saved OutofPhase_High_Beta.npy for sub-11\n",
      "   💾 Saved OutofPhase_Low_Gamma.npy for sub-11\n",
      "   💾 Saved OutofPhase_High_Gamma.npy for sub-11\n",
      "✅ sub-11: 12 matrices (10/12)\n",
      "   💾 Saved InPhase_Theta.npy for sub-01\n",
      "   💾 Saved InPhase_Alpha.npy for sub-01\n",
      "   💾 Saved InPhase_Low_Beta.npy for sub-01\n",
      "   💾 Saved InPhase_High_Beta.npy for sub-01\n",
      "   💾 Saved InPhase_Low_Gamma.npy for sub-01\n",
      "   💾 Saved InPhase_High_Gamma.npy for sub-01\n",
      "   💾 Saved OutofPhase_Theta.npy for sub-01\n",
      "   💾 Saved OutofPhase_Alpha.npy for sub-01\n",
      "   💾 Saved OutofPhase_Low_Beta.npy for sub-01\n",
      "   💾 Saved OutofPhase_High_Beta.npy for sub-01\n",
      "   💾 Saved OutofPhase_Low_Gamma.npy for sub-01\n",
      "   💾 Saved OutofPhase_High_Gamma.npy for sub-01\n",
      "✅ sub-01: 12 matrices (11/12)\n",
      "   💾 Saved InPhase_Theta.npy for sub-03\n",
      "   💾 Saved InPhase_Alpha.npy for sub-03\n",
      "   💾 Saved InPhase_Low_Beta.npy for sub-03\n",
      "   💾 Saved InPhase_High_Beta.npy for sub-03\n",
      "   💾 Saved InPhase_Low_Gamma.npy for sub-03\n",
      "   💾 Saved InPhase_High_Gamma.npy for sub-03\n",
      "   💾 Saved OutofPhase_Theta.npy for sub-03\n",
      "   💾 Saved OutofPhase_Alpha.npy for sub-03\n",
      "   💾 Saved OutofPhase_Low_Beta.npy for sub-03\n",
      "   💾 Saved OutofPhase_High_Beta.npy for sub-03\n",
      "   💾 Saved OutofPhase_Low_Gamma.npy for sub-03\n",
      "   💾 Saved OutofPhase_High_Gamma.npy for sub-03\n",
      "✅ sub-03: 12 matrices (12/12)\n",
      "\n",
      "⚡ Computing group averages...\n",
      "   ✅ InPhase Theta: 12 subjects\n",
      "   ✅ InPhase Alpha: 12 subjects\n",
      "   ✅ InPhase Low_Beta: 12 subjects\n",
      "   ✅ InPhase High_Beta: 12 subjects\n",
      "   ✅ InPhase Low_Gamma: 12 subjects\n",
      "   ✅ InPhase High_Gamma: 12 subjects\n",
      "   ✅ OutofPhase Theta: 12 subjects\n",
      "   ✅ OutofPhase Alpha: 12 subjects\n",
      "   ✅ OutofPhase Low_Beta: 12 subjects\n",
      "   ✅ OutofPhase High_Beta: 12 subjects\n",
      "   ✅ OutofPhase Low_Gamma: 12 subjects\n",
      "   ✅ OutofPhase High_Gamma: 12 subjects\n",
      "\n",
      "💾 Saving 12 group average matrices...\n",
      "   ✅ matrix_InPhase_Theta_group_avg.csv\n",
      "   ✅ matrix_InPhase_Alpha_group_avg.csv\n",
      "   ✅ matrix_InPhase_Low_Beta_group_avg.csv\n",
      "   ✅ matrix_InPhase_High_Beta_group_avg.csv\n",
      "   ✅ matrix_InPhase_Low_Gamma_group_avg.csv\n",
      "   ✅ matrix_InPhase_High_Gamma_group_avg.csv\n",
      "   ✅ matrix_OutofPhase_Theta_group_avg.csv\n",
      "   ✅ matrix_OutofPhase_Alpha_group_avg.csv\n",
      "   ✅ matrix_OutofPhase_Low_Beta_group_avg.csv\n",
      "   ✅ matrix_OutofPhase_High_Beta_group_avg.csv\n",
      "   ✅ matrix_OutofPhase_Low_Gamma_group_avg.csv\n",
      "   ✅ matrix_OutofPhase_High_Gamma_group_avg.csv\n",
      "\n",
      "🎉 Analysis Complete!\n",
      "   • Time elapsed: 657.3 seconds\n",
      "   • Subjects found: 12\n",
      "   • Total matrices computed: 144\n",
      "   • Conditions: ['InPhase', 'OutofPhase']\n",
      "   • Frequency bands: ['Theta', 'Alpha', 'Low_Beta', 'High_Beta', 'Low_Gamma', 'High_Gamma']\n",
      "   • Output: /home/jaizor/jaizor/xtra/derivatives/group\n",
      "   • Speed: 0.2 matrices/second\n",
      "   • Subject-level matrices saved in: /home/jaizor/jaizor/xtra/derivatives/group/subject_level\n"
     ]
    }
   ],
   "source": [
    "# Compute Group Connectivity + Save Subject-Level Matrices\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "from mne_connectivity import spectral_connectivity_epochs\n",
    "from nilearn import datasets\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import multiprocessing as mp\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "mne.set_log_level('ERROR')\n",
    "\n",
    "# Configuration\n",
    "PROJECT_BASE = '/home/jaizor/jaizor/xtra'\n",
    "BASE_DIR = Path(PROJECT_BASE)\n",
    "GROUP_OUTPUT_DIR = Path(PROJECT_BASE) / \"derivatives\" / \"group\"\n",
    "GROUP_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "BANDS = {\n",
    "    \"Theta\": (4, 8),\n",
    "    \"Alpha\": (8, 12),\n",
    "    \"Low_Beta\": (13, 20),\n",
    "    \"High_Beta\": (20, 30),\n",
    "    \"Low_Gamma\": (30, 60),\n",
    "    \"High_Gamma\": (60, 100)\n",
    "}\n",
    "\n",
    "METHOD = 'wpli2_debiased'\n",
    "SFREQ = 500.0\n",
    "N_ROIS = 512\n",
    "CONDITIONS = ['InPhase', 'OutofPhase']\n",
    "\n",
    "# Use all available cores minus 1\n",
    "N_JOBS = max(1, mp.cpu_count() - 1)\n",
    "\n",
    "\n",
    "def load_roi_names() -> List[str]:\n",
    "    \"\"\"Load and clean DiFuMo ROI names once.\"\"\"\n",
    "    try:\n",
    "        atlas = datasets.fetch_atlas_difumo(dimension=512, resolution_mm=2)\n",
    "        roi_names = atlas.labels['difumo_names'].astype(str).tolist()\n",
    "    except Exception:\n",
    "        roi_names = [f\"Component_{i}\" for i in range(N_ROIS)]\n",
    "    \n",
    "    # Clean names for CSV compatibility\n",
    "    return [name.replace(',', ';').replace('\\n', ' ').replace('\\r', ' ') \n",
    "            for name in roi_names]\n",
    "\n",
    "\n",
    "def find_subjects() -> List[str]:\n",
    "    \"\"\"Find all subjects with complete data.\"\"\"\n",
    "    eeg_dir = BASE_DIR / \"derivatives\" / \"eeg\"\n",
    "    if not eeg_dir.exists():\n",
    "        return []\n",
    "\n",
    "    subjects = []\n",
    "    for item in eeg_dir.iterdir():\n",
    "        if not (item.is_dir() and item.name.startswith(\"sub-\")):\n",
    "            continue\n",
    "            \n",
    "        # Check required files exist\n",
    "        events_dir = item / \"bima_DBSOFF\"\n",
    "        required_files = [\n",
    "            events_dir / f\"{item.name}_events_mne_binary-eve.fif\",\n",
    "            events_dir / f\"{item.name}_event_id_binary.json\",\n",
    "            BASE_DIR / \"derivatives\" / \"lcmv\" / f\"{item.name}_bima_full_off\" / \"difumo_time_courses.npy\"\n",
    "        ]\n",
    "        \n",
    "        if all(f.exists() for f in required_files):\n",
    "            subjects.append(item.name)\n",
    "\n",
    "    return sorted(subjects, key=lambda x: int(x.split('-')[1]))\n",
    "\n",
    "\n",
    "def compute_single_connectivity(epoch_data: np.ndarray, band_range: Tuple[float, float]) -> Optional[np.ndarray]:\n",
    "    \"\"\"Compute connectivity matrix for given epochs and frequency band - optimized version.\"\"\"\n",
    "    if len(epoch_data) == 0:\n",
    "        return None\n",
    "        \n",
    "    try:\n",
    "        # Use fewer tapers for speed while maintaining quality\n",
    "        con = spectral_connectivity_epochs(\n",
    "            data=epoch_data,\n",
    "            method=METHOD,\n",
    "            mode='multitaper',\n",
    "            sfreq=SFREQ,\n",
    "            fmin=band_range[0],\n",
    "            fmax=band_range[1],\n",
    "            faverage=True,\n",
    "            verbose=False,\n",
    "            n_jobs=1,  # Each process handles one job\n",
    "            mt_bandwidth=2,  # Reduced bandwidth for speed\n",
    "            mt_low_bias=True\n",
    "        )\n",
    "        \n",
    "        matrix = con.get_data(output='dense').squeeze()\n",
    "        \n",
    "        # Fast symmetrization and diagonal zeroing\n",
    "        matrix = np.maximum(matrix, matrix.T)  # Faster than (matrix + matrix.T) / 2\n",
    "        np.fill_diagonal(matrix, 0)\n",
    "        \n",
    "        return matrix.astype(np.float32)  # Use float32 to save memory\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️  Connectivity computation failed: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def save_subject_matrices(subject: str, subject_matrices: Dict[Tuple[str, str], np.ndarray], base_output_dir: Path):\n",
    "    \"\"\"Save subject-level connectivity matrices as .npy files.\"\"\"\n",
    "    subject_dir = base_output_dir / \"subject_level\" / subject\n",
    "    subject_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    for (condition, band_name), matrix in subject_matrices.items():\n",
    "        filename = f\"{condition}_{band_name}.npy\"\n",
    "        filepath = subject_dir / filename\n",
    "        np.save(filepath, matrix)\n",
    "        print(f\"   💾 Saved {filename} for {subject}\")\n",
    "\n",
    "\n",
    "def process_subject_parallel(subject: str) -> Dict[Tuple[str, str], np.ndarray]:\n",
    "    \"\"\"Process one subject - designed for parallel execution.\"\"\"\n",
    "    # File paths\n",
    "    data_file = BASE_DIR / \"derivatives\" / \"lcmv\" / f\"{subject}_bima_full_off\" / \"difumo_time_courses.npy\"\n",
    "    events_file = BASE_DIR / \"derivatives\" / \"eeg\" / subject / \"bima_DBSOFF\" / f\"{subject}_events_mne_binary-eve.fif\"\n",
    "    event_id_file = BASE_DIR / \"derivatives\" / \"eeg\" / subject / \"bima_DBSOFF\" / f\"{subject}_event_id_binary.json\"\n",
    "    \n",
    "    subject_matrices = {}\n",
    "    \n",
    "    try:\n",
    "        # 🛡️ SAFE LOAD: Avoid mmap to prevent file corruption\n",
    "        data = np.load(data_file)  # Load fully into memory\n",
    "        print(f\"📥 Loaded {data.shape} from {data_file.name}\")\n",
    "\n",
    "        if data.size == 0:\n",
    "            print(f\"⚠️  Empty data in {data_file}\")\n",
    "            return {}\n",
    "\n",
    "        # Ensure (channels, time) format\n",
    "        if data.shape[0] > data.shape[1]:\n",
    "            data = data.T.copy()  # 🚨 COPY to ensure data ownership — critical fix!\n",
    "        else:\n",
    "            data = data.copy()  # Still copy to be safe\n",
    "\n",
    "        events = mne.read_events(events_file, verbose=False)\n",
    "        with open(event_id_file, 'r') as f:\n",
    "            event_id = json.load(f)\n",
    "        \n",
    "        # Create MNE objects with minimal overhead\n",
    "        info = mne.create_info(\n",
    "            ch_names=[f'C{i}' for i in range(N_ROIS)], \n",
    "            sfreq=SFREQ, \n",
    "            ch_types='misc'\n",
    "        )\n",
    "        raw = mne.io.RawArray(data, info, verbose=False)\n",
    "        \n",
    "        # Process all conditions\n",
    "        for condition in CONDITIONS:\n",
    "            if condition not in event_id:\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                # Create epochs with optimized parameters\n",
    "                epochs = mne.Epochs(\n",
    "                    raw, events, {condition: event_id[condition]},\n",
    "                    tmin=0, tmax=1.5, preload=True, baseline=None, \n",
    "                    event_repeated='drop', verbose=False,\n",
    "                    proj=False,  # Skip projection for speed\n",
    "                    reject=None  # Skip rejection for speed\n",
    "                )\n",
    "                \n",
    "                epoch_data = epochs.get_data()\n",
    "                if len(epoch_data) == 0:\n",
    "                    print(f\"⚠️  No epochs for {condition} in {subject}\")\n",
    "                    continue\n",
    "                \n",
    "                # Compute connectivity for all bands at once per condition\n",
    "                for band_name, band_range in BANDS.items():\n",
    "                    matrix = compute_single_connectivity(epoch_data, band_range)\n",
    "                    if matrix is not None:\n",
    "                        subject_matrices[(condition, band_name)] = matrix\n",
    "                    else:\n",
    "                        print(f\"⚠️  Failed to compute {band_name} for {condition} in {subject}\")\n",
    "                        \n",
    "            except Exception as e:\n",
    "                print(f\"⚠️  Epoch creation failed for {condition} in {subject}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Subject {subject} failed: {e}\")\n",
    "        return {}\n",
    "    \n",
    "    return subject_matrices\n",
    "\n",
    "\n",
    "def batch_process_subjects(subjects: List[str]) -> Dict[Tuple[str, str], List[np.ndarray]]:\n",
    "    \"\"\"Process all subjects in parallel and collect matrices + save subject-level.\"\"\"\n",
    "    print(f\"🚀 Processing {len(subjects)} subjects in parallel using {N_JOBS} cores...\")\n",
    "    \n",
    "    all_matrices = defaultdict(list)\n",
    "    \n",
    "    # Process subjects in parallel\n",
    "    with ProcessPoolExecutor(max_workers=N_JOBS) as executor:\n",
    "        # Submit all jobs\n",
    "        future_to_subject = {\n",
    "            executor.submit(process_subject_parallel, subject): subject \n",
    "            for subject in subjects\n",
    "        }\n",
    "        \n",
    "        # Collect results as they complete\n",
    "        completed = 0\n",
    "        for future in as_completed(future_to_subject):\n",
    "            subject = future_to_subject[future]\n",
    "            try:\n",
    "                subject_matrices = future.result()\n",
    "                \n",
    "                # Add matrices to collections\n",
    "                for (condition, band_name), matrix in subject_matrices.items():\n",
    "                    all_matrices[(condition, band_name)].append(matrix)\n",
    "                \n",
    "                # 💾 SAVE SUBJECT-LEVEL MATRICES\n",
    "                save_subject_matrices(subject, subject_matrices, GROUP_OUTPUT_DIR)\n",
    "                \n",
    "                completed += 1\n",
    "                success_count = len(subject_matrices)\n",
    "                print(f\"✅ {subject}: {success_count} matrices ({completed}/{len(subjects)})\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"❌ {subject}: failed with exception ({completed}/{len(subjects)}) — {e}\")\n",
    "                completed += 1\n",
    "    \n",
    "    return dict(all_matrices)\n",
    "\n",
    "\n",
    "def compute_fast_averages(all_matrices: Dict[Tuple[str, str], List[np.ndarray]]) -> Dict[Tuple[str, str], np.ndarray]:\n",
    "    \"\"\"Compute group averages using optimized numpy operations.\"\"\"\n",
    "    print(f\"\\n⚡ Computing group averages...\")\n",
    "    \n",
    "    group_averages = {}\n",
    "    for (condition, band_name), matrix_list in all_matrices.items():\n",
    "        if not matrix_list:\n",
    "            print(f\"⚠️  No data for {condition} {band_name}\")\n",
    "            continue\n",
    "        \n",
    "        # Stack and average in one optimized operation\n",
    "        # Use float32 to reduce memory usage\n",
    "        stacked = np.stack(matrix_list, axis=0, dtype=np.float32)\n",
    "        group_avg = np.mean(stacked, axis=0, dtype=np.float32)\n",
    "        \n",
    "        group_averages[(condition, band_name)] = group_avg\n",
    "        print(f\"   ✅ {condition} {band_name}: {len(matrix_list)} subjects\")\n",
    "    \n",
    "    return group_averages\n",
    "\n",
    "\n",
    "def save_matrices_fast(group_averages: Dict[Tuple[str, str], np.ndarray], roi_names: List[str]) -> None:\n",
    "    \"\"\"Save only the final group average matrices as CSV.\"\"\"\n",
    "    print(f\"\\n💾 Saving {len(group_averages)} group average matrices...\")\n",
    "    \n",
    "    for (condition, band_name), matrix in group_averages.items():\n",
    "        df = pd.DataFrame(matrix, index=roi_names, columns=roi_names)\n",
    "        csv_filename = f\"matrix_{condition}_{band_name}_group_avg.csv\"\n",
    "        csv_filepath = GROUP_OUTPUT_DIR / csv_filename\n",
    "        df.to_csv(csv_filepath, float_format='%.6f')\n",
    "        print(f\"   ✅ {csv_filename}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution with timing.\"\"\"\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(\"Starting ultra-fast group connectivity analysis...\")\n",
    "    \n",
    "    # Load ROI names once\n",
    "    print(\"📥 Loading ROI names...\")\n",
    "    roi_names = load_roi_names()\n",
    "    \n",
    "    # Find subjects\n",
    "    subjects = find_subjects()\n",
    "    if not subjects:\n",
    "        print(\"❌ No valid subjects found.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"🧬 Found {len(subjects)} subjects\")\n",
    "    \n",
    "    # Phase 1: Extract all matrices in parallel\n",
    "    all_matrices = batch_process_subjects(subjects)\n",
    "    \n",
    "    if not all_matrices:\n",
    "        print(\"❌ No matrices computed.\")\n",
    "        return\n",
    "    \n",
    "    # Phase 2: Compute averages\n",
    "    group_averages = compute_fast_averages(all_matrices)\n",
    "    \n",
    "    if not group_averages:\n",
    "        print(\"❌ No group averages computed.\")\n",
    "        return\n",
    "    \n",
    "    # Phase 3: Save CSVs\n",
    "    save_matrices_fast(group_averages, roi_names)\n",
    "    \n",
    "    # Summary\n",
    "    elapsed = time.time() - start_time\n",
    "    total_subjects = sum(len(matrices) for matrices in all_matrices.values())\n",
    "    \n",
    "    print(f\"\\n🎉 Analysis Complete!\")\n",
    "    print(f\"   • Time elapsed: {elapsed:.1f} seconds\")\n",
    "    print(f\"   • Subjects found: {len(subjects)}\")\n",
    "    print(f\"   • Total matrices computed: {total_subjects}\")\n",
    "    print(f\"   • Conditions: {CONDITIONS}\")\n",
    "    print(f\"   • Frequency bands: {list(BANDS.keys())}\")\n",
    "    print(f\"   • Output: {GROUP_OUTPUT_DIR}\")\n",
    "    print(f\"   • Speed: {total_subjects/elapsed:.1f} matrices/second\")\n",
    "    print(f\"   • Subject-level matrices saved in: {GROUP_OUTPUT_DIR / 'subject_level'}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Xtra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
