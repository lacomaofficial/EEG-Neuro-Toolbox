{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba0a5c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 Output directories created:\n",
      "   Statistics: /home/jaizor/jaizor/xtra/derivatives/group/statistics\n",
      "   Matrices: /home/jaizor/jaizor/xtra/derivatives/group/statistics/matrices\n",
      "   Reports: /home/jaizor/jaizor/xtra/derivatives/group/statistics/reports\n",
      "   Figures: /home/jaizor/jaizor/xtra/derivatives/group/statistics/figures\n",
      "🚀 STARTING SIMPLIFIED CONNECTIVITY ANALYSIS\n",
      "============================================================\n",
      "✅ Loaded 512 ROI names from: matrix_InPhase_Alpha_group_avg.csv\n",
      "🧠 Found 12 subjects: ['sub-01', 'sub-02', 'sub-03', 'sub-05', 'sub-06', 'sub-07', 'sub-08', 'sub-09', 'sub-10', 'sub-11', 'sub-12', 'sub-14']\n",
      "✅ Theta: 12 complete subjects\n",
      "✅ Alpha: 12 complete subjects\n",
      "✅ Low_Beta: 12 complete subjects\n",
      "✅ High_Beta: 12 complete subjects\n",
      "✅ Low_Gamma: 12 complete subjects\n",
      "✅ High_Gamma: 12 complete subjects\n",
      "\n",
      "🔬 STATISTICAL ANALYSIS (Top 3 per band, p<0.01)\n",
      "============================================================\n",
      "\n",
      "📊 THETA BAND\n",
      "   📈 Analyzing 12 subjects\n",
      "   🔼 Testing only upper triangle: 131328 connections\n",
      "   🔗 Valid connections: 127260/131328\n",
      "   📊 Uncorrected p<0.01: 1325\n",
      "   📊 Max |t-value|: 5.781\n",
      "\n",
      "📊 ALPHA BAND\n",
      "   📈 Analyzing 12 subjects\n",
      "   🔼 Testing only upper triangle: 131328 connections\n",
      "   🔗 Valid connections: 127260/131328\n",
      "   📊 Uncorrected p<0.01: 544\n",
      "   📊 Max |t-value|: 4.814\n",
      "\n",
      "📊 LOW_BETA BAND\n",
      "   📈 Analyzing 12 subjects\n",
      "   🔼 Testing only upper triangle: 131328 connections\n",
      "   🔗 Valid connections: 127260/131328\n",
      "   📊 Uncorrected p<0.01: 725\n",
      "   📊 Max |t-value|: 6.729\n",
      "\n",
      "📊 HIGH_BETA BAND\n",
      "   📈 Analyzing 12 subjects\n",
      "   🔼 Testing only upper triangle: 131328 connections\n",
      "   🔗 Valid connections: 127260/131328\n",
      "   📊 Uncorrected p<0.01: 2174\n",
      "   📊 Max |t-value|: 6.724\n",
      "\n",
      "📊 LOW_GAMMA BAND\n",
      "   📈 Analyzing 12 subjects\n",
      "   🔼 Testing only upper triangle: 131328 connections\n",
      "   🔗 Valid connections: 127260/131328\n",
      "   📊 Uncorrected p<0.01: 5177\n",
      "   📊 Max |t-value|: 8.447\n",
      "\n",
      "📊 HIGH_GAMMA BAND\n",
      "   📈 Analyzing 12 subjects\n",
      "   🔼 Testing only upper triangle: 131328 connections\n",
      "   🔗 Valid connections: 127260/131328\n",
      "   📊 Uncorrected p<0.01: 239\n",
      "   📊 Max |t-value|: 6.097\n",
      "🎯 Found 18 top-3 connections (p<0.01 uncorrected, ranked by |t|)\n",
      "📊 Comprehensive reports saved to: /home/jaizor/jaizor/xtra/derivatives/group/statistics/reports\n",
      "   🖼️  Saved top-3 plot for Theta\n",
      "   🖼️  Saved top-3 plot for Alpha\n",
      "   🖼️  Saved top-3 plot for Low_Beta\n",
      "   🖼️  Saved top-3 plot for High_Beta\n",
      "   🖼️  Saved top-3 plot for Low_Gamma\n",
      "   🖼️  Saved top-3 plot for High_Gamma\n",
      "📊 Summary visualization saved to: /home/jaizor/jaizor/xtra/derivatives/group/statistics/figures/analysis_summary.png\n",
      "\n",
      "============================================================\n",
      "📊 ANALYSIS COMPLETE - SUMMARY\n",
      "============================================================\n",
      "      Band  N_Subjects  Valid_Connections  Significant_p01  Max_T_Value  Mean_Abs_Difference\n",
      "     Theta          12             127260             1325     5.780873             0.025904\n",
      "     Alpha          12             127260              544     4.814351             0.018108\n",
      "  Low_Beta          12             127260              725     6.728839             0.014467\n",
      " High_Beta          12             127260             2174     6.723581             0.013808\n",
      " Low_Gamma          12             127260             5177     8.447051             0.013604\n",
      "High_Gamma          12             127260              239     6.097148             0.008320\n",
      "\n",
      "🎯 TOP 3 CONNECTIONS (p<0.01):\n",
      "      Band  Rank                                                                                      ROI_1                                                                          ROI_2  T_Value  P_Value  Mean_Difference  Effect_Size_Cohen_d\n",
      "     Theta     1                                                      Parieto-occipital sulcus mid-anterior                                                              Heschl’s gyrus LH 5.780873 0.000123         0.047066             1.668794\n",
      "     Theta     2                                                                     Cerebellum IX inferior                                       Middle temporal gyrus middle anterior LH 5.736804 0.000131         0.042604             1.656073\n",
      "     Theta     3                                                            Insula postero-superior lateral                                                           Corpus callosum genu 5.614056 0.000157         0.050128             1.620638\n",
      "     Alpha     1                                                                          Central sulcus LH                                         Middle temporal gyrus mid-posterior LH 4.814351 0.000541         0.034642             1.389783\n",
      "     Alpha     2                                                                       Pars triangularis LH                                          Superior occipital sulcus superior RH 4.782364 0.000569         0.027118             1.380549\n",
      "     Alpha     3                                                                  Angular gyrus inferior LH                                                     Precentral gyrus middle LH 4.754289 0.000596         0.040767             1.372445\n",
      "  Low_Beta     1                                                            Superior frontal gyrus superior Cerebrospinal fluid (between superior frontal gyrus middle superior and skull) 6.728839 0.000032         0.042786             1.942449\n",
      "  Low_Beta     2                                                                     Cerebellum IX inferior                                                                  Temporal pole 6.515943 0.000043         0.023872             1.880991\n",
      "  Low_Beta     3                                                                              Temporal pole                                                                  Cerebellum VI 6.420995 0.000049         0.023285             1.853582\n",
      " High_Beta     1                                                     Cerebellum IX and cerebellar peduncle                                                                   Cerebellum VI 6.723581 0.000033         0.026383             1.940931\n",
      " High_Beta     2                                                                   Collateral sulcus middle                                                          Cerebellum Crus II RH 6.570002 0.000040         0.021686             1.896596\n",
      " High_Beta     3                                                              Callosal sulcus mid-posterior                                                     Cerebellum Crus I superior 6.070498 0.000081         0.026659             1.752402\n",
      " Low_Gamma     1                                                           Paracingulate gyrus posterior LH                                                        Cerebellum III superior 8.447051 0.000004         0.027457             2.438454\n",
      " Low_Gamma     2 Cerebrospinal fluid (between interhemispheric fissure and superior frontal gyrus superio )                                                          Cerebellum V superior 7.236108 0.000017         0.023308             2.088884\n",
      " Low_Gamma     3                                                                         Cerebral peduncles                                                     Precentral sulcus superior 6.970051 0.000024         0.017437             2.012081\n",
      "High_Gamma     1                                                        Superior frontal gyrus posterior LH                                        Inferior frontal sulcus mid-anterior LH 6.097148 0.000078         0.014094             1.760095\n",
      "High_Gamma     2                                                                       Pars triangularis LH                                         Superior frontal gyrus mid-anterior LH 4.842641 0.000517         0.019455             1.397950\n",
      "High_Gamma     3                                                            Cerebellum Crus II posterior LH                                                       Central sulcus superior  4.746657 0.000603         0.015993             1.370242\n",
      "\n",
      "📁 All outputs saved to:\n",
      "   📊 Statistics: /home/jaizor/jaizor/xtra/derivatives/group/statistics\n",
      "   📈 Matrices: /home/jaizor/jaizor/xtra/derivatives/group/statistics/matrices\n",
      "   📋 Reports: /home/jaizor/jaizor/xtra/derivatives/group/statistics/reports\n",
      "   📊 Figures: /home/jaizor/jaizor/xtra/derivatives/group/statistics/figures\n",
      "   🎯 Top 3: /home/jaizor/jaizor/xtra/derivatives/group/statistics/reports/top3_connections_p01.csv\n",
      "\n",
      "✅ 🎯 ANALYSIS COMPLETED SUCCESSFULLY — Top 3 per band (p<0.01)!\n"
     ]
    }
   ],
   "source": [
    "# Simplified Group Statistics Script\n",
    "\"\"\"\n",
    "- Only paired t-test\n",
    "- Only top 3 connections per band with p < 0.01 (uncorrected)\n",
    "- Clean, publication-ready figures and reports\n",
    "- No multiple comparison corrections\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from scipy.stats import ttest_rel\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict, List, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ===========================\n",
    "# CONFIGURATION\n",
    "# ===========================\n",
    "\n",
    "PROJECT_BASE = '/home/jaizor/jaizor/xtra'\n",
    "GROUP_OUTPUT_DIR = Path(PROJECT_BASE) / \"derivatives\" / \"group\"\n",
    "SUBJECT_MATRICES_DIR = GROUP_OUTPUT_DIR / \"subject_level\"\n",
    "\n",
    "# Create organized output structure\n",
    "STATS_OUTPUT_DIR = GROUP_OUTPUT_DIR / \"statistics\"\n",
    "MATRICES_DIR = STATS_OUTPUT_DIR / \"matrices\"\n",
    "REPORTS_DIR = STATS_OUTPUT_DIR / \"reports\"\n",
    "FIGURES_DIR = STATS_OUTPUT_DIR / \"figures\"\n",
    "\n",
    "# Create directories\n",
    "for dir_path in [STATS_OUTPUT_DIR, MATRICES_DIR, REPORTS_DIR, FIGURES_DIR]:\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "BANDS = [\"Theta\", \"Alpha\", \"Low_Beta\", \"High_Beta\", \"Low_Gamma\", \"High_Gamma\"]\n",
    "CONDITIONS = ['InPhase', 'OutofPhase']\n",
    "N_ROIS = 512\n",
    "MIN_SUBJECT_THRESHOLD = 8  # Minimum subjects needed for analysis\n",
    "\n",
    "print(f\"📁 Output directories created:\")\n",
    "print(f\"   Statistics: {STATS_OUTPUT_DIR}\")\n",
    "print(f\"   Matrices: {MATRICES_DIR}\")\n",
    "print(f\"   Reports: {REPORTS_DIR}\")\n",
    "print(f\"   Figures: {FIGURES_DIR}\")\n",
    "\n",
    "# ===========================\n",
    "# LOAD ROI NAMES WITH FALLBACK\n",
    "# ===========================\n",
    "\n",
    "def load_roi_names() -> List[str]:\n",
    "    \"\"\"Load ROI names with multiple fallback options.\"\"\"\n",
    "    possible_files = [\n",
    "        GROUP_OUTPUT_DIR / \"matrix_InPhase_Alpha_group_avg.csv\",\n",
    "        GROUP_OUTPUT_DIR / \"matrix_OutofPhase_Alpha_group_avg.csv\",\n",
    "        GROUP_OUTPUT_DIR / \"matrix_InPhase_Theta_group_avg.csv\"\n",
    "    ]\n",
    "    \n",
    "    for csv_path in possible_files:\n",
    "        if csv_path.exists():\n",
    "            try:\n",
    "                df = pd.read_csv(csv_path, index_col=0)\n",
    "                roi_names = df.index.tolist()\n",
    "                print(f\"✅ Loaded {len(roi_names)} ROI names from: {csv_path.name}\")\n",
    "                return roi_names\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Error reading {csv_path.name}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    print(\"⚠️ No CSV with ROI names found, creating generic names\")\n",
    "    return [f\"ROI_{i:03d}\" for i in range(N_ROIS)]\n",
    "\n",
    "# ===========================\n",
    "# DATA LOADING\n",
    "# ===========================\n",
    "\n",
    "def load_subject_matrices() -> Dict:\n",
    "    \"\"\"Load and validate subject-level matrices.\"\"\"\n",
    "    if not SUBJECT_MATRICES_DIR.exists():\n",
    "        raise FileNotFoundError(f\"Subject matrices directory not found: {SUBJECT_MATRICES_DIR}\")\n",
    "\n",
    "    subjects = sorted([d.name for d in SUBJECT_MATRICES_DIR.iterdir() \n",
    "                      if d.is_dir() and d.name.startswith('sub-')])\n",
    "    \n",
    "    if len(subjects) < MIN_SUBJECT_THRESHOLD:\n",
    "        raise ValueError(f\"Only {len(subjects)} subjects found, need at least {MIN_SUBJECT_THRESHOLD}\")\n",
    "    \n",
    "    print(f\"🧠 Found {len(subjects)} subjects: {subjects}\")\n",
    "\n",
    "    data = {band: {'InPhase': [], 'OutofPhase': [], 'subjects': []} for band in BANDS}\n",
    "    missing_files = []\n",
    "\n",
    "    for subject in subjects:\n",
    "        subject_dir = SUBJECT_MATRICES_DIR / subject\n",
    "        subject_complete = True\n",
    "        \n",
    "        for condition in CONDITIONS:\n",
    "            for band in BANDS:\n",
    "                file_path = subject_dir / f\"{condition}_{band}.npy\"\n",
    "                if file_path.exists():\n",
    "                    try:\n",
    "                        matrix = np.load(file_path)\n",
    "                        if matrix.shape != (N_ROIS, N_ROIS):\n",
    "                            subject_complete = False\n",
    "                            continue\n",
    "                        if np.any(np.isnan(matrix)) or np.any(np.isinf(matrix)):\n",
    "                            matrix = np.nan_to_num(matrix, nan=0.0, posinf=1.0, neginf=-1.0)\n",
    "                        data[band][condition].append(matrix)\n",
    "                    except Exception as e:\n",
    "                        subject_complete = False\n",
    "                        missing_files.append(str(file_path))\n",
    "                else:\n",
    "                    missing_files.append(str(file_path))\n",
    "                    subject_complete = False\n",
    "        \n",
    "        if subject_complete:\n",
    "            for band in BANDS:\n",
    "                data[band]['subjects'].append(subject)\n",
    "\n",
    "    # Final validation\n",
    "    cleaned_data = {band: {'InPhase': [], 'OutofPhase': [], 'subjects': []} for band in BANDS}\n",
    "    for band in BANDS:\n",
    "        n_in = len(data[band]['InPhase'])\n",
    "        n_out = len(data[band]['OutofPhase'])\n",
    "        n_subjects = len(data[band]['subjects'])\n",
    "        if n_in == n_out == len(subjects):\n",
    "            print(f\"✅ {band}: {n_in} complete subjects\")\n",
    "            cleaned_data[band] = data[band]\n",
    "        else:\n",
    "            print(f\"❌ {band}: incomplete data (In:{n_in}, Out:{n_out}, Expected:{len(subjects)})\")\n",
    "    \n",
    "    if missing_files:\n",
    "        print(f\"\\n⚠️ {len(missing_files)} missing files saved to missing_files.txt\")\n",
    "        with open(REPORTS_DIR / \"missing_files.txt\", 'w') as f:\n",
    "            f.write(\"\\n\".join(missing_files))\n",
    "\n",
    "    return cleaned_data\n",
    "\n",
    "# ===========================\n",
    "# STATISTICAL ANALYSIS — ONLY T-TEST + TOP 3\n",
    "# ===========================\n",
    "\n",
    "def enhanced_statistical_analysis(data: Dict, roi_names: List[str]) -> Dict:\n",
    "    \"\"\"Run paired t-test and extract top 3 connections per band (p<0.01).\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    print(f\"\\n🔬 STATISTICAL ANALYSIS (Top 3 per band, p<0.01)\")\n",
    "    print(f\"=\" * 60)\n",
    "    \n",
    "    for band in BANDS:\n",
    "        if not data[band]['InPhase']:\n",
    "            print(f\"⏭️ Skipping {band} - no data\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\n📊 {band.upper()} BAND\")\n",
    "        \n",
    "        # Stack matrices\n",
    "        inphase = np.stack(data[band]['InPhase'])\n",
    "        outphase = np.stack(data[band]['OutofPhase'])\n",
    "        n_subjects = inphase.shape[0]\n",
    "        \n",
    "        print(f\"   📈 Analyzing {n_subjects} subjects\")\n",
    "        \n",
    "        # Calculate group averages\n",
    "        avg_inphase = np.mean(inphase, axis=0)\n",
    "        avg_outphase = np.mean(outphase, axis=0)\n",
    "        avg_difference = avg_inphase - avg_outphase\n",
    "        \n",
    "        # Flatten for statistical testing (upper triangle only)\n",
    "        n_conn_full = N_ROIS * N_ROIS\n",
    "        in_flat = inphase.reshape(n_subjects, n_conn_full)\n",
    "        out_flat = outphase.reshape(n_subjects, n_conn_full)\n",
    "\n",
    "        # Mask to upper triangle\n",
    "        upper_tri_mask = np.triu(np.ones((N_ROIS, N_ROIS), dtype=bool)).flatten()\n",
    "        in_flat = in_flat[:, upper_tri_mask]\n",
    "        out_flat = out_flat[:, upper_tri_mask]\n",
    "        n_conn = in_flat.shape[1]\n",
    "\n",
    "        print(f\"   🔼 Testing only upper triangle: {n_conn} connections\")\n",
    "        \n",
    "        # Remove connections with zero variance\n",
    "        var_mask = (np.var(in_flat, axis=0) > 1e-10) & (np.var(out_flat, axis=0) > 1e-10)\n",
    "        valid_connections = np.sum(var_mask)\n",
    "        \n",
    "        print(f\"   🔗 Valid connections: {valid_connections}/{n_conn}\")\n",
    "        \n",
    "        if valid_connections == 0:\n",
    "            print(f\"   ❌ No valid connections found for {band}\")\n",
    "            continue\n",
    "        \n",
    "        # Initialize results arrays\n",
    "        t_vals = np.zeros(n_conn)\n",
    "        p_vals = np.ones(n_conn)\n",
    "        \n",
    "        # Paired t-test only on valid connections\n",
    "        valid_in = in_flat[:, var_mask]\n",
    "        valid_out = out_flat[:, var_mask]\n",
    "        t_vals_valid, p_vals_valid = ttest_rel(valid_in, valid_out, axis=0)\n",
    "        \n",
    "        # Fill results\n",
    "        t_vals[var_mask] = t_vals_valid\n",
    "        p_vals[var_mask] = p_vals_valid\n",
    "        \n",
    "        # Initialize full 512x512 matrices\n",
    "        t_matrix = np.zeros((N_ROIS, N_ROIS))\n",
    "        p_matrix = np.ones((N_ROIS, N_ROIS))\n",
    "\n",
    "        # Fill upper triangle\n",
    "        upper_tri_indices = np.triu_indices(N_ROIS)\n",
    "        t_matrix[upper_tri_indices] = t_vals\n",
    "        p_matrix[upper_tri_indices] = p_vals\n",
    "\n",
    "        # Mirror upper triangle to lower for symmetric matrices\n",
    "        t_matrix = t_matrix + t_matrix.T - np.diag(np.diag(t_matrix))\n",
    "        p_matrix = p_matrix + p_matrix.T - np.diag(np.diag(p_matrix))\n",
    "\n",
    "        # Count connections with p < 0.01\n",
    "        n_uncorr = np.sum(p_vals < 0.01)\n",
    "        print(f\"   📊 Uncorrected p<0.01: {n_uncorr}\")\n",
    "        print(f\"   📊 Max |t-value|: {np.max(np.abs(t_vals)):.3f}\")\n",
    "        \n",
    "        # Create DataFrames\n",
    "        df_avg_in = pd.DataFrame(avg_inphase, index=roi_names, columns=roi_names)\n",
    "        df_avg_out = pd.DataFrame(avg_outphase, index=roi_names, columns=roi_names)\n",
    "        df_diff = pd.DataFrame(avg_difference, index=roi_names, columns=roi_names)\n",
    "        df_t = pd.DataFrame(t_matrix, index=roi_names, columns=roi_names)\n",
    "        df_p = pd.DataFrame(p_matrix, index=roi_names, columns=roi_names)\n",
    "        \n",
    "        # Save results\n",
    "        band_dir = MATRICES_DIR / band\n",
    "        band_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        df_avg_in.to_csv(band_dir / f\"{band}_average_inphase.csv\")\n",
    "        df_avg_out.to_csv(band_dir / f\"{band}_average_outphase.csv\")\n",
    "        df_diff.to_csv(band_dir / f\"{band}_difference.csv\")\n",
    "        df_t.to_csv(band_dir / f\"{band}_t_values.csv\")\n",
    "        df_p.to_csv(band_dir / f\"{band}_p_values.csv\")\n",
    "        \n",
    "        np.save(band_dir / f\"{band}_t_values.npy\", t_matrix)\n",
    "        np.save(band_dir / f\"{band}_p_values.npy\", p_matrix)\n",
    "        np.save(band_dir / f\"{band}_difference.npy\", avg_difference)\n",
    "        \n",
    "        # Store results\n",
    "        results[band] = {\n",
    "            'n_subjects': n_subjects,\n",
    "            'average_inphase': avg_inphase,\n",
    "            'average_outphase': avg_outphase,\n",
    "            'difference_matrix': avg_difference,\n",
    "            't_matrix': t_matrix,\n",
    "            'p_matrix': p_matrix,\n",
    "            'n_significant_uncorr': n_uncorr,\n",
    "            'max_t': np.max(np.abs(t_vals)),\n",
    "            'valid_connections': valid_connections,\n",
    "            't_vals_upper': t_vals.copy(),\n",
    "            'p_vals_upper': p_vals.copy(),\n",
    "            'upper_tri_mask': upper_tri_mask\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# ===========================\n",
    "# REPORTING — TOP 3 PER BAND\n",
    "# ===========================\n",
    "\n",
    "def generate_comprehensive_report(results: Dict, roi_names: List[str]):\n",
    "    \"\"\"Generate report with top 3 connections per band (p<0.01).\"\"\"\n",
    "    \n",
    "    summary_data = []\n",
    "    top3_findings = []  # Top 3 per band with p<0.01\n",
    "    \n",
    "    for band, res in results.items():\n",
    "        summary_data.append({\n",
    "            'Band': band,\n",
    "            'N_Subjects': res['n_subjects'],\n",
    "            'Valid_Connections': res['valid_connections'],\n",
    "            'Significant_p01': res['n_significant_uncorr'],\n",
    "            'Max_T_Value': res['max_t'],\n",
    "            'Mean_Abs_Difference': np.mean(np.abs(res['difference_matrix']))\n",
    "        })\n",
    "        \n",
    "        # Extract top 3 by |t| with p<0.01\n",
    "        t_vals_upper = res['t_vals_upper']\n",
    "        p_vals_upper = res['p_vals_upper']\n",
    "        t_abs_upper = np.abs(t_vals_upper)\n",
    "        sorted_indices = np.argsort(t_abs_upper)[::-1]  # descending by |t|\n",
    "\n",
    "        count = 0\n",
    "        for idx in sorted_indices:\n",
    "            if count >= 3:  # Only top 3\n",
    "                break\n",
    "            if p_vals_upper[idx] < 0.01:  # uncorrected p<0.01\n",
    "                upper_tri_indices = np.triu_indices(N_ROIS)\n",
    "                row, col = upper_tri_indices[0][idx], upper_tri_indices[1][idx]\n",
    "                if row == col:\n",
    "                    continue\n",
    "                top3_findings.append({\n",
    "                    'Band': band,\n",
    "                    'Rank': count + 1,\n",
    "                    'ROI_1': roi_names[row],\n",
    "                    'ROI_2': roi_names[col],\n",
    "                    'T_Value': t_vals_upper[idx],\n",
    "                    'P_Value': p_vals_upper[idx],\n",
    "                    'Mean_Difference': res['difference_matrix'][row, col],\n",
    "                    'Effect_Size_Cohen_d': t_vals_upper[idx] / np.sqrt(res['n_subjects'])\n",
    "                })\n",
    "                count += 1\n",
    "\n",
    "    # Save summary report\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    summary_df.to_csv(REPORTS_DIR / \"analysis_summary.csv\", index=False)\n",
    "    \n",
    "    # Save Top-3 findings\n",
    "    if top3_findings:\n",
    "        top3_df = pd.DataFrame(top3_findings)\n",
    "        top3_df.to_csv(REPORTS_DIR / \"top3_connections_p01.csv\", index=False)\n",
    "        print(f\"🎯 Found {len(top3_findings)} top-3 connections (p<0.01 uncorrected, ranked by |t|)\")\n",
    "    else:\n",
    "        print(\"⚠️ No top-3 connections found with p<0.01\")\n",
    "\n",
    "    # Generate text report\n",
    "    with open(REPORTS_DIR / \"analysis_report.txt\", 'w') as f:\n",
    "        f.write(\"SIMPLIFIED CONNECTIVITY ANALYSIS REPORT\\n\")\n",
    "        f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "        f.write(\"ANALYSIS METHOD\\n\")\n",
    "        f.write(\"-\" * 30 + \"\\n\")\n",
    "        f.write(\"Paired t-tests were performed for each connection (InPhase vs OutofPhase).\\n\")\n",
    "        f.write(\"Due to high dimensionality (131K+ tests), no multiple comparison correction was applied.\\n\")\n",
    "        f.write(\"Top 3 connections per band, ranked by absolute t-value and passing p < 0.01, are reported for exploratory analysis.\\n\\n\")\n",
    "        \n",
    "        f.write(\"SUMMARY BY FREQUENCY BAND\\n\")\n",
    "        f.write(\"-\" * 30 + \"\\n\")\n",
    "        for _, row in summary_df.iterrows():\n",
    "            f.write(f\"\\n{row['Band'].upper()} BAND:\\n\")\n",
    "            f.write(f\"  Subjects analyzed: {row['N_Subjects']}\\n\")\n",
    "            f.write(f\"  Valid connections: {row['Valid_Connections']}\\n\")\n",
    "            f.write(f\"  Connections with p<0.01: {row['Significant_p01']}\\n\")\n",
    "            f.write(f\"  Maximum |t-value|: {row['Max_T_Value']:.3f}\\n\")\n",
    "            f.write(f\"  Mean absolute difference: {row['Mean_Abs_Difference']:.6f}\\n\")\n",
    "    \n",
    "    print(f\"📊 Comprehensive reports saved to: {REPORTS_DIR}\")\n",
    "    return summary_df, top3_findings\n",
    "\n",
    "# ===========================\n",
    "# VISUALIZATION — TOP 3 PER BAND\n",
    "# ===========================\n",
    "\n",
    "def plot_top3_connections(results: Dict, roi_names: List[str], top3_findings: List[Dict]):\n",
    "    \"\"\"Plot top 3 connections per band.\"\"\"\n",
    "    for band in BANDS:\n",
    "        if band not in results:\n",
    "            continue\n",
    "            \n",
    "        res = results[band]\n",
    "        # Create mask for top 3 connections\n",
    "        top3_mask = np.zeros((N_ROIS, N_ROIS), dtype=bool)\n",
    "        \n",
    "        # Find top 3 for this band\n",
    "        band_findings = [f for f in top3_findings if f['Band'] == band]\n",
    "        \n",
    "        for finding in band_findings:\n",
    "            # Find ROI indices\n",
    "            row_idx = roi_names.index(finding['ROI_1'])\n",
    "            col_idx = roi_names.index(finding['ROI_2'])\n",
    "            top3_mask[row_idx, col_idx] = True\n",
    "            top3_mask[col_idx, row_idx] = True  # symmetric\n",
    "        \n",
    "        # Plot\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "        im = ax.imshow(\n",
    "            np.where(top3_mask, res['difference_matrix'], np.nan),\n",
    "            cmap='RdBu_r',\n",
    "            aspect='auto',\n",
    "            interpolation='none',\n",
    "            vmin=-np.nanmax(np.abs(res['difference_matrix'])),\n",
    "            vmax=np.nanmax(np.abs(res['difference_matrix']))\n",
    "        )\n",
    "        ax.set_title(f\"{band}: Top 3 Connections (p<0.01 uncorrected)\", fontsize=14, fontweight='bold')\n",
    "        plt.colorbar(im, ax=ax, shrink=0.8, label='Mean Difference (InPhase - OutofPhase)')\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.grid(False)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(FIGURES_DIR / f\"{band}_top3_connections_p01.png\", dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"   🖼️  Saved top-3 plot for {band}\")\n",
    "\n",
    "def create_summary_visualization(results: Dict, top3_counts: Dict):\n",
    "    \"\"\"Create summary visualization.\"\"\"\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    fig.suptitle('Connectivity Analysis Summary\\nTop 3 per band (p<0.01)', fontsize=16)\n",
    "    \n",
    "    bands = list(results.keys())\n",
    "    if not bands:\n",
    "        return\n",
    "    \n",
    "    # Plot 1: Number of p<0.01 connections\n",
    "    p01_counts = [results[band]['n_significant_uncorr'] for band in bands]\n",
    "    axes[0,0].bar(bands, p01_counts, color='#FF6B6B', alpha=0.7)\n",
    "    axes[0,0].set_title('Connections with p<0.01', fontsize=12)\n",
    "    axes[0,0].set_ylabel('Count')\n",
    "    plt.setp(axes[0,0].xaxis.get_majorticklabels(), rotation=45)\n",
    "    \n",
    "    # Plot 2: Maximum t-values\n",
    "    max_t = [results[band]['max_t'] for band in bands]\n",
    "    axes[0,1].bar(bands, max_t, color='#DDA0DD', alpha=0.7)\n",
    "    axes[0,1].set_title('Maximum |t-value|', fontsize=12)\n",
    "    axes[0,1].set_ylabel('t-value')\n",
    "    plt.setp(axes[0,1].xaxis.get_majorticklabels(), rotation=45)\n",
    "    \n",
    "    # Plot 3: Effect sizes\n",
    "    mean_diff = [np.mean(np.abs(results[band]['difference_matrix'])) for band in bands]\n",
    "    axes[1,0].bar(bands, mean_diff, color='#A29BFE', alpha=0.7)\n",
    "    axes[1,0].set_title('Mean Absolute Difference', fontsize=12)\n",
    "    axes[1,0].set_ylabel('Difference')\n",
    "    plt.setp(axes[1,0].xaxis.get_majorticklabels(), rotation=45)\n",
    "    \n",
    "    # Plot 4: Top 3 counts (should be 3 per band, or less if not enough significant)\n",
    "    top3_vals = [top3_counts.get(band, 0) for band in bands]\n",
    "    axes[1,1].bar(bands, top3_vals, color='#FFEAA7', alpha=0.7)\n",
    "    axes[1,1].set_title('Top 3 Connections Found', fontsize=12)\n",
    "    axes[1,1].set_ylabel('Count')\n",
    "    axes[1,1].set_ylim([0, 3])\n",
    "    plt.setp(axes[1,1].xaxis.get_majorticklabels(), rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIGURES_DIR / \"analysis_summary.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"📊 Summary visualization saved to: {FIGURES_DIR}/analysis_summary.png\")\n",
    "\n",
    "# ===========================\n",
    "# MAIN EXECUTION\n",
    "# ===========================\n",
    "\n",
    "def main():\n",
    "    print(\"🚀 STARTING SIMPLIFIED CONNECTIVITY ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        # Load ROI names\n",
    "        roi_names = load_roi_names()\n",
    "        \n",
    "        # Load subject data\n",
    "        data = load_subject_matrices()\n",
    "        \n",
    "        if not any(data[band]['InPhase'] for band in BANDS):\n",
    "            raise ValueError(\"No valid data found for any frequency band\")\n",
    "        \n",
    "        # Run statistical analysis\n",
    "        results = enhanced_statistical_analysis(data, roi_names)\n",
    "        \n",
    "        if not results:\n",
    "            raise ValueError(\"No results generated from statistical analysis\")\n",
    "        \n",
    "        # Generate reports\n",
    "        summary_df, top3_findings = generate_comprehensive_report(results, roi_names)\n",
    "        \n",
    "        # Count top3 per band\n",
    "        top3_counts = {}\n",
    "        for finding in top3_findings:\n",
    "            band = finding['Band']\n",
    "            top3_counts[band] = top3_counts.get(band, 0) + 1\n",
    "        \n",
    "        # Create visualizations\n",
    "        plot_top3_connections(results, roi_names, top3_findings)\n",
    "        create_summary_visualization(results, top3_counts)\n",
    "        \n",
    "        # Final summary\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"📊 ANALYSIS COMPLETE - SUMMARY\")\n",
    "        print(\"=\" * 60)\n",
    "        print(summary_df.to_string(index=False))\n",
    "        \n",
    "        if top3_findings:\n",
    "            print(f\"\\n🎯 TOP 3 CONNECTIONS (p<0.01):\")\n",
    "            top3_df = pd.DataFrame(top3_findings)\n",
    "            print(top3_df.to_string(index=False))\n",
    "        \n",
    "        print(f\"\\n📁 All outputs saved to:\")\n",
    "        print(f\"   📊 Statistics: {STATS_OUTPUT_DIR}\")\n",
    "        print(f\"   📈 Matrices: {MATRICES_DIR}\")\n",
    "        print(f\"   📋 Reports: {REPORTS_DIR}\")\n",
    "        print(f\"   📊 Figures: {FIGURES_DIR}\")\n",
    "        print(f\"   🎯 Top 3: {REPORTS_DIR}/top3_connections_p01.csv\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ ANALYSIS FAILED: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    success = main()\n",
    "    if success:\n",
    "        print(\"\\n✅ 🎯 ANALYSIS COMPLETED SUCCESSFULLY — Top 3 per band (p<0.01)!\")\n",
    "    else:\n",
    "        print(\"\\n❌ ANALYSIS FAILED - CHECK LOGS\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Xtra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
