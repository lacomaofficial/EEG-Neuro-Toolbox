{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64606f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-19 21:56:07,355 - INFO - ðŸš€ Starting optimized brain connectivity visualization...\n",
      "2025-09-19 21:56:07,356 - INFO - Loading DiFuMo 512 atlas...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">fetch_atlas_difumo</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span> Dataset found in <span style=\"color: #800080; text-decoration-color: #800080\">/home/jaizor/nilearn_data/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">difumo_atlases</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34m[\u001b[0m\u001b[34mfetch_atlas_difumo\u001b[0m\u001b[1;34m]\u001b[0m Dataset found in \u001b[35m/home/jaizor/nilearn_data/\u001b[0m\u001b[95mdifumo_atlases\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-19 21:56:07,461 - INFO - Loaded 512 ROI names from atlas\n",
      "2025-09-19 21:56:07,462 - INFO - Computing ROI coordinates...\n",
      "2025-09-19 21:56:18,750 - INFO - Progress: 100/512 ROI coordinates computed\n",
      "2025-09-19 21:56:25,600 - INFO - Progress: 200/512 ROI coordinates computed\n",
      "2025-09-19 21:56:32,942 - INFO - Progress: 300/512 ROI coordinates computed\n",
      "2025-09-19 21:56:39,720 - INFO - Progress: 400/512 ROI coordinates computed\n",
      "2025-09-19 21:56:46,607 - INFO - Progress: 500/512 ROI coordinates computed\n",
      "2025-09-19 21:56:47,578 - INFO - âœ… Loaded 512 ROIs with coordinates\n",
      "2025-09-19 21:56:47,579 - INFO - ðŸŽ¯ Processing top 10 connections per condition:\n",
      "2025-09-19 21:56:47,581 - INFO -    ðŸ”µ BLUE = InPhase\n",
      "2025-09-19 21:56:47,581 - INFO -    ðŸ”´ RED = OutofPhase\n",
      "2025-09-19 21:56:47,582 - INFO - Processing band: Theta\n",
      "2025-09-19 21:56:47,608 - INFO - Loaded matrix InPhase_Theta: shape (512, 512)\n",
      "2025-09-19 21:56:47,631 - INFO - Loaded matrix OutofPhase_Theta: shape (512, 512)\n",
      "2025-09-19 21:56:47,637 - INFO - Saved CSV: /home/jaizor/jaizor/xtra/derivatives/group/top_connections/top_10_per_condition_Theta.csv\n",
      "2025-09-19 21:56:47,637 - INFO - Loading fsaverage mesh...\n",
      "2025-09-19 21:56:47,763 - INFO - Saved HTML: /home/jaizor/jaizor/xtra/derivatives/group/top_connections/html/top_10_per_condition_Theta.html\n",
      "2025-09-19 21:56:47,764 - INFO - Processing band: Alpha\n",
      "2025-09-19 21:56:47,785 - INFO - Loaded matrix InPhase_Alpha: shape (512, 512)\n",
      "2025-09-19 21:56:47,804 - INFO - Loaded matrix OutofPhase_Alpha: shape (512, 512)\n",
      "2025-09-19 21:56:47,809 - INFO - Saved CSV: /home/jaizor/jaizor/xtra/derivatives/group/top_connections/top_10_per_condition_Alpha.csv\n",
      "2025-09-19 21:56:47,851 - INFO - Saved HTML: /home/jaizor/jaizor/xtra/derivatives/group/top_connections/html/top_10_per_condition_Alpha.html\n",
      "2025-09-19 21:56:47,851 - INFO - Processing band: Low_Beta\n",
      "2025-09-19 21:56:47,879 - INFO - Loaded matrix InPhase_Low_Beta: shape (512, 512)\n",
      "2025-09-19 21:56:47,902 - INFO - Loaded matrix OutofPhase_Low_Beta: shape (512, 512)\n",
      "2025-09-19 21:56:47,907 - INFO - Saved CSV: /home/jaizor/jaizor/xtra/derivatives/group/top_connections/top_10_per_condition_Low_Beta.csv\n",
      "2025-09-19 21:56:47,951 - INFO - Saved HTML: /home/jaizor/jaizor/xtra/derivatives/group/top_connections/html/top_10_per_condition_Low_Beta.html\n",
      "2025-09-19 21:56:47,952 - INFO - Processing band: High_Beta\n",
      "2025-09-19 21:56:47,972 - INFO - Loaded matrix InPhase_High_Beta: shape (512, 512)\n",
      "2025-09-19 21:56:47,989 - INFO - Loaded matrix OutofPhase_High_Beta: shape (512, 512)\n",
      "2025-09-19 21:56:47,994 - INFO - Saved CSV: /home/jaizor/jaizor/xtra/derivatives/group/top_connections/top_10_per_condition_High_Beta.csv\n",
      "2025-09-19 21:56:48,036 - INFO - Saved HTML: /home/jaizor/jaizor/xtra/derivatives/group/top_connections/html/top_10_per_condition_High_Beta.html\n",
      "2025-09-19 21:56:48,037 - INFO - Processing band: Low_Gamma\n",
      "2025-09-19 21:56:48,056 - INFO - Loaded matrix InPhase_Low_Gamma: shape (512, 512)\n",
      "2025-09-19 21:56:48,073 - INFO - Loaded matrix OutofPhase_Low_Gamma: shape (512, 512)\n",
      "2025-09-19 21:56:48,077 - INFO - Saved CSV: /home/jaizor/jaizor/xtra/derivatives/group/top_connections/top_10_per_condition_Low_Gamma.csv\n",
      "2025-09-19 21:56:48,119 - INFO - Saved HTML: /home/jaizor/jaizor/xtra/derivatives/group/top_connections/html/top_10_per_condition_Low_Gamma.html\n",
      "2025-09-19 21:56:48,120 - INFO - Processing band: High_Gamma\n",
      "2025-09-19 21:56:48,143 - INFO - Loaded matrix InPhase_High_Gamma: shape (512, 512)\n",
      "2025-09-19 21:56:48,163 - INFO - Loaded matrix OutofPhase_High_Gamma: shape (512, 512)\n",
      "2025-09-19 21:56:48,167 - INFO - Saved CSV: /home/jaizor/jaizor/xtra/derivatives/group/top_connections/top_10_per_condition_High_Gamma.csv\n",
      "2025-09-19 21:56:48,207 - INFO - Saved HTML: /home/jaizor/jaizor/xtra/derivatives/group/top_connections/html/top_10_per_condition_High_Gamma.html\n",
      "2025-09-19 21:56:48,208 - INFO - \n",
      "ðŸŽ‰ Processing complete!\n",
      "2025-09-19 21:56:48,208 - INFO -    â€¢ Successfully processed: 6/6 bands\n",
      "2025-09-19 21:56:48,209 - INFO -    â€¢ Data saved to: /home/jaizor/jaizor/xtra/derivatives/group/top_connections\n",
      "2025-09-19 21:56:48,210 - INFO -    â€¢ Interactive plots: /home/jaizor/jaizor/xtra/derivatives/group/top_connections/html\n",
      "2025-09-19 21:56:48,210 - INFO -    â€¢ Open HTML files in browser to explore\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Visualize top connections\n",
    "\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nilearn import datasets, image\n",
    "from nilearn.plotting.find_cuts import find_xyz_cut_coords\n",
    "from nilearn.image import iter_img\n",
    "from nilearn.datasets import load_fsaverage\n",
    "import plotly.graph_objects as go\n",
    "import warnings\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from functools import lru_cache\n",
    "import logging\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# ===== CONFIGURATION =====\n",
    "PROJECT_BASE = '/home/jaizor/jaizor/xtra'\n",
    "GROUP_OUTPUT_DIR = Path(PROJECT_BASE) / \"derivatives\" / \"group\"\n",
    "OUTPUT_DIR = GROUP_OUTPUT_DIR / \"top_connections\"\n",
    "HTML_OUTPUT_DIR = OUTPUT_DIR / \"html\"\n",
    "\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "HTML_OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "BANDS = [\"Theta\", \"Alpha\", \"Low_Beta\", \"High_Beta\", \"Low_Gamma\", \"High_Gamma\"]\n",
    "CONDITIONS = ['InPhase', 'OutofPhase']\n",
    "N_TOP = 10\n",
    "\n",
    "# Color scheme\n",
    "CONDITION_COLORS = {\n",
    "    'InPhase': '#1f77b4',     # Blue\n",
    "    'OutofPhase': '#d62728'   # Red\n",
    "}\n",
    "\n",
    "# ===== CACHED DATA LOADING =====\n",
    "@lru_cache(maxsize=1)\n",
    "def get_difumo_atlas():\n",
    "    \"\"\"Cache atlas loading to avoid repeated downloads\"\"\"\n",
    "    logger.info(\"Loading DiFuMo 512 atlas...\")\n",
    "    return datasets.fetch_atlas_difumo(dimension=512, resolution_mm=2)\n",
    "\n",
    "@lru_cache(maxsize=1)\n",
    "def get_roi_coords():\n",
    "    \"\"\"Optimized ROI coordinate computation with progress tracking\"\"\"\n",
    "    logger.info(\"Computing ROI coordinates...\")\n",
    "    atlas = get_difumo_atlas()\n",
    "    atlas_img = atlas[\"maps\"]\n",
    "    \n",
    "    roi_coords = []\n",
    "    total_rois = 512\n",
    "    \n",
    "    for i, roi_img in enumerate(iter_img(atlas_img)):\n",
    "        try:\n",
    "            coord = find_xyz_cut_coords(roi_img, activation_threshold=0.1)\n",
    "            roi_coords.append(coord)\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Failed to compute coordinates for ROI {i}: {e}\")\n",
    "            roi_coords.append([0, 0, 0])  # Fallback coordinates\n",
    "        \n",
    "        if (i + 1) % 100 == 0:\n",
    "            logger.info(f\"Progress: {i+1}/{total_rois} ROI coordinates computed\")\n",
    "    \n",
    "    return np.array(roi_coords)\n",
    "\n",
    "@lru_cache(maxsize=1)\n",
    "def get_roi_names():\n",
    "    \"\"\"Load and clean ROI names\"\"\"\n",
    "    try:\n",
    "        atlas = get_difumo_atlas()\n",
    "        roi_names = atlas.labels['difumo_names'].astype(str).tolist()\n",
    "        logger.info(f\"Loaded {len(roi_names)} ROI names from atlas\")\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Failed to load ROI names: {e}, using generic names\")\n",
    "        roi_names = [f\"Component_{i:03d}\" for i in range(512)]\n",
    "    \n",
    "    # Clean names for CSV compatibility\n",
    "    cleaned_names = []\n",
    "    for name in roi_names:\n",
    "        cleaned = name.replace(',', ';').replace('\\n', ' ').replace('\\r', ' ').strip()\n",
    "        cleaned_names.append(cleaned)\n",
    "    \n",
    "    return cleaned_names\n",
    "\n",
    "@lru_cache(maxsize=1)\n",
    "def get_fsaverage_mesh():\n",
    "    \"\"\"Cache fsaverage mesh loading\"\"\"\n",
    "    logger.info(\"Loading fsaverage mesh...\")\n",
    "    return load_fsaverage(mesh='fsaverage5')\n",
    "\n",
    "# ===== OPTIMIZED MATRIX OPERATIONS =====\n",
    "def load_matrix(condition, band):\n",
    "    \"\"\"Load connectivity matrix with error handling\"\"\"\n",
    "    fname = GROUP_OUTPUT_DIR / f\"matrix_{condition}_{band}_group_avg.csv\"\n",
    "    if not fname.exists():\n",
    "        raise FileNotFoundError(f\"Missing matrix: {fname}\")\n",
    "    \n",
    "    try:\n",
    "        matrix = pd.read_csv(fname, index_col=0).values.astype(np.float32)\n",
    "        logger.info(f\"Loaded matrix {condition}_{band}: shape {matrix.shape}\")\n",
    "        return matrix\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error loading matrix {fname}: {e}\")\n",
    "\n",
    "def extract_top_edges_vectorized(matrix, condition, band, roi_names, top_n=N_TOP):\n",
    "    \"\"\"Vectorized extraction of top edges - much faster than loops\"\"\"\n",
    "    n_rois = len(roi_names)\n",
    "    \n",
    "    # Get upper triangle indices (excluding diagonal)\n",
    "    i_indices, j_indices = np.triu_indices(n_rois, k=1)\n",
    "    \n",
    "    # Extract upper triangle values\n",
    "    upper_triangle_values = matrix[i_indices, j_indices]\n",
    "    \n",
    "    # Handle NaN/inf values\n",
    "    valid_mask = np.isfinite(upper_triangle_values)\n",
    "    if not np.any(valid_mask):\n",
    "        logger.warning(f\"No valid connections found for {condition}_{band}\")\n",
    "        return []\n",
    "    \n",
    "    # Apply mask to get valid indices and values\n",
    "    valid_values = upper_triangle_values[valid_mask]\n",
    "    valid_i = i_indices[valid_mask]\n",
    "    valid_j = j_indices[valid_mask]\n",
    "    \n",
    "    # Get top N indices based on absolute values for stability\n",
    "    top_indices = np.argpartition(np.abs(valid_values), -top_n)[-top_n:]\n",
    "    \n",
    "    # Sort by actual values (descending)\n",
    "    sorted_top_indices = top_indices[np.argsort(valid_values[top_indices])[::-1]]\n",
    "    \n",
    "    edges = []\n",
    "    for idx in sorted_top_indices:\n",
    "        i, j = valid_i[idx], valid_j[idx]\n",
    "        weight = valid_values[idx]\n",
    "        edges.append({\n",
    "            'Marker1': roi_names[i],\n",
    "            'Marker2': roi_names[j],\n",
    "            'Stability': float(weight),  # Ensure JSON serializable\n",
    "            'Band': band,\n",
    "            'Condition': condition,\n",
    "            'ROI1_Index': int(i),\n",
    "            'ROI2_Index': int(j)\n",
    "        })\n",
    "    \n",
    "    return edges\n",
    "\n",
    "# ===== OPTIMIZED COORDINATE MATCHING =====\n",
    "def create_region_lookup(roi_names):\n",
    "    \"\"\"Create efficient lookup for region matching\"\"\"\n",
    "    lookup = {}\n",
    "    for i, name in enumerate(roi_names):\n",
    "        # Create multiple lookup keys for better matching\n",
    "        clean_name = name.lower().replace('-', ' ').replace('_', ' ')\n",
    "        words = clean_name.split()\n",
    "        \n",
    "        # Full name\n",
    "        lookup[name] = i\n",
    "        lookup[clean_name] = i\n",
    "        \n",
    "        # Individual words for partial matching\n",
    "        for word in words:\n",
    "            if len(word) > 2:  # Skip very short words\n",
    "                if word not in lookup:\n",
    "                    lookup[word] = []\n",
    "                if isinstance(lookup[word], int):\n",
    "                    lookup[word] = [lookup[word]]\n",
    "                if isinstance(lookup[word], list) and i not in lookup[word]:\n",
    "                    lookup[word].append(i)\n",
    "    \n",
    "    return lookup\n",
    "\n",
    "def get_coordinates_for_regions_optimized(regions, roi_coords, roi_names):\n",
    "    \"\"\"Optimized coordinate matching with fallbacks\"\"\"\n",
    "    lookup = create_region_lookup(roi_names)\n",
    "    coordinates = []\n",
    "    matched_labels = []\n",
    "    \n",
    "    for region in regions:\n",
    "        clean_region = region.lower().replace('-', ' ').replace('_', ' ')\n",
    "        \n",
    "        # Try exact match first\n",
    "        if region in lookup:\n",
    "            idx = lookup[region] if isinstance(lookup[region], int) else lookup[region][0]\n",
    "            coordinates.append(roi_coords[idx])\n",
    "            matched_labels.append(roi_names[idx])\n",
    "            continue\n",
    "        \n",
    "        # Try cleaned match\n",
    "        if clean_region in lookup:\n",
    "            idx = lookup[clean_region] if isinstance(lookup[clean_region], int) else lookup[clean_region][0]\n",
    "            coordinates.append(roi_coords[idx])\n",
    "            matched_labels.append(roi_names[idx])\n",
    "            continue\n",
    "        \n",
    "        # Try word-based matching\n",
    "        region_words = clean_region.split()\n",
    "        best_match_idx = None\n",
    "        best_score = 0\n",
    "        \n",
    "        for word in region_words:\n",
    "            if word in lookup and isinstance(lookup[word], list):\n",
    "                for candidate_idx in lookup[word]:\n",
    "                    candidate_words = set(roi_names[candidate_idx].lower().split())\n",
    "                    region_word_set = set(region_words)\n",
    "                    \n",
    "                    intersection = region_word_set & candidate_words\n",
    "                    union = region_word_set | candidate_words\n",
    "                    \n",
    "                    if union:\n",
    "                        score = len(intersection) / len(union)\n",
    "                        if score > best_score:\n",
    "                            best_score = score\n",
    "                            best_match_idx = candidate_idx\n",
    "        \n",
    "        if best_match_idx is not None and best_score > 0.2:\n",
    "            coordinates.append(roi_coords[best_match_idx])\n",
    "            matched_labels.append(roi_names[best_match_idx])\n",
    "        else:\n",
    "            # Fallback to origin with warning\n",
    "            logger.warning(f\"No match found for region: {region}\")\n",
    "            coordinates.append([0, 0, 0])\n",
    "            matched_labels.append(region)\n",
    "    \n",
    "    return np.array(coordinates), matched_labels\n",
    "\n",
    "# ===== SCIENTIFIC ABBREVIATIONS =====\n",
    "SCIENTIFIC_ABBREVIATIONS = {\n",
    "    'ventromedial prefrontal cortex': 'vmPFC',\n",
    "    'ventromedial prefrontal': 'vmPFC',\n",
    "    'middle frontal gyrus': 'DLPFC',\n",
    "    'middle frontal': 'MFG',\n",
    "    'precentral gyrus': 'M1',\n",
    "    'precentral': 'M1',\n",
    "    'superior frontal gyrus': 'SFG',\n",
    "    'superior frontal': 'SFG',\n",
    "    'central sulcus': 'CS',\n",
    "    'globus pallidus': 'GP',\n",
    "    'amygdala': 'Amyg',\n",
    "    'caudate': 'Caud',\n",
    "    'cerebellum': 'Cereb',\n",
    "    'midbrain': 'MB',\n",
    "    'hippocampus': 'Hipp',\n",
    "    'thalamus': 'Thal',\n",
    "    'putamen': 'Put',\n",
    "    'insula': 'Ins'\n",
    "}\n",
    "\n",
    "def abbreviate_region_name(name, max_length=15):\n",
    "    \"\"\"Improved region name abbreviation\"\"\"\n",
    "    name_lower = name.lower()\n",
    "    \n",
    "    # Check for scientific abbreviations\n",
    "    for full_term, abbrev in SCIENTIFIC_ABBREVIATIONS.items():\n",
    "        if full_term in name_lower:\n",
    "            return abbrev\n",
    "    \n",
    "    # If still too long, truncate intelligently\n",
    "    if len(name) > max_length:\n",
    "        # Try to keep meaningful parts\n",
    "        words = name.split()\n",
    "        if len(words) > 1:\n",
    "            # Take first letters of each word\n",
    "            abbrev = ''.join(word[0].upper() for word in words if word)\n",
    "            if len(abbrev) <= max_length:\n",
    "                return abbrev\n",
    "        \n",
    "        # Simple truncation\n",
    "        return name[:max_length-2] + '..'\n",
    "    \n",
    "    return name\n",
    "\n",
    "# ===== OPTIMIZED PLOTLY VISUALIZATION =====\n",
    "def create_optimized_connectome(df_edges, roi_coords, roi_names, fsaverage_mesh, \n",
    "                              title=\"Top Connections by Condition\", brain_opacity=0.1):\n",
    "    \"\"\"Optimized 3D brain visualization\"\"\"\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Prepare brain surface\n",
    "    mesh = fsaverage_mesh.pial\n",
    "    vertices_lh = mesh.parts['left'].coordinates\n",
    "    vertices_rh = mesh.parts['right'].coordinates\n",
    "    vertices = np.vstack([vertices_lh, vertices_rh])\n",
    "    \n",
    "    faces_lh = mesh.parts['left'].faces\n",
    "    faces_rh = mesh.parts['right'].faces + len(vertices_lh)\n",
    "    faces = np.vstack([faces_lh, faces_rh])\n",
    "    \n",
    "    # Add brain surface\n",
    "    fig.add_trace(go.Mesh3d(\n",
    "        x=vertices[:, 0], y=vertices[:, 1], z=vertices[:, 2],\n",
    "        i=faces[:, 0], j=faces[:, 1], k=faces[:, 2],\n",
    "        color=f'rgba(200, 200, 200, {brain_opacity})',\n",
    "        flatshading=True,\n",
    "        name='Cortical Surface',\n",
    "        hoverinfo='skip',\n",
    "        showlegend=False,\n",
    "        lighting=dict(ambient=0.4, diffuse=0.7, fresnel=0.1, specular=0.2, roughness=0.3),\n",
    "        lightposition=dict(x=100, y=100, z=200)\n",
    "    ))\n",
    "    \n",
    "    # Get unique regions and their coordinates\n",
    "    unique_regions = pd.unique(df_edges[['Marker1', 'Marker2']].values.ravel())\n",
    "    marker_coords, matched_labels = get_coordinates_for_regions_optimized(\n",
    "        unique_regions, roi_coords, roi_names)\n",
    "    \n",
    "    region_to_coord = dict(zip(matched_labels, marker_coords))\n",
    "    \n",
    "    # Calculate node properties\n",
    "    node_stats = {}\n",
    "    for _, row in df_edges.iterrows():\n",
    "        for marker in [row['Marker1'], row['Marker2']]:\n",
    "            if marker not in node_stats:\n",
    "                node_stats[marker] = {'connections': 0, 'max_stability': 0, 'conditions': set()}\n",
    "            node_stats[marker]['connections'] += 1\n",
    "            node_stats[marker]['max_stability'] = max(node_stats[marker]['max_stability'], abs(row['Stability']))\n",
    "            node_stats[marker]['conditions'].add(row['Condition'])\n",
    "    \n",
    "    # Prepare node visualization\n",
    "    node_coords = []\n",
    "    node_sizes = []\n",
    "    node_colors = []\n",
    "    node_labels = []\n",
    "    node_hover_texts = []\n",
    "    \n",
    "    max_connections = max([stats['connections'] for stats in node_stats.values()]) if node_stats else 1\n",
    "    \n",
    "    for region in matched_labels:\n",
    "        if region in region_to_coord:\n",
    "            coord = region_to_coord[region]\n",
    "            node_coords.append(coord)\n",
    "            \n",
    "            stats = node_stats.get(region, {'connections': 0, 'max_stability': 0, 'conditions': set()})\n",
    "            \n",
    "            # Node size based on connections\n",
    "            size_factor = stats['connections'] / max_connections\n",
    "            size = 8 + 12 * size_factor\n",
    "            node_sizes.append(size)\n",
    "            \n",
    "            # Node color based on stability\n",
    "            stability_intensity = min(255, int(100 + 155 * stats['max_stability']))\n",
    "            node_colors.append(f'rgb({stability_intensity}, {stability_intensity}, {stability_intensity})')\n",
    "            \n",
    "            # Labels and hover\n",
    "            abbrev_label = abbreviate_region_name(region)\n",
    "            node_labels.append(abbrev_label)\n",
    "            \n",
    "            conditions_str = ', '.join(sorted(stats['conditions']))\n",
    "            hover_text = (f\"<b>{region}</b><br>\"\n",
    "                         f\"Connections: {stats['connections']}<br>\"\n",
    "                         f\"Max Stability: {stats['max_stability']:.3f}<br>\"\n",
    "                         f\"Conditions: {conditions_str}\")\n",
    "            node_hover_texts.append(hover_text)\n",
    "    \n",
    "    if node_coords:\n",
    "        node_coords = np.array(node_coords)\n",
    "        \n",
    "        # Add nodes\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=node_coords[:, 0], y=node_coords[:, 1], z=node_coords[:, 2],\n",
    "            mode='markers+text',\n",
    "            marker=dict(\n",
    "                size=node_sizes, \n",
    "                color=node_colors,\n",
    "                line=dict(width=1, color='black'),\n",
    "                opacity=0.9\n",
    "            ),\n",
    "            text=node_labels,\n",
    "            textfont=dict(size=14, color='black', family=\"Arial Bold\"),\n",
    "            textposition='top center',\n",
    "            hovertext=node_hover_texts,\n",
    "            hoverinfo='text',\n",
    "            name='Brain Regions',\n",
    "            showlegend=False\n",
    "        ))\n",
    "    \n",
    "    # Add edges grouped by condition\n",
    "    for condition in CONDITIONS:\n",
    "        condition_edges = df_edges[df_edges['Condition'] == condition]\n",
    "        if condition_edges.empty:\n",
    "            continue\n",
    "        \n",
    "        edge_x, edge_y, edge_z = [], [], []\n",
    "        edge_hover_texts = []\n",
    "        \n",
    "        for _, row in condition_edges.iterrows():\n",
    "            marker1, marker2 = row['Marker1'], row['Marker2']\n",
    "            \n",
    "            if marker1 in region_to_coord and marker2 in region_to_coord:\n",
    "                coord1 = region_to_coord[marker1]\n",
    "                coord2 = region_to_coord[marker2]\n",
    "                \n",
    "                edge_x.extend([coord1[0], coord2[0], None])\n",
    "                edge_y.extend([coord1[1], coord2[1], None])\n",
    "                edge_z.extend([coord1[2], coord2[2], None])\n",
    "                \n",
    "                hover_text = (f\"<b>{marker1} â†” {marker2}</b><br>\"\n",
    "                             f\"Weight: {row['Stability']:.4f}<br>\"\n",
    "                             f\"Band: {row['Band']}<br>\"\n",
    "                             f\"Condition: {condition}\")\n",
    "                edge_hover_texts.extend([hover_text, hover_text, \"\"])\n",
    "        \n",
    "        if edge_x:  # Only add trace if there are valid edges\n",
    "            fig.add_trace(go.Scatter3d(\n",
    "                x=edge_x, y=edge_y, z=edge_z,\n",
    "                mode='lines',\n",
    "                line=dict(color=CONDITION_COLORS[condition], width=5),\n",
    "                opacity=0.8,\n",
    "                name=f'{condition} (Top {N_TOP})',\n",
    "                showlegend=True,\n",
    "                hovertext=edge_hover_texts,\n",
    "                hoverinfo='text'\n",
    "            ))\n",
    "    \n",
    "    # Optimized layout\n",
    "    fig.update_layout(\n",
    "        title=dict(\n",
    "            text=f'<b>{title}</b>',\n",
    "            x=0.5, y=0.95,\n",
    "            font=dict(size=16, family=\"Arial\", color='black')\n",
    "        ),\n",
    "        paper_bgcolor='white',\n",
    "        plot_bgcolor='white',\n",
    "        scene=dict(\n",
    "            bgcolor='white',\n",
    "            xaxis=dict(visible=False),\n",
    "            yaxis=dict(visible=False),\n",
    "            zaxis=dict(visible=False),\n",
    "            aspectmode='data',\n",
    "            camera=dict(eye=dict(x=1.3, y=1.3, z=0.8))\n",
    "        ),\n",
    "        legend=dict(\n",
    "            orientation=\"v\",\n",
    "            yanchor=\"top\", y=0.98,\n",
    "            xanchor=\"left\", x=0.02,\n",
    "            bgcolor=\"rgba(255, 255, 255, 0.9)\",\n",
    "            bordercolor=\"black\",\n",
    "            borderwidth=1,\n",
    "            font=dict(size=11, family=\"Arial\"),\n",
    "            title=dict(text=\"<b>Conditions</b>\", font=dict(size=12))\n",
    "        ),\n",
    "        margin=dict(l=10, r=10, b=10, t=50),\n",
    "        height=800,\n",
    "        width=1000\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# ===== MAIN PROCESSING FUNCTIONS =====\n",
    "def process_band(band, roi_coords, roi_names):\n",
    "    \"\"\"Process a single frequency band\"\"\"\n",
    "    logger.info(f\"Processing band: {band}\")\n",
    "    \n",
    "    try:\n",
    "        # Load matrices\n",
    "        matrix_in = load_matrix(\"InPhase\", band)\n",
    "        matrix_out = load_matrix(\"OutofPhase\", band)\n",
    "        \n",
    "        # Validate matrix dimensions\n",
    "        expected_size = len(roi_names)\n",
    "        if matrix_in.shape != (expected_size, expected_size) or matrix_out.shape != (expected_size, expected_size):\n",
    "            raise ValueError(f\"Matrix size mismatch for {band}. Expected {expected_size}x{expected_size}\")\n",
    "        \n",
    "        # Extract top edges\n",
    "        top_in = extract_top_edges_vectorized(matrix_in, 'InPhase', band, roi_names, N_TOP)\n",
    "        top_out = extract_top_edges_vectorized(matrix_out, 'OutofPhase', band, roi_names, N_TOP)\n",
    "        \n",
    "        if not top_in and not top_out:\n",
    "            logger.warning(f\"No valid connections found for {band}\")\n",
    "            return False\n",
    "        \n",
    "        # Combine and create DataFrame\n",
    "        all_edges = top_in + top_out\n",
    "        df_edges = pd.DataFrame(all_edges)\n",
    "        \n",
    "        # Save CSV\n",
    "        csv_path = OUTPUT_DIR / f\"top_{N_TOP}_per_condition_{band}.csv\"\n",
    "        df_edges.to_csv(csv_path, index=False)\n",
    "        logger.info(f\"Saved CSV: {csv_path}\")\n",
    "        \n",
    "        # Generate 3D plot\n",
    "        try:\n",
    "            fsaverage = get_fsaverage_mesh()\n",
    "            fig_3d = create_optimized_connectome(\n",
    "                df_edges=df_edges,\n",
    "                roi_coords=roi_coords,\n",
    "                roi_names=roi_names,\n",
    "                fsaverage_mesh=fsaverage,\n",
    "                title=f\"Top {N_TOP} Connections: {band} Band\"\n",
    "            )\n",
    "            \n",
    "            html_path = HTML_OUTPUT_DIR / f\"top_{N_TOP}_per_condition_{band}.html\"\n",
    "            fig_3d.write_html(html_path, include_plotlyjs='cdn')\n",
    "            logger.info(f\"Saved HTML: {html_path}\")\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to generate plot for {band}: {e}\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to process {band}: {e}\")\n",
    "        return False\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function with parallel processing\"\"\"\n",
    "    logger.info(\"ðŸš€ Starting optimized brain connectivity visualization...\")\n",
    "    \n",
    "    try:\n",
    "        # Load cached data\n",
    "        roi_names = get_roi_names()\n",
    "        roi_coords = get_roi_coords()\n",
    "        \n",
    "        logger.info(f\"âœ… Loaded {len(roi_names)} ROIs with coordinates\")\n",
    "        logger.info(f\"ðŸŽ¯ Processing top {N_TOP} connections per condition:\")\n",
    "        logger.info(\"   ðŸ”µ BLUE = InPhase\")\n",
    "        logger.info(\"   ðŸ”´ RED = OutofPhase\")\n",
    "        \n",
    "        # Process bands with optional parallel processing\n",
    "        successful_bands = 0\n",
    "        \n",
    "        # Sequential processing for better error handling\n",
    "        for band in BANDS:\n",
    "            success = process_band(band, roi_coords, roi_names)\n",
    "            if success:\n",
    "                successful_bands += 1\n",
    "        \n",
    "        # Summary\n",
    "        logger.info(f\"\\nðŸŽ‰ Processing complete!\")\n",
    "        logger.info(f\"   â€¢ Successfully processed: {successful_bands}/{len(BANDS)} bands\")\n",
    "        logger.info(f\"   â€¢ Data saved to: {OUTPUT_DIR}\")\n",
    "        logger.info(f\"   â€¢ Interactive plots: {HTML_OUTPUT_DIR}\")\n",
    "        logger.info(f\"   â€¢ Open HTML files in browser to explore\")\n",
    "        \n",
    "        if successful_bands == 0:\n",
    "            logger.error(\"No bands were processed successfully. Check input data and paths.\")\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fatal error in main execution: {e}\")\n",
    "        return False\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    success = main()\n",
    "    exit(0 if success else 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Xtra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
