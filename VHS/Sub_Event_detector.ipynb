{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fcbb1a0",
   "metadata": {},
   "source": [
    "## Single Subject  VIDEO EVENT DETECTOR\n",
    "Incorporates balanced event detection, enhanced trial plotting, and MNE format saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71eccab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Libraries ---\n",
    "import mne\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import savgol_filter, hilbert, butter, filtfilt\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.ndimage import uniform_filter1d\n",
    "from matplotlib.lines import Line2D\n",
    "import warnings\n",
    "import shutil\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# === Coordination Analyzer Class ===\n",
    "class CoordinationAnalyzer:\n",
    "    \"\"\"Enhanced coordination analysis with improved event detection and plotting\"\"\"\n",
    "    def __init__(self, subject_id, config=None):\n",
    "        self.subject_id = subject_id\n",
    "        self.config = self._get_default_config()\n",
    "        if config:\n",
    "            self.config.update(config)\n",
    "        # Data storage\n",
    "        self.times = None\n",
    "        self.right_x = None\n",
    "        self.left_x = None\n",
    "        self.event_df = None\n",
    "        self.trials_df = None\n",
    "        # Preprocessing results\n",
    "        self.right_x_smooth = None\n",
    "        self.left_x_smooth = None\n",
    "        self.right_x_filtered = None\n",
    "        self.left_x_filtered = None\n",
    "        self.right_vel = None\n",
    "        self.left_vel = None\n",
    "        # Analysis results\n",
    "        self.phase_diff_wrapped = None\n",
    "        self.coordination_index = None\n",
    "        self.coord_smooth = None\n",
    "        self.std_coord = None\n",
    "\n",
    "    def _get_default_config(self):\n",
    "        return {\n",
    "            'keypoint_index': 8,\n",
    "            'sample_rate': 60.0,\n",
    "            'window_sec': 0.5,\n",
    "            'anti_phase_threshold_rad': 5 * np.pi / 6,\n",
    "            'breakdown_std_threshold': 0.60,\n",
    "            'window_size_ratio': 0.5,\n",
    "            'initial_window_ratio': 1.0,\n",
    "            'grouping_window_ratio': 0.5,\n",
    "            'trial_gap_threshold_s': 2.5,\n",
    "            'extension_duration_s': 4.3,\n",
    "            'eeg_to_behavior_delay': 0.0,\n",
    "            'filter_lowcut': 0.5,\n",
    "            'filter_highcut': 10.0,\n",
    "            'stim_channels': ['TT140', 'TT255', '1a', '2a', '3a', '4a', '5a', '6a'],\n",
    "            'pacing_channels': ['1a', '2a', '3a', '4a', '5a', '6a'],\n",
    "            'target_in_phase_events': 280  # NEW: Target number for balanced sampling\n",
    "        }\n",
    "\n",
    "    def load_behavioral_data(self, file_path):\n",
    "        \"\"\"Load and preprocess behavioral keypoint data\"\"\"\n",
    "        print(f\"Loading behavioral data for {self.subject_id}...\")\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        # Extract data\n",
    "        times, right_x, left_x = [], [], []\n",
    "        for frame in data['instance_info']:\n",
    "            t = frame['frame_id'] / self.config['sample_rate']\n",
    "            times.append(t)\n",
    "            rx, lx = np.nan, np.nan\n",
    "            for inst in frame['instances']:\n",
    "                label = inst['label']\n",
    "                kpts = inst['keypoints']\n",
    "                if self.config['keypoint_index'] < len(kpts):\n",
    "                    x, y = kpts[self.config['keypoint_index']]\n",
    "                    if label == \"Right\":\n",
    "                        rx = x\n",
    "                    elif label == \"Left\":\n",
    "                        lx = x\n",
    "            right_x.append(rx)\n",
    "            left_x.append(lx)\n",
    "        self.times = np.array(times)\n",
    "        self.right_x = np.array(right_x)\n",
    "        self.left_x = np.array(left_x)\n",
    "        print(f\"✓ Loaded {len(self.times)} frames, duration: {self.times[-1]:.1f}s\")\n",
    "        return self\n",
    "\n",
    "    def preprocess_signals(self):\n",
    "        \"\"\"Enhanced preprocessing with better filtering\"\"\"\n",
    "        # Interpolate missing values\n",
    "        self.right_x_smooth = self._interpolate_and_smooth(self.right_x)\n",
    "        self.left_x_smooth = self._interpolate_and_smooth(self.left_x)\n",
    "        # Apply bandpass filter (IMPROVED)\n",
    "        self.right_x_filtered = self._bandpass_filter(self.right_x_smooth)\n",
    "        self.left_x_filtered = self._bandpass_filter(self.left_x_smooth)\n",
    "        # Compute velocities\n",
    "        self.right_vel = self._compute_velocity(self.right_x_smooth)\n",
    "        self.left_vel = self._compute_velocity(self.left_x_smooth)\n",
    "        return self\n",
    "\n",
    "    def _interpolate_and_smooth(self, x):\n",
    "        \"\"\"Interpolate NaN values and apply smoothing\"\"\"\n",
    "        valid = ~np.isnan(x)\n",
    "        if np.sum(valid) < 2:\n",
    "            return np.zeros_like(self.times) * np.nan\n",
    "        f = interp1d(self.times[valid], x[valid], kind='linear', fill_value='extrapolate')\n",
    "        x_interp = f(self.times)\n",
    "        window = min(int(self.config['window_sec'] * self.config['sample_rate']) | 1, len(self.times) // 4)\n",
    "        return savgol_filter(x_interp, window_length=window, polyorder=3)\n",
    "\n",
    "    def _bandpass_filter(self, data):\n",
    "        \"\"\"Enhanced bandpass filter with better error handling\"\"\"\n",
    "        try:\n",
    "            nyquist = 0.5 * self.config['sample_rate']\n",
    "            low = self.config['filter_lowcut'] / nyquist\n",
    "            high = self.config['filter_highcut'] / nyquist\n",
    "            if low <= 0 or high >= 1 or low >= high:\n",
    "                print(f\"⚠️ Invalid filter frequencies for {self.subject_id}, using unfiltered data\")\n",
    "                return data\n",
    "            b, a = butter(5, [low, high], btype='band')\n",
    "            return filtfilt(b, a, data)\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Filter failed for {self.subject_id}: {e}, using unfiltered data\")\n",
    "            return data\n",
    "\n",
    "    def _compute_velocity(self, pos):\n",
    "        \"\"\"Compute and smooth velocity\"\"\"\n",
    "        vel = np.gradient(pos, self.times)\n",
    "        window = min(int(self.config['window_sec'] * self.config['sample_rate']) | 1, len(self.times) // 4)\n",
    "        return savgol_filter(vel, window_length=window, polyorder=3)\n",
    "\n",
    "    def analyze_coordination(self):\n",
    "        \"\"\"Enhanced coordination analysis\"\"\"\n",
    "        # Compute phases using Hilbert transform\n",
    "        phase_left = self._compute_phase_from_velocity(self.left_vel)\n",
    "        phase_right = self._compute_phase_from_velocity(self.right_vel)\n",
    "        # Phase difference analysis\n",
    "        phase_diff_raw = phase_left - phase_right\n",
    "        phase_diff_smooth = uniform_filter1d(phase_diff_raw, size=int(0.2 * self.config['sample_rate']))\n",
    "        self.phase_diff_wrapped = ((phase_diff_smooth + np.pi) % (2 * np.pi)) - np.pi\n",
    "        # Coordination metrics\n",
    "        self.coordination_index = np.cos(self.phase_diff_wrapped)\n",
    "        self.coord_smooth = uniform_filter1d(self.coordination_index, size=int(0.3 * self.config['sample_rate']))\n",
    "        # Compute coordination variability\n",
    "        window_size = int(self.config['window_size_ratio'] * self.config['sample_rate'])\n",
    "        self.std_coord = self._compute_rolling_std(self.coord_smooth, window_size)\n",
    "        return self\n",
    "\n",
    "    def _compute_phase_from_velocity(self, vel):\n",
    "        \"\"\"Compute phase from velocity using Hilbert transform\"\"\"\n",
    "        vel_centered = vel - np.mean(vel)\n",
    "        analytic = hilbert(vel_centered)\n",
    "        return np.unwrap(np.angle(analytic))\n",
    "\n",
    "    def _compute_rolling_std(self, signal, window_size):\n",
    "        \"\"\"Compute rolling standard deviation efficiently\"\"\"\n",
    "        std_signal = np.zeros_like(signal)\n",
    "        half_window = window_size // 2\n",
    "        for i in range(len(signal)):\n",
    "            start = max(0, i - half_window)\n",
    "            end = min(len(signal), i + half_window + 1)\n",
    "            std_signal[i] = np.std(signal[start:end])\n",
    "        return std_signal\n",
    "\n",
    "    def detect_events(self):\n",
    "        \"\"\"ENHANCED: Detect events with balanced sampling\"\"\"\n",
    "        # Classify coordination modes\n",
    "        in_phase_current = np.abs(self.phase_diff_wrapped) < self.config['anti_phase_threshold_rad']\n",
    "        anti_phase_current = np.abs(self.phase_diff_wrapped) >= self.config['anti_phase_threshold_rad']\n",
    "        # Get grouping window\n",
    "        grouping_window = int(self.config['grouping_window_ratio'] * self.config['sample_rate'])\n",
    "        # Get indices for each state\n",
    "        in_phase_indices = np.where(in_phase_current)[0]\n",
    "        anti_phase_indices = np.where(anti_phase_current)[0]\n",
    "        high_std_indices = np.where(self.std_coord > self.config['breakdown_std_threshold'])[0]\n",
    "        # Find breakdown candidates (in-phase + high variability)\n",
    "        breakdown_candidate_indices = np.intersect1d(in_phase_indices, high_std_indices)\n",
    "        # Group breakdown candidates\n",
    "        breakdown_groups = self._group_indices(breakdown_candidate_indices, grouping_window)\n",
    "        # Create In-Phase Breakdown events\n",
    "        in_phase_breakdown_events = []\n",
    "        for group in breakdown_groups:\n",
    "            idx = group[0]\n",
    "            in_phase_breakdown_events.append({\n",
    "                'time_s': float(self.times[idx]),\n",
    "                'frame': int(idx),\n",
    "                'type': 'In-Phase Breakdown'\n",
    "            })\n",
    "        # Create Anti-Phase events\n",
    "        anti_phase_groups = self._group_indices(anti_phase_indices, grouping_window)\n",
    "        anti_phase_events = []\n",
    "        for group in anti_phase_groups:\n",
    "            idx = group[0]\n",
    "            anti_phase_events.append({\n",
    "                'time_s': float(self.times[idx]),\n",
    "                'frame': int(idx),\n",
    "                'type': 'Anti-Phase Event'\n",
    "            })\n",
    "        # NEW: Create balanced In-Phase events using improved sampling\n",
    "        in_phase_events = self._create_in_phase_events_balanced(\n",
    "            in_phase_indices, self.config['target_in_phase_events']\n",
    "        )\n",
    "        # Combine all events\n",
    "        all_events = in_phase_breakdown_events + anti_phase_events + in_phase_events\n",
    "        all_events.sort(key=lambda x: x['time_s'])\n",
    "        # Create DataFrame\n",
    "        if all_events:\n",
    "            self.event_df = pd.DataFrame(all_events)\n",
    "            self.event_df['time_s'] = self.event_df['time_s'].round(2)\n",
    "            self.event_df['subject_id'] = self.subject_id\n",
    "        else:\n",
    "            self.event_df = pd.DataFrame(columns=['time_s', 'frame', 'type', 'subject_id'])\n",
    "        # Print enhanced summary\n",
    "        self._print_enhanced_analysis_summary(in_phase_current, anti_phase_current, all_events)\n",
    "        return self\n",
    "\n",
    "    def _create_in_phase_events_balanced(self, in_phase_indices, target_events=250):\n",
    "        \"\"\"NEW: Create balanced in-phase events by intelligent sampling\"\"\"\n",
    "        events = []\n",
    "        if len(in_phase_indices) == 0:\n",
    "            return events\n",
    "        # Group consecutive in-phase points\n",
    "        grouping_window = int(self.config['grouping_window_ratio'] * self.config['sample_rate'])\n",
    "        in_phase_groups = self._group_indices(in_phase_indices, grouping_window)\n",
    "        # Collect all sampleable points\n",
    "        all_sampleable_points = []\n",
    "        for group in in_phase_groups:\n",
    "            if len(group) == 0:\n",
    "                continue\n",
    "            elif len(group) <= 5:  # Small group - just take the first point\n",
    "                all_sampleable_points.append(group[0])\n",
    "            else:  # Long group - sample multiple points\n",
    "                step = max(1, len(group) // min(5, len(group)))\n",
    "                sampled_from_group = group[::step]\n",
    "                all_sampleable_points.extend(sampled_from_group)\n",
    "        # Sample to reach target\n",
    "        if len(all_sampleable_points) <= target_events:\n",
    "            selected_indices = all_sampleable_points\n",
    "        else:\n",
    "            step = len(all_sampleable_points) // target_events\n",
    "            selected_indices = all_sampleable_points[::step][:target_events]\n",
    "        # Create events\n",
    "        for idx in selected_indices:\n",
    "            events.append({\n",
    "                'time_s': float(self.times[idx]),\n",
    "                'frame': int(idx),\n",
    "                'type': 'In-Phase Event'\n",
    "            })\n",
    "        return events[:target_events]\n",
    "\n",
    "    def _group_indices(self, indices, gap):\n",
    "        \"\"\"Group nearby indices\"\"\"\n",
    "        if len(indices) == 0:\n",
    "            return []\n",
    "        groups = []\n",
    "        current_group = [indices[0]]\n",
    "        for idx in indices[1:]:\n",
    "            if idx - current_group[-1] <= gap:\n",
    "                current_group.append(idx)\n",
    "            else:\n",
    "                groups.append(np.array(current_group))\n",
    "                current_group = [idx]\n",
    "        groups.append(np.array(current_group))\n",
    "        return groups\n",
    "\n",
    "    def _print_enhanced_analysis_summary(self, in_phase_current, anti_phase_current, all_events):\n",
    "        \"\"\"Enhanced analysis summary with event type breakdown\"\"\"\n",
    "        in_phase_pct = np.mean(in_phase_current) * 100\n",
    "        anti_phase_pct = np.mean(anti_phase_current) * 100\n",
    "        print(f\"\\n📊 {self.subject_id} ENHANCED COORDINATION ANALYSIS\")\n",
    "        print(\"—\" * 60)\n",
    "        print(f\"Total events detected: {len(all_events)}\")\n",
    "        if all_events:\n",
    "            event_types = {}\n",
    "            for event in all_events:\n",
    "                event_type = event['type']\n",
    "                event_types[event_type] = event_types.get(event_type, 0) + 1\n",
    "            print(f\"Event type distribution:\")\n",
    "            for event_type, count in event_types.items():\n",
    "                print(f\"  {event_type}: {count}\")\n",
    "        print(f\"In-phase time: {in_phase_pct:.1f}%\")\n",
    "        print(f\"Anti-phase time: {anti_phase_pct:.1f}%\")\n",
    "\n",
    "    def create_plots(self, output_dir=\"plots\", plot_duration=60.0):\n",
    "        \"\"\"Generate all standard plots (keeping original functionality)\"\"\"\n",
    "        output_dir = Path(output_dir)\n",
    "        output_dir.mkdir(exist_ok=True)\n",
    "        # Main coordination analysis plot\n",
    "        self._plot_coordination_overview(output_dir, plot_duration)\n",
    "        # Variability plot\n",
    "        self._plot_variability(output_dir, plot_duration)\n",
    "        return self\n",
    "\n",
    "    def _plot_coordination_overview(self, output_dir, plot_duration):\n",
    "        \"\"\"Create main coordination analysis plot\"\"\"\n",
    "        mask_plot = self.times <= plot_duration\n",
    "        t_plot = self.times[mask_plot]\n",
    "        # Filter events for plotting\n",
    "        events_plot = self.event_df[self.event_df['time_s'] <= plot_duration] if not self.event_df.empty else pd.DataFrame()\n",
    "        colors = {\n",
    "            'right_hand': \"#9121B4\", 'left_hand': \"#4446D6\", 'breakdown': \"#E60000\",\n",
    "            'in_phase': \"#4446D6\", 'anti_phase': \"#D81049\", 'background_grid': \"#FDFDFD\"\n",
    "        }\n",
    "        fig, axes = plt.subplots(3, 1, figsize=(14, 10))\n",
    "        # 1. Position\n",
    "        ax = axes[0]\n",
    "        ax.plot(t_plot, self.right_x_smooth[mask_plot], '-', color=colors['right_hand'], label='Right Hand', linewidth=2)\n",
    "        ax.plot(t_plot, self.left_x_smooth[mask_plot], '-', color=colors['left_hand'], label='Left Hand', linewidth=2)\n",
    "        self._add_event_lines(ax, events_plot, colors)\n",
    "        ax.set_ylabel(\"Position (px)\", fontweight='bold')\n",
    "        ax.set_title(f\"{self.subject_id} - Hand Positions\", fontweight='bold')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        # 2. Coordination Index\n",
    "        ax = axes[1]\n",
    "        in_phase_plot = np.abs(self.phase_diff_wrapped[mask_plot]) < self.config['anti_phase_threshold_rad']\n",
    "        anti_phase_plot = np.abs(self.phase_diff_wrapped[mask_plot]) >= self.config['anti_phase_threshold_rad']\n",
    "        ax.plot(t_plot, self.coord_smooth[mask_plot], '-', color='black', linewidth=2, label='Coordination Index')\n",
    "        ax.fill_between(t_plot, -1, 1, where=in_phase_plot, alpha=0.3, color=colors['in_phase'], label='In-Phase')\n",
    "        ax.fill_between(t_plot, -1, 1, where=anti_phase_plot, alpha=0.3, color=colors['anti_phase'], label='Anti-Phase')\n",
    "        ax.axhline(0, color='gray', linestyle=':', alpha=0.6)\n",
    "        self._add_event_lines(ax, events_plot, colors)\n",
    "        ax.set_ylabel(\"cos(Δφ)\", fontweight='bold')\n",
    "        ax.set_title(\"Coordination Index\", fontweight='bold')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        # 3. Coordination Variability\n",
    "        ax = axes[2]\n",
    "        ax.plot(t_plot, self.std_coord[mask_plot], '-', color=colors['in_phase'], linewidth=2, label='Coordination Std')\n",
    "        ax.axhline(self.config['breakdown_std_threshold'], color=colors['breakdown'], linestyle=':', label='Breakdown Threshold')\n",
    "        self._add_event_lines(ax, events_plot, colors)\n",
    "        ax.set_ylabel(\"Std Dev\", fontweight='bold')\n",
    "        ax.set_xlabel(\"Time (s)\", fontweight='bold')\n",
    "        ax.set_title(\"Coordination Variability\", fontweight='bold')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(output_dir / f\"{self.subject_id}_coordination_analysis.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"✅ Saved coordination analysis plot: {self.subject_id}_coordination_analysis.png\")\n",
    "\n",
    "    def _plot_variability(self, output_dir, plot_duration):\n",
    "        \"\"\"Create enhanced variability plot with all event types\"\"\"\n",
    "        mask_plot = self.times <= plot_duration\n",
    "        t_plot = self.times[mask_plot]\n",
    "        events_plot = self.event_df[self.event_df['time_s'] <= plot_duration] if not self.event_df.empty else pd.DataFrame()\n",
    "        plt.figure(figsize=(14, 5))\n",
    "        plt.plot(t_plot, self.std_coord[mask_plot], color='indigo', linewidth=2.5, alpha=0.8, label='Coordination Variability')\n",
    "        plt.axhline(self.config['breakdown_std_threshold'], color='black', linestyle=':', alpha=0.7, label='Instability Threshold')\n",
    "        # Add event lines with enhanced colors\n",
    "        event_colors = {\n",
    "            'In-Phase Breakdown': 'blue',\n",
    "            'Anti-Phase Event': 'red',\n",
    "            'In-Phase Event': 'green'  # NEW\n",
    "        }\n",
    "        for _, event in events_plot.iterrows():\n",
    "            color = event_colors.get(event['type'], 'black')\n",
    "            plt.axvline(x=event['time_s'], color=color, linestyle='--', linewidth=2.5, alpha=0.8)\n",
    "        # Enhanced legend\n",
    "        legend_elements = [\n",
    "            Line2D([0], [0], color='indigo', lw=2.5, label='Coordination Variability'),\n",
    "            Line2D([0], [0], color='black', lw=1.5, linestyle=':', label='Instability Threshold'),\n",
    "            Line2D([0], [0], color='blue', lw=2.5, linestyle='--', label='In-Phase Breakdown'),\n",
    "            Line2D([0], [0], color='red', lw=2.5, linestyle='--', label='Anti-Phase Event'),\n",
    "            Line2D([0], [0], color='green', lw=2.5, linestyle='--', label='In-Phase Event')\n",
    "        ]\n",
    "        plt.ylabel(\"Std Dev of Coordination Index\", fontweight='bold')\n",
    "        plt.xlabel(\"Time (s)\", fontweight='bold')\n",
    "        plt.title(f\"{self.subject_id} - Enhanced Coordination Variability (0 – {plot_duration:.0f}s)\", fontweight='bold')\n",
    "        plt.legend(handles=legend_elements, loc='upper right')\n",
    "        plt.grid(True, alpha=0.4)\n",
    "        plt.ylim(0, np.max(self.std_coord[mask_plot]) * 1.1 if len(self.std_coord[mask_plot]) > 0 else 1.0)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(output_dir / f\"{self.subject_id}_enhanced_variability.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"✅ Saved enhanced variability plot: {self.subject_id}_enhanced_variability.png\")\n",
    "\n",
    "    def _add_event_lines(self, ax, events_df, colors):\n",
    "        \"\"\"Add event lines to plot with enhanced event types\"\"\"\n",
    "        if events_df.empty:\n",
    "            return\n",
    "        # Enhanced event type handling\n",
    "        event_type_colors = {\n",
    "            'In-Phase Breakdown': colors['breakdown'],\n",
    "            'Anti-Phase Event': colors['anti_phase'],\n",
    "            'In-Phase Event': 'green'\n",
    "        }\n",
    "        # Group events by type to avoid duplicate labels\n",
    "        plotted_types = set()\n",
    "        for _, event in events_df.iterrows():\n",
    "            event_type = event['type']\n",
    "            color = event_type_colors.get(event_type, 'black')\n",
    "            linestyle = '--' if 'Breakdown' in event_type else '-.' if 'Anti-Phase' in event_type else ':'\n",
    "            label = event_type if event_type not in plotted_types else \"\"\n",
    "            plotted_types.add(event_type)\n",
    "            ax.axvline(event['time_s'], color=color, linestyle=linestyle, alpha=0.7, label=label)\n",
    "\n",
    "\n",
    "# === Enhanced EEGTrialTracker Class ===\n",
    "class EEGTrialTracker:\n",
    "    \"\"\"Enhanced EEG trial detection and alignment with improved stim_channel handling\"\"\"\n",
    "    def __init__(self, subject_id, base_path, mff_filename, config=None):\n",
    "        self.subject_id = subject_id\n",
    "        self.base_path = Path(base_path)\n",
    "        self.mff_filename = mff_filename\n",
    "        self.config = config or {}\n",
    "        self.raw = None\n",
    "\n",
    "    def load_and_align(self, analyzer):\n",
    "        \"\"\"Load EEG data and align with behavioral events\"\"\"\n",
    "        try:\n",
    "            # Load EEG data\n",
    "            mff_path = self.base_path / self.mff_filename\n",
    "            if not mff_path.exists():\n",
    "                print(f\"⚠️ EEG file not found: {mff_path}\")\n",
    "                return analyzer\n",
    "            self.raw = mne.io.read_raw_egi(str(mff_path), preload=True, verbose=False)\n",
    "            self._setup_channels()\n",
    "            # Get trials\n",
    "            trials_df = self._get_trials_from_pacing()\n",
    "            if trials_df.empty:\n",
    "                print(f\"⚠️ No trials found for {self.subject_id}\")\n",
    "                return analyzer\n",
    "            # Align events\n",
    "            analyzer = self._align_behavioral_events(analyzer, trials_df)\n",
    "            analyzer.trials_df = trials_df\n",
    "            print(f\"✅ EEG alignment complete for {self.subject_id}\")\n",
    "            return analyzer\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ EEG alignment failed for {self.subject_id}: {e}\")\n",
    "            return analyzer\n",
    "\n",
    "    def _setup_channels(self):\n",
    "        \"\"\"Setup channel names and types\"\"\"\n",
    "        rename_dict = {str(i): f'E{i}' for i in range(1, 281)}\n",
    "        rename_dict['REF CZ'] = 'Cz'\n",
    "        self.raw.rename_channels(rename_dict)\n",
    "        stim_channels = self.config.get('stim_channels', ['TT140', 'TT255', '1a', '2a', '3a', '4a', '5a', '6a'])\n",
    "        existing_stim = [ch for ch in stim_channels if ch in self.raw.ch_names]\n",
    "        self.raw.set_channel_types({ch: 'stim' for ch in existing_stim})\n",
    "\n",
    "    def _get_trials_from_pacing(self):\n",
    "        \"\"\"Extract trials from pacing channels with enhanced detection\"\"\"\n",
    "        pacing_channels = self.config.get('pacing_channels', ['1a', '2a', '3a', '4a', '5a', '6a'])\n",
    "        picks = [ch for ch in pacing_channels if ch in self.raw.ch_names]\n",
    "        if not picks:\n",
    "            return pd.DataFrame()\n",
    "        # Extract all pacing events\n",
    "        all_onsets = []\n",
    "        for ch_name in picks:\n",
    "            ch_idx = self.raw.ch_names.index(ch_name)\n",
    "            ch_data = self.raw.get_data(picks=[ch_idx])[0]\n",
    "            digital = (ch_data != 0).astype(int)\n",
    "            starts = np.where(np.diff(digital, prepend=0) == 1)[0]\n",
    "            event_times = self.raw.times[starts] + self.config.get('eeg_to_behavior_delay', 0.0)\n",
    "            for t in event_times:\n",
    "                all_onsets.append({'channel': ch_name, 'eeg_time_s': t})\n",
    "        if not all_onsets:\n",
    "            return pd.DataFrame()\n",
    "        events_df = pd.DataFrame(all_onsets).sort_values('eeg_time_s').reset_index(drop=True)\n",
    "        # Define trials based on gaps\n",
    "        return self._define_trials_from_gaps(events_df)\n",
    "\n",
    "    def _define_trials_from_gaps(self, events_df):\n",
    "        \"\"\"Enhanced trial definition with improved gap detection\"\"\"\n",
    "        gap_threshold = self.config.get('trial_gap_threshold_s', 2.5)\n",
    "        extension_duration = self.config.get('extension_duration_s', 4.3)\n",
    "        times = events_df['eeg_time_s'].values\n",
    "        intervals = np.diff(times)\n",
    "        gap_indices = np.where(intervals > gap_threshold)[0]\n",
    "        # Define block boundaries\n",
    "        boundaries = []\n",
    "        start_idx = 0\n",
    "        for gap_idx in gap_indices:\n",
    "            boundaries.append((start_idx, gap_idx))\n",
    "            start_idx = gap_idx + 1\n",
    "        boundaries.append((start_idx, len(events_df) - 1))\n",
    "        # Create trials with enhanced information\n",
    "        trials = []\n",
    "        for start_idx, end_idx in boundaries:\n",
    "            block_events = events_df.iloc[start_idx:end_idx+1]\n",
    "            first_1a = block_events[block_events['channel'] == '1a']['eeg_time_s'].min()\n",
    "            last_6a = block_events[block_events['channel'] == '6a']['eeg_time_s'].max()\n",
    "            if pd.notna(first_1a) and pd.notna(last_6a) and last_6a > first_1a:\n",
    "                trials.append({\n",
    "                    'trial_number': len(trials) + 1,\n",
    "                    'start_time': first_1a,\n",
    "                    'end_time': last_6a,\n",
    "                    'end_time_extended': last_6a + extension_duration,\n",
    "                    'duration_s': last_6a - first_1a,\n",
    "                    'subject_id': self.subject_id\n",
    "                })\n",
    "        return pd.DataFrame(trials)\n",
    "\n",
    "    def _align_behavioral_events(self, analyzer, trials_df):\n",
    "        \"\"\"Enhanced behavioral event alignment with improved stim_channel handling\"\"\"\n",
    "        if analyzer.event_df.empty or trials_df.empty:\n",
    "            return analyzer\n",
    "        # Convert behavioral time to EEG time\n",
    "        first_trial_start = trials_df['start_time'].iloc[0]\n",
    "        analyzer.event_df['eeg_time_s'] = (analyzer.event_df['time_s'] + first_trial_start).round(3)\n",
    "        # Assign to trials using extended window\n",
    "        def assign_to_trial(eeg_time):\n",
    "            for _, trial in trials_df.iterrows():\n",
    "                if trial['start_time'] <= eeg_time < trial['end_time_extended']:\n",
    "                    return trial['trial_number']\n",
    "            return np.nan\n",
    "        analyzer.event_df['trial_number'] = analyzer.event_df['eeg_time_s'].apply(assign_to_trial)\n",
    "        # Enhanced stim_channel assignment\n",
    "        print(f\"🧠 Adding enhanced stim_channel info for {self.subject_id}...\")\n",
    "        pacing_channels = self.config.get('pacing_channels', ['1a', '2a', '3a', '4a', '5a', '6a'])\n",
    "        pacing_onsets = []\n",
    "        for ch_name in pacing_channels:\n",
    "            if ch_name not in self.raw.ch_names:\n",
    "                continue\n",
    "            ch_idx = self.raw.ch_names.index(ch_name)\n",
    "            ch_data = self.raw.get_data(picks=[ch_idx])[0]\n",
    "            digital = (ch_data != 0).astype(int)\n",
    "            transitions = np.diff(digital, prepend=0)\n",
    "            starts = np.where(transitions == 1)[0]  # Rising edges\n",
    "            event_times = self.raw.times[starts]\n",
    "            for t in event_times:\n",
    "                pacing_onsets.append({'eeg_time_s': t, 'stim_channel': ch_name})\n",
    "        # Sort all pacing triggers by time\n",
    "        pacing_df = pd.DataFrame(pacing_onsets).sort_values('eeg_time_s').reset_index(drop=True)\n",
    "        # Enhanced function to get last stim channel before event\n",
    "        def get_last_stim_channel(eeg_time_s):\n",
    "            valid = pacing_df[pacing_df['eeg_time_s'] <= eeg_time_s]\n",
    "            if not valid.empty:\n",
    "                return valid.iloc[-1]['stim_channel']\n",
    "            return np.nan\n",
    "        # Apply to each event\n",
    "        analyzer.event_df['stim_channel'] = analyzer.event_df['eeg_time_s'].apply(get_last_stim_channel)\n",
    "        print(f\"✅ Enhanced stim_channel added for {self.subject_id}\")\n",
    "        return analyzer\n",
    "\n",
    "    def save_events_to_mne_format(self, analyzer, output_dir=\"results\"):\n",
    "        \"\"\"NEW: Save events in MNE format for further analysis\"\"\"\n",
    "        if analyzer.event_df.empty or self.raw is None:\n",
    "            print(f\"⚠️ Cannot save MNE events for {self.subject_id}: missing data\")\n",
    "            return\n",
    "        try:\n",
    "            # Convert events to MNE format\n",
    "            events_list = []\n",
    "            event_id = {}\n",
    "            event_counter = 1\n",
    "            for _, event in analyzer.event_df.iterrows():\n",
    "                if pd.notna(event['eeg_time_s']):\n",
    "                    # Find the sample index corresponding to the time\n",
    "                    sample_idx = int(event['eeg_time_s'] * self.raw.info['sfreq'])\n",
    "                    # Create unique event ID for each event type\n",
    "                    event_type = event['type']\n",
    "                    if event_type not in event_id:\n",
    "                        event_id[event_type] = event_counter\n",
    "                        event_counter += 1\n",
    "                    events_list.append([sample_idx, 0, event_id[event_type]])\n",
    "            if events_list:\n",
    "                events_array = np.array(events_list)\n",
    "                # Save MNE events\n",
    "                output_path = Path(output_dir) / self.subject_id\n",
    "                output_path.mkdir(parents=True, exist_ok=True)\n",
    "                events_file = output_path / f\"{self.subject_id}_events_mne.fif\"\n",
    "                mne.write_events(str(events_file), events_array)\n",
    "                # Save event_id mapping\n",
    "                event_id_file = output_path / f\"{self.subject_id}_event_id.json\"\n",
    "                with open(event_id_file, 'w') as f:\n",
    "                    json.dump(event_id, f, indent=2)\n",
    "                print(f\"✅ Saved MNE events: {events_file}\")\n",
    "                print(f\"✅ Saved event ID mapping: {event_id_file}\")\n",
    "            else:\n",
    "                print(f\"⚠️ No valid events to save in MNE format for {self.subject_id}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Failed to save MNE events for {self.subject_id}: {e}\")\n",
    "\n",
    "\n",
    "# === Enhanced Processing Functions ===\n",
    "def process_subject(subject_id, behavioral_file, eeg_config=None, analysis_config=None, output_dir=\"results\"):\n",
    "    \"\"\"Process a single subject through the complete pipeline\"\"\"\n",
    "    print(f\"\\n🔄 Processing {subject_id}...\")\n",
    "    # Initialize analyzer\n",
    "    analyzer = CoordinationAnalyzer(subject_id, analysis_config)\n",
    "    # Load and analyze behavioral data\n",
    "    analyzer.load_behavioral_data(behavioral_file)\n",
    "    analyzer.preprocess_signals()\n",
    "    analyzer.analyze_coordination()\n",
    "    analyzer.detect_events()\n",
    "    # EEG alignment (if config provided)\n",
    "    if eeg_config:\n",
    "        tracker = EEGTrialTracker(subject_id, **eeg_config)\n",
    "        analyzer = tracker.load_and_align(analyzer)\n",
    "        # NEW: Save MNE format events\n",
    "        tracker.save_events_to_mne_format(analyzer, output_dir)\n",
    "    # Create plots\n",
    "    output_path = Path(output_dir) / subject_id\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    analyzer.create_plots(output_path)\n",
    "    # Save event data\n",
    "    if not analyzer.event_df.empty:\n",
    "        event_file = output_path / f\"{subject_id}_events.csv\"\n",
    "        analyzer.event_df.to_csv(event_file, index=False)\n",
    "        print(f\"✅ Saved events: {event_file}\")\n",
    "    # Save trial data (if available)\n",
    "    if hasattr(analyzer, 'trials_df') and analyzer.trials_df is not None:\n",
    "        trial_file = output_path / f\"{subject_id}_trials.csv\"\n",
    "        analyzer.trials_df.to_csv(trial_file, index=False)\n",
    "        print(f\"✅ Saved trials: {trial_file}\")\n",
    "    print(f\"✅ {subject_id} processing complete!\")\n",
    "    return analyzer\n",
    "\n",
    "def process_multiple_subjects(subject_configs, output_dir=\"results\"):\n",
    "    \"\"\"Process multiple subjects in batch\"\"\"\n",
    "    results = {}\n",
    "    for subject_id, config in subject_configs.items():\n",
    "        try:\n",
    "            analyzer = process_subject(\n",
    "                subject_id=subject_id,\n",
    "                behavioral_file=config['behavioral_file'],\n",
    "                eeg_config=config.get('eeg_config'),\n",
    "                analysis_config=config.get('analysis_config'),\n",
    "                output_dir=output_dir\n",
    "            )\n",
    "            results[subject_id] = analyzer\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Failed to process {subject_id}: {e}\")\n",
    "            results[subject_id] = None\n",
    "    # Combine all events\n",
    "    all_events = []\n",
    "    for subject_id, analyzer in results.items():\n",
    "        if analyzer and not analyzer.event_df.empty:\n",
    "            all_events.append(analyzer.event_df)\n",
    "    if all_events:\n",
    "        combined_events = pd.concat(all_events, ignore_index=True)\n",
    "        combined_file = Path(output_dir) / \"combined_events.csv\"\n",
    "        combined_events.to_csv(combined_file, index=False)\n",
    "        print(f\"\\n✅ Saved combined events: {combined_file}\")\n",
    "    return results\n",
    "\n",
    "\n",
    "# === Visualize Trials Functions ===\n",
    "def plot_single_trial_for_subject(analyzer, trial_number, output_dir=\"results\", show_events=True, duration_limit=50):\n",
    "    \"\"\"\n",
    "    Enhanced trial plotting with 6 subplots including Hilbert phase analysis.\n",
    "    Plots first `duration_limit` seconds of each trial based on EEG time and includes stim channel events.\n",
    "    X-axis shows EEG time.\n",
    "\n",
    "    Parameters:\n",
    "    - analyzer: CoordinationAnalyzer object after processing.\n",
    "    - trial_number: int, the trial number to plot.\n",
    "    - output_dir: str, base directory for saving results.\n",
    "    - show_events: bool, whether to mark events on the plot.\n",
    "    - duration_limit: float, maximum duration to plot in seconds (default 50 seconds).\n",
    "    \"\"\"\n",
    "    # --- 1. Check if necessary data exists ---\n",
    "    if analyzer.trials_df is None or analyzer.trials_df.empty:\n",
    "        print(f\"⚠️ No trial data available for {analyzer.subject_id}. Skipping trial plot {trial_number}.\")\n",
    "        return\n",
    "    if trial_number not in analyzer.trials_df['trial_number'].values:\n",
    "        print(f\"❌ Trial {trial_number} not found for subject {analyzer.subject_id}. Available trials: {list(analyzer.trials_df['trial_number'])}\")\n",
    "        return\n",
    "    if not hasattr(analyzer, 'right_x_filtered') or not hasattr(analyzer, 'left_x_filtered'):\n",
    "        print(f\"⚠️ Filtered signals not found for {analyzer.subject_id}. Run preprocessing first. Skipping trial plot {trial_number}.\")\n",
    "        return\n",
    "    if analyzer.event_df is None or analyzer.event_df.empty: # Check if empty too\n",
    "        print(f\"⚠️ Event data not found or empty for {analyzer.subject_id}. Skipping event marking for trial {trial_number}.\")\n",
    "        show_events = False\n",
    "\n",
    "    # --- 2. Get trial info (EEG time base) ---\n",
    "    trial = analyzer.trials_df[analyzer.trials_df['trial_number'] == trial_number].iloc[0]\n",
    "    start_time_eeg = trial['start_time']  # This is in EEG time (s)\n",
    "    \n",
    "    # Determine the end time based on duration limit and trial extension\n",
    "    # Use 'end_time_extended' if available for a potentially longer view, but still limit by duration_limit\n",
    "    actual_end_time_eeg = trial.get('end_time_extended', trial['end_time'])\n",
    "    end_time_eeg = min(start_time_eeg + duration_limit, actual_end_time_eeg)\n",
    "    plot_duration_eeg = end_time_eeg - start_time_eeg # This is the actual duration plotted\n",
    "\n",
    "    # --- 3. Align Behavioral Time with EEG Time ---\n",
    "    # The alignment offset was calculated during EEG processing:\n",
    "    # analyzer.event_df['eeg_time_s'] = (analyzer.event_df['time_s'] + first_trial_start)\n",
    "    # Therefore: behavioral_time = eeg_time - first_trial_start\n",
    "    # We need the `first_trial_start` value. Let's assume it's the start_time of trial 1.\n",
    "    # A more robust way is to check the offset used in alignment.\n",
    "    # Let's find the offset by comparing the first event's behavioral and EEG times if possible.\n",
    "    # Or, we can use the trial's start_time and the corresponding behavioral time segment.\n",
    "    \n",
    "    # Find the index in behavioral data (`analyzer.times`) that corresponds to `start_time_eeg`\n",
    "    # We need to find the behavioral time that maps to `start_time_eeg`\n",
    "    # Since `eeg_time_s = behavioral_time_s + offset`, we have `offset = eeg_time_s - behavioral_time_s`\n",
    "    # We can use the first event of this trial to find the offset, or assume it's consistent.\n",
    "    # Let's find the first event of this trial to get the offset.\n",
    "    trial_events_all = analyzer.event_df[analyzer.event_df['trial_number'] == trial_number]\n",
    "    if not trial_events_all.empty:\n",
    "        first_event_of_trial = trial_events_all.iloc[0]\n",
    "        # offset = eeg_time_s - behavioral_time_s\n",
    "        time_offset = first_event_of_trial['eeg_time_s'] - first_event_of_trial['time_s']\n",
    "        # print(f\"Debug: Time offset for trial {trial_number}: {time_offset}\")\n",
    "    else:\n",
    "        # If no events, we cannot reliably determine the offset. Fallback or skip?\n",
    "        # Let's try to use the trial start time. The trial start time in EEG should correspond\n",
    "        # to some point in the behavioral data. This is tricky without the explicit offset.\n",
    "        # Let's assume the offset is `first_trial_start` from the EEG alignment process.\n",
    "        # How was `first_trial_start` determined? It was `trials_df['start_time'].iloc[0]`.\n",
    "        # The behavioral data starts at t=0. So, the offset should be `first_trial_start`.\n",
    "        # Let's try to get it from the first trial's start time in EEG.\n",
    "        if not analyzer.trials_df.empty:\n",
    "             first_trial_start_eeg = analyzer.trials_df['start_time'].iloc[0]\n",
    "             # Behavioral time 0 maps to EEG time `first_trial_start_eeg`\n",
    "             time_offset = first_trial_start_eeg # eeg_time = behavioral_time + time_offset\n",
    "             # print(f\"Debug: Using first trial start as offset: {time_offset}\")\n",
    "        else:\n",
    "             print(f\"❌ Cannot determine time alignment for trial {trial_number} of {analyzer.subject_id}. Skipping.\")\n",
    "             return\n",
    "\n",
    "    # Now, convert EEG time window to behavioral time window for data extraction\n",
    "    start_time_behavioral = start_time_eeg - time_offset\n",
    "    end_time_behavioral = end_time_eeg - time_offset\n",
    "\n",
    "    # --- 4. Extract data segment (using behavioral time for indexing) ---\n",
    "    mask = (analyzer.times >= start_time_behavioral) & (analyzer.times <= end_time_behavioral)\n",
    "    t_segment_behavioral = analyzer.times[mask] # Behavioral time axis for data\n",
    "    if len(t_segment_behavioral) == 0:\n",
    "        print(f\"❌ No behavioral data found for trial {trial_number} of {analyzer.subject_id} (EEG: {start_time_eeg:.2f}s – {end_time_eeg:.2f}s, Behavioral: {start_time_behavioral:.2f}s – {end_time_behavioral:.2f}s)\")\n",
    "        return\n",
    "\n",
    "    # Convert behavioral time axis to EEG time axis for plotting\n",
    "    t_segment_eeg = t_segment_behavioral + time_offset # This is the correct EEG time axis for the x-axis\n",
    "\n",
    "    left_x_segment = analyzer.left_x_filtered[mask]\n",
    "    right_x_segment = analyzer.right_x_filtered[mask]\n",
    "    coord_smooth_segment = analyzer.coord_smooth[mask]\n",
    "    std_coord_segment = analyzer.std_coord[mask]\n",
    "\n",
    "    # --- 5. Enhanced Hilbert Transform Analysis ---\n",
    "    try:\n",
    "        # Left hand analysis\n",
    "        analytic_left = hilbert(left_x_segment)\n",
    "        phase_wrapped_left = np.angle(analytic_left)\n",
    "        phase_unwrapped_left = np.unwrap(phase_wrapped_left)\n",
    "        amplitude_left = np.abs(analytic_left)\n",
    "        # Right hand analysis\n",
    "        analytic_right = hilbert(right_x_segment)\n",
    "        phase_wrapped_right = np.angle(analytic_right)\n",
    "        phase_unwrapped_right = np.unwrap(phase_wrapped_right)\n",
    "        amplitude_right = np.abs(analytic_right)\n",
    "        # Relative phase analysis\n",
    "        rp_unwrap = phase_unwrapped_right - phase_unwrapped_left\n",
    "        rp_normalized = np.angle(np.exp(1j * rp_unwrap))  # Wraps to [-π, π]\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error during Hilbert transform for trial {trial_number} of {analyzer.subject_id}: {e}\")\n",
    "        return\n",
    "\n",
    "    # --- 6. Get Events for this Trial within the specified EEG time window ---\n",
    "    trial_events_filtered = pd.DataFrame()\n",
    "    if show_events and not analyzer.event_df.empty:\n",
    "        # Filter events: must belong to this trial AND fall within the EEG time window of the plot\n",
    "        trial_events_filtered = analyzer.event_df[\n",
    "            (analyzer.event_df['trial_number'] == trial_number) &\n",
    "            (analyzer.event_df['eeg_time_s'] >= start_time_eeg) &\n",
    "            (analyzer.event_df['eeg_time_s'] <= end_time_eeg)\n",
    "        ].copy()\n",
    "\n",
    "        if not trial_events_filtered.empty:\n",
    "            print(f\"   📊 Found {len(trial_events_filtered)} events for trial {trial_number} within EEG time {start_time_eeg:.2f}s - {end_time_eeg:.2f}s\")\n",
    "            if 'stim_channel' in trial_events_filtered.columns:\n",
    "                stim_channels = trial_events_filtered['stim_channel'].dropna().unique() # Drop NaN if any\n",
    "                if len(stim_channels) > 0:\n",
    "                     print(f\"   🎛️ Stim channels in this segment: {list(stim_channels)}\")\n",
    "                else:\n",
    "                     print(f\"   ⚠️ No valid stim channels found for events in this segment.\")\n",
    "        else:\n",
    "             print(f\"   🟢 No events found for trial {trial_number} within the specified EEG time window ({start_time_eeg:.2f}s - {end_time_eeg:.2f}s).\")\n",
    "\n",
    "\n",
    "    # === 7. ENHANCED PLOT WITH 6 SUBPLOTS (X-axis: EEG Time) ===\n",
    "    fig, axes = plt.subplots(6, 1, figsize=(16, 14), sharex=True)\n",
    "\n",
    "    # Define colors\n",
    "    colors = {\n",
    "        'right_hand': '#9121B4',\n",
    "        'left_hand': '#4446D6',\n",
    "        'breakdown': '#E60000',\n",
    "        'in_phase': '#4446D6',\n",
    "        'anti_phase': '#D81049'\n",
    "    }\n",
    "    stim_channel_colors = {\n",
    "        '1a': '#FF6B6B',\n",
    "        '2a': '#4ECDC4',\n",
    "        '3a': '#45B7D1',\n",
    "        '4a': '#96CEB4',\n",
    "        '5a': '#FFEAA7',\n",
    "        '6a': '#DDA0DD',\n",
    "        'default': '#FF8C00'\n",
    "    }\n",
    "\n",
    "    # --- 8. Plotting (using EEG time axis) ---\n",
    "    # 1. Position with Amplitude Envelope\n",
    "    ax = axes[0]\n",
    "    ax.plot(t_segment_eeg, right_x_segment, color=colors['right_hand'], label='Right Hand', lw=2)\n",
    "    ax.plot(t_segment_eeg, left_x_segment, color=colors['left_hand'], label='Left Hand', lw=2)\n",
    "    ax.plot(t_segment_eeg, right_x_segment + amplitude_right, color=colors['right_hand'], alpha=0.3, lw=1)\n",
    "    ax.plot(t_segment_eeg, right_x_segment - amplitude_right, color=colors['right_hand'], alpha=0.3, lw=1)\n",
    "    ax.fill_between(t_segment_eeg, right_x_segment - amplitude_right, right_x_segment + amplitude_right,\n",
    "                    color=colors['right_hand'], alpha=0.1)\n",
    "    # Add events\n",
    "    for _, e in trial_events_filtered.iterrows():\n",
    "        stim_channel = e.get('stim_channel', 'default')\n",
    "        event_type = e.get('type', '')\n",
    "        color = stim_channel_colors.get(stim_channel, stim_channel_colors['default'])\n",
    "        linestyle = '--'\n",
    "        if 'Breakdown' in event_type:\n",
    "            linestyle = '-.'\n",
    "        elif 'Anti-Phase' in event_type:\n",
    "            linestyle = ':'\n",
    "        ax.axvline(e['eeg_time_s'], color=color, ls=linestyle, lw=1.5, alpha=0.8)\n",
    "        ax.text(e['eeg_time_s'], ax.get_ylim()[1], f\"{stim_channel}\",\n",
    "                rotation=90, verticalalignment='bottom',\n",
    "                fontsize=8, color=color, alpha=0.7)\n",
    "    ax.set_ylabel(\"Position (px)\", fontweight='bold')\n",
    "    ax.set_title(f\"Subject {analyzer.subject_id} - Trial {trial_number}: First {plot_duration_eeg:.1f}s (EEG Time) ({len(trial_events_filtered)} events)\", fontweight='bold')\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # 2. Wrapped Phase\n",
    "    ax = axes[1]\n",
    "    ax.plot(t_segment_eeg, phase_wrapped_left, color=colors['left_hand'], label='Left Hand', lw=2)\n",
    "    ax.plot(t_segment_eeg, phase_wrapped_right, color=colors['right_hand'], label='Right Hand', lw=2)\n",
    "    ax.axhline(0, color='k', ls=':', alpha=0.6)\n",
    "    # Add events\n",
    "    for _, e in trial_events_filtered.iterrows():\n",
    "        stim_channel = e.get('stim_channel', 'default')\n",
    "        color = stim_channel_colors.get(stim_channel, stim_channel_colors['default'])\n",
    "        linestyle = '--'\n",
    "        if 'Breakdown' in e.get('type', ''):\n",
    "            linestyle = '-.'\n",
    "        elif 'Anti-Phase' in e.get('type', ''):\n",
    "            linestyle = ':'\n",
    "        ax.axvline(e['eeg_time_s'], color=color, ls=linestyle, lw=1.0, alpha=0.6)\n",
    "    ax.set_ylabel(\"Wrapped Phase (rad)\", fontweight='bold')\n",
    "    ax.set_title(\"Instantaneous Phase (Wrapped) - EEG Time\", fontweight='bold')\n",
    "    ax.set_ylim(-np.pi - 0.2, np.pi + 0.2)\n",
    "    ax.set_yticks([-np.pi, -np.pi/2, 0, np.pi/2, np.pi])\n",
    "    ax.set_yticklabels([r'$-\\pi$', r'$-\\pi/2$', '0', r'$\\pi/2$', r'$\\pi$'])\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # 3. Unwrapped Phase\n",
    "    ax = axes[2]\n",
    "    ax.plot(t_segment_eeg, phase_unwrapped_left, color=colors['left_hand'], label='Left Hand', lw=2)\n",
    "    ax.plot(t_segment_eeg, phase_unwrapped_right, color=colors['right_hand'], label='Right Hand', lw=2)\n",
    "    # Add events\n",
    "    for _, e in trial_events_filtered.iterrows():\n",
    "        stim_channel = e.get('stim_channel', 'default')\n",
    "        color = stim_channel_colors.get(stim_channel, stim_channel_colors['default'])\n",
    "        ax.axvline(e['eeg_time_s'], color=color, ls='--', lw=1.0, alpha=0.6)\n",
    "    ax.set_ylabel(\"Unwrapped Phase (rad)\", fontweight='bold')\n",
    "    ax.set_title(\"Instantaneous Phase (Unwrapped) - EEG Time\", fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # 4. Relative Phase\n",
    "    ax = axes[3]\n",
    "    ax.plot(t_segment_eeg, rp_normalized, color='indigo', lw=2.5, label='Relative Phase (Right - Left)')\n",
    "    ax.axhspan(-np.pi/6, np.pi/6, alpha=0.2, color='green', label='In-Phase Region')\n",
    "    ax.axhspan(5*np.pi/6, np.pi, alpha=0.2, color='red', label='Anti-Phase Region')\n",
    "    ax.axhspan(-np.pi, -5*np.pi/6, alpha=0.2, color='red')\n",
    "    ax.axhline(0, color='green', ls='--', lw=1.5, alpha=0.7)\n",
    "    ax.axhline(np.pi, color='red', ls='--', lw=1.5, alpha=0.7)\n",
    "    ax.axhline(-np.pi, color='red', ls='--', lw=1.5, alpha=0.7)\n",
    "    # Add events\n",
    "    for _, e in trial_events_filtered.iterrows():\n",
    "        stim_channel = e.get('stim_channel', 'default')\n",
    "        color = stim_channel_colors.get(stim_channel, stim_channel_colors['default'])\n",
    "        ax.axvline(e['eeg_time_s'], color=color, ls='--', lw=1.5, alpha=0.8)\n",
    "    ax.set_ylim(-np.pi - 0.2, np.pi + 0.2)\n",
    "    ax.set_yticks([-np.pi, -np.pi/2, 0, np.pi/2, np.pi])\n",
    "    ax.set_yticklabels([r'$-\\pi$', r'$-\\pi/2$', '0', r'$\\pi/2$', r'$\\pi$'])\n",
    "    ax.set_ylabel(\"Relative Phase (rad)\", fontweight='bold')\n",
    "    ax.set_title(\"Enhanced Relative Phase Dynamics - EEG Time\", fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # 5. Coordination Index\n",
    "    ax = axes[4]\n",
    "    ax.plot(t_segment_eeg, coord_smooth_segment, color='black', lw=2, label='Coordination Index')\n",
    "    ax.axhline(0, color='gray', linestyle=':', alpha=0.6)\n",
    "    ax.axhline(np.cos(analyzer.config['anti_phase_threshold_rad']), color='red',\n",
    "              linestyle=':', alpha=0.7, label='Anti-Phase Threshold')\n",
    "    in_phase_mask = coord_smooth_segment > np.cos(analyzer.config['anti_phase_threshold_rad'])\n",
    "    ax.fill_between(t_segment_eeg, -1, 1, where=in_phase_mask, alpha=0.2, color='blue', label='In-Phase')\n",
    "    ax.fill_between(t_segment_eeg, -1, 1, where=~in_phase_mask, alpha=0.2, color='red', label='Anti-Phase')\n",
    "    # Add events\n",
    "    for _, e in trial_events_filtered.iterrows():\n",
    "        stim_channel = e.get('stim_channel', 'default')\n",
    "        color = stim_channel_colors.get(stim_channel, stim_channel_colors['default'])\n",
    "        ax.axvline(e['eeg_time_s'], color=color, ls='--', lw=1.0, alpha=0.6)\n",
    "    ax.set_ylabel(\"cos(Δφ)\", fontweight='bold')\n",
    "    ax.set_title(\"Coordination Index - EEG Time\", fontweight='bold')\n",
    "    ax.set_ylim(-1.1, 1.1)\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # 6. Coordination Variability\n",
    "    ax = axes[5]\n",
    "    ax.plot(t_segment_eeg, std_coord_segment, color='purple', lw=2, label='Coordination Variability')\n",
    "    ax.axhline(analyzer.config['breakdown_std_threshold'], color='red',\n",
    "              linestyle=':', alpha=0.7, label='Breakdown Threshold')\n",
    "    high_var_mask = std_coord_segment > analyzer.config['breakdown_std_threshold']\n",
    "    ax.fill_between(t_segment_eeg, 0, np.max(std_coord_segment) if len(std_coord_segment) > 0 else 1,\n",
    "                   where=high_var_mask, alpha=0.3, color='red', label='High Variability')\n",
    "    # Add events\n",
    "    for _, e in trial_events_filtered.iterrows():\n",
    "        stim_channel = e.get('stim_channel', 'default')\n",
    "        color = stim_channel_colors.get(stim_channel, stim_channel_colors['default'])\n",
    "        ax.axvline(e['eeg_time_s'], color=color, ls='--', lw=1.5, alpha=0.8)\n",
    "    ax.set_ylabel(\"Std Dev\", fontweight='bold')\n",
    "    ax.set_xlabel(\"Time (s) - EEG Time\", fontweight='bold')\n",
    "    ax.set_title(\"Coordination Variability - EEG Time\", fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # Set x-axis limits explicitly to match the intended window\n",
    "    ax.set_xlim(start_time_eeg, end_time_eeg)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # --- 9. Save plot ---\n",
    "    subject_output_dir = Path(output_dir) / analyzer.subject_id\n",
    "    subject_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    # Use the actual plotted duration in the filename\n",
    "    plot_filename = subject_output_dir / f\"{analyzer.subject_id}_trial_{trial_number:02d}_eeg_time_{int(plot_duration_eeg)}s.png\"\n",
    "    plt.savefig(plot_filename, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # --- 10. Print Summary ---\n",
    "    print(f\"📈 Enhanced trial plot saved: {analyzer.subject_id}, Trial {trial_number} | EEG Duration: {plot_duration_eeg:.2f}s\")\n",
    "    if len(trial_events_filtered) > 0:\n",
    "        print(f\"   🔴 Events in plotted segment: {len(trial_events_filtered)}\")\n",
    "        if 'stim_channel' in trial_events_filtered.columns:\n",
    "            stim_summary = trial_events_filtered['stim_channel'].value_counts().to_dict()\n",
    "            for stim, count in stim_summary.items():\n",
    "                print(f\"     • Stim {stim}: {count} events\")\n",
    "    else:\n",
    "        print(f\"   🟢 No events in this plotted EEG time segment ({start_time_eeg:.2f}s - {end_time_eeg:.2f}s)\")\n",
    "\n",
    "\n",
    "def plot_all_trials_for_subject(analyzer, output_dir=\"results\", max_trials=None, duration_limit=50):\n",
    "    \"\"\"Plot first `duration_limit` seconds of all trials for a given subject using enhanced plotting with EEG time\"\"\"\n",
    "    if analyzer.trials_df is None or analyzer.trials_df.empty:\n",
    "        print(f\"⚠️ No trial data available for {analyzer.subject_id}. Skipping all trial plots.\")\n",
    "        return\n",
    "\n",
    "    trial_numbers_to_plot = analyzer.trials_df['trial_number'].tolist()\n",
    "    if max_trials is not None:\n",
    "        trial_numbers_to_plot = trial_numbers_to_plot[:max_trials]\n",
    "\n",
    "    print(f\"\\n🔄 Plotting first {duration_limit}s (EEG time) of {len(trial_numbers_to_plot)} trial(s) for {analyzer.subject_id}...\")\n",
    "    for trial_num in trial_numbers_to_plot:\n",
    "        plot_single_trial_for_subject(analyzer, trial_num, output_dir=output_dir, duration_limit=duration_limit)\n",
    "\n",
    "    print(f\"✅ Finished plotting enhanced trials for {analyzer.subject_id} (EEG Time)\")\n",
    "\n",
    "\n",
    "\n",
    "def save_subject_event_df(analyzer, output_dir=\"results\"):\n",
    "    \"\"\"Save the enhanced event_df of a subject to CSV\"\"\"\n",
    "    if analyzer.event_df is not None and not analyzer.event_df.empty:\n",
    "        subject_output_dir = Path(output_dir) / analyzer.subject_id\n",
    "        subject_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        event_file = subject_output_dir / f\"{analyzer.subject_id}_events_enhanced.csv\"\n",
    "        analyzer.event_df.to_csv(event_file, index=False)\n",
    "        print(f\"💾 Saved enhanced event data: {event_file}\")\n",
    "    else:\n",
    "        print(f\"⚠️ No event data to save for {analyzer.subject_id}\")\n",
    "\n",
    "\n",
    "def save_subject_event_df(analyzer, output_dir=\"results\"):\n",
    "    \"\"\"Save the enhanced event_df of a subject to CSV\"\"\"\n",
    "    if analyzer.event_df is not None and not analyzer.event_df.empty:\n",
    "        subject_output_dir = Path(output_dir) / analyzer.subject_id\n",
    "        subject_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        event_file = subject_output_dir / f\"{analyzer.subject_id}_events_enhanced.csv\"\n",
    "        analyzer.event_df.to_csv(event_file, index=False)\n",
    "        print(f\"💾 Saved enhanced event data: {event_file}\")\n",
    "    else:\n",
    "        print(f\"⚠️ No event data to save for {analyzer.subject_id}\")\n",
    "\n",
    "\n",
    "def create_binary_mne_events_for_subject(subject_id, base_results_path, binary_suffix=\"_binary\"):\n",
    "    \"\"\"\n",
    "    Creates binary MNE event files for a single subject, replicating the logic\n",
    "    from the batch BINARY MNE script.\n",
    "\n",
    "    This function takes the multi-class event files generated by the main analysis\n",
    "    ('In-Phase Event', 'Anti-Phase Event', 'In-Phase Breakdown') and creates new\n",
    "    binary event files where:\n",
    "    - 'In-Phase Event' -> 0 (In-Phase)\n",
    "    - 'Anti-Phase Event' + 'In-Phase Breakdown' -> 1 (Out-of-Phase)\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    subject_id : str\n",
    "        The ID of the subject (e.g., 'Sbj01').\n",
    "    base_results_path : str or Path\n",
    "        The path to the main results directory containing subject subfolders.\n",
    "    binary_suffix : str, optional\n",
    "        The suffix to append to the new binary files (default is \"_binary\").\n",
    "        This creates files like 'Sbj01_events_mne_binary-eve.fif'.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    bool\n",
    "        True if the process was successful, False otherwise.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import mne\n",
    "    import json\n",
    "    import numpy as np\n",
    "    from pathlib import Path\n",
    "\n",
    "    base_results_path = Path(base_results_path)\n",
    "    subject_folder = base_results_path / subject_id\n",
    "\n",
    "    print(f\"\\n--- Creating Binary MNE Events for Subject: {subject_id} ---\")\n",
    "\n",
    "    # --- 1. Define File Paths for this Subject ---\n",
    "    trials_path = subject_folder / f\"{subject_id}_trials.csv\"\n",
    "    events_path = subject_folder / f\"{subject_id}_events.csv\"\n",
    "    # Try the enhanced version if the standard one doesn't exist\n",
    "    if not events_path.exists():\n",
    "        events_path = subject_folder / f\"{subject_id}_events_enhanced.csv\"\n",
    "\n",
    "    original_mne_events_path = subject_folder / f\"{subject_id}_events_mne.fif\"\n",
    "    original_event_id_path = subject_folder / f\"{subject_id}_event_id.json\"\n",
    "\n",
    "    # --- 2. Check if Required Files Exist ---\n",
    "    required_files = [trials_path, events_path, original_mne_events_path, original_event_id_path]\n",
    "    missing_files = [f for f in required_files if not f.exists()]\n",
    "\n",
    "    if missing_files:\n",
    "        print(f\"  ⚠️ Skipping {subject_id}. Missing files: {[f.name for f in missing_files]}\")\n",
    "        return False # Indicate failure\n",
    "\n",
    "    # --- 3. Load Data for this Subject ---\n",
    "    try:\n",
    "        # Load DataFrames (optional for verification, but good to have)\n",
    "        # trials_df = pd.read_csv(trials_path) # Not strictly necessary for this function\n",
    "        # events_df = pd.read_csv(events_path) # Not strictly necessary for this function\n",
    "        # print(f\"  ✅ Loaded CSV data.\")\n",
    "\n",
    "        # Load original MNE Events and ID mapping\n",
    "        original_mne_events = mne.read_events(str(original_mne_events_path))\n",
    "        with open(original_event_id_path, 'r') as f:\n",
    "            original_event_id_mapping = json.load(f)\n",
    "        print(f\"  ✅ Loaded original MNE events ({original_mne_events.shape}) and ID mapping.\")\n",
    "        print(f\"     Original ID Mapping: {original_event_id_mapping}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  ⚠️ Error loading data for {subject_id}: {e}\")\n",
    "        return False\n",
    "\n",
    "    # --- 4. Prepare for Binary Recoding ---\n",
    "    # Define the mapping from ORIGINAL event IDs to NEW binary IDs\n",
    "    # Goal: 0: In-Phase, 1: Out-of-Phase (Anti-Phase + Breakdown)\n",
    "    id_transformation_map = {}\n",
    "\n",
    "    # Find the ID for 'In-Phase Event' and map it to 0\n",
    "    in_phase_id = original_event_id_mapping.get('In-Phase Event')\n",
    "    if in_phase_id is not None:\n",
    "        id_transformation_map[in_phase_id] = 0\n",
    "    else:\n",
    "        print(f\"  ⚠️ 'In-Phase Event' not found in original mapping for {subject_id}. Skipping recoding.\")\n",
    "        return False\n",
    "\n",
    "    # Find IDs for 'Anti-Phase Event' and 'In-Phase Breakdown' and map them to 1\n",
    "    anti_phase_id = original_event_id_mapping.get('Anti-Phase Event')\n",
    "    if anti_phase_id is not None:\n",
    "        id_transformation_map[anti_phase_id] = 1\n",
    "\n",
    "    breakdown_id = original_event_id_mapping.get('In-Phase Breakdown')\n",
    "    if breakdown_id is not None:\n",
    "        id_transformation_map[breakdown_id] = 1\n",
    "\n",
    "    if len(id_transformation_map) < 2: # Need at least In-Phase ID and one Out-of-Phase ID\n",
    "        print(f\"  ⚠️ Incomplete original mapping for {subject_id}. Found IDs: {id_transformation_map}. Skipping recoding.\")\n",
    "        return False\n",
    "\n",
    "    print(f\"  🔄 ID Transformation Map: {id_transformation_map}\")\n",
    "\n",
    "    # --- 5. Modify the Existing MNE Events Array ---\n",
    "    try:\n",
    "        binary_mne_events_array = original_mne_events.copy()\n",
    "        original_ids = binary_mne_events_array[:, 2]\n",
    "\n",
    "        # Recode IDs\n",
    "        unique_original_ids_in_data = np.unique(original_ids)\n",
    "        print(f\"  📊 Unique original IDs in data: {unique_original_ids_in_data}\")\n",
    "\n",
    "        for orig_id in unique_original_ids_in_data:\n",
    "            new_id = id_transformation_map.get(orig_id)\n",
    "            if new_id is not None:\n",
    "                indices_to_change = np.where(original_ids == orig_id)[0]\n",
    "                binary_mne_events_array[indices_to_change, 2] = new_id\n",
    "                # Get original type name for reporting\n",
    "                old_type = [k for k, v in original_event_id_mapping.items() if v == orig_id][0]\n",
    "                new_type = \"In-Phase\" if new_id == 0 else \"Out-of-Phase\"\n",
    "                print(f\"    Recoded {len(indices_to_change)} events: {old_type} (ID {orig_id}) -> {new_type} (ID {new_id})\")\n",
    "            else:\n",
    "                print(f\"    ⚠️ No mapping for original ID {orig_id}. Events unchanged.\")\n",
    "\n",
    "        print(f\"  ✅ Modified MNE events array. Shape: {binary_mne_events_array.shape}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  ⚠️ Error modifying MNE events for {subject_id}: {e}\")\n",
    "        return False\n",
    "\n",
    "    # --- 6. Define New Event ID Mapping ---\n",
    "    new_mne_event_id = {\n",
    "        'In-Phase': 0,\n",
    "        'Out-of-Phase': 1 # This now includes both Anti-Phase Events and Breakdowns\n",
    "    }\n",
    "    print(f\"  🆕 New MNE Event ID Mapping: {new_mne_event_id}\")\n",
    "\n",
    "    # --- 7. Save New Binary Files ---\n",
    "    try:\n",
    "        # New filenames (using MNE's recommended naming convention)\n",
    "        binary_events_fif_path = subject_folder / f\"{subject_id}_events_mne{binary_suffix}-eve.fif\"\n",
    "        binary_events_txt_path = subject_folder / f\"{subject_id}_events_mne{binary_suffix}-eve.txt\" # Optional\n",
    "        new_event_id_json_path = subject_folder / f\"{subject_id}_event_id{binary_suffix}.json\"\n",
    "\n",
    "        # Save the BINARY MNE events (binary .fif - Correct Format)\n",
    "        mne.write_events(str(binary_events_fif_path), binary_mne_events_array, overwrite=True)\n",
    "        print(f\"  💾 Saved BINARY MNE events (.fif): {binary_events_fif_path.name}\")\n",
    "\n",
    "        # Save the BINARY MNE events (text .txt - Optional)\n",
    "        mne.write_events(str(binary_events_txt_path), binary_mne_events_array, overwrite=True)\n",
    "        print(f\"  💾 Saved BINARY MNE events (.txt): {binary_events_txt_path.name}\")\n",
    "\n",
    "        # Save the NEW event ID mapping (JSON)\n",
    "        with open(new_event_id_json_path, 'w') as f:\n",
    "            json.dump(new_mne_event_id, f, indent=2)\n",
    "        print(f\"  💾 Saved NEW event ID mapping: {new_event_id_json_path.name}\")\n",
    "\n",
    "        print(f\"  ✅ Successfully processed and saved binary files for {subject_id}.\")\n",
    "        return True # Indicate success\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  ⚠️ Error saving new files for {subject_id}: {e}\")\n",
    "        return False # Indicate failure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b90a8fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found EEG file for Sbj06: PD_006_bima_DBSOFF.mff\n",
      "\n",
      "--- STEP 1: Initializing Analyzer for Sbj06 ---\n",
      "✅ Analyzer initialized.\n",
      "\n",
      "--- STEP 2: Loading Behavioral Data for Sbj06 ---\n",
      "Loading behavioral data for Sbj06...\n",
      "✓ Loaded 31491 frames, duration: 524.8s\n",
      "✅ Behavioral data loaded.\n",
      "\n",
      "--- STEP 3: Preprocessing Signals for Sbj06 ---\n",
      "✅ Signals preprocessed.\n",
      "\n",
      "--- STEP 4: Analyzing Coordination for Sbj06 ---\n",
      "✅ Coordination analyzed.\n",
      "\n",
      "--- STEP 5: Detecting Events for Sbj06 ---\n",
      "\n",
      "📊 Sbj06 ENHANCED COORDINATION ANALYSIS\n",
      "————————————————————————————————————————————————————————————\n",
      "Total events detected: 363\n",
      "Event type distribution:\n",
      "  In-Phase Event: 187\n",
      "  In-Phase Breakdown: 65\n",
      "  Anti-Phase Event: 111\n",
      "In-phase time: 90.5%\n",
      "Anti-phase time: 9.5%\n",
      "✅ Events detected.\n",
      "\n",
      "--- STOPPING POINT: Inspect and Edit analyzer.event_df ---\n",
      "Location of event_df: analyzer.event_df\n",
      "Shape of event_df: (363, 4)\n",
      "Columns: ['time_s', 'frame', 'type', 'subject_id']\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration for Single Subject ---\n",
    "# 1. SET YOUR MAIN DATA DIRECTORY\n",
    "data_dir = Path(r\"C:\\Users\\lacom\\Downloads\\xtra\\data\\PD_Keypoints\")  # <-- CHANGE THIS!\n",
    "\n",
    "# 2. SPECIFY THE SUBJECT YOU WANT TO PROCESS (e.g., \"Sbj01\", \"Sbj02\")\n",
    "target_subject_id = \"Sbj06\"  # <-- CHANGE THIS TO THE SUBJECT YOU WANT TO RUN!\n",
    "\n",
    "# 3. OUTPUT DIRECTORY NAME\n",
    "output_dir_main = \"results_Enhanced_PD_Analysis\"\n",
    "\n",
    "# --- Find Files for the Target Subject ---\n",
    "keypoint_files = list(data_dir.glob(f\"{target_subject_id}_task_hand_keypoints_cam0.json\"))\n",
    "if not keypoint_files:\n",
    "    raise FileNotFoundError(f\"Keypoint file for {target_subject_id} not found in {data_dir}\")\n",
    "behavioral_file = str(keypoint_files[0])\n",
    "\n",
    "# Find corresponding EEG directory\n",
    "eeg_mff_dirs = [p for p in data_dir.iterdir() if p.is_dir() and p.name.startswith(f\"PD_{int(target_subject_id.replace('Sbj', '')):03d}_\")]\n",
    "eeg_config = None\n",
    "if eeg_mff_dirs:\n",
    "    eeg_mff_path = eeg_mff_dirs[0]\n",
    "    eeg_config = {\n",
    "        \"base_path\": str(data_dir),\n",
    "        \"mff_filename\": eeg_mff_path.name,\n",
    "        \"config\": { # Nesting config as expected by EEGTrialTracker\n",
    "            'trial_gap_threshold_s': 2.5,\n",
    "            'extension_duration_s': 4.3,\n",
    "            'eeg_to_behavior_delay': 0.1,\n",
    "            'stim_channels': ['TT140', 'TT255', '1a', '2a', '3a', '4a', '5a', '6a'],\n",
    "            'pacing_channels': ['1a', '2a', '3a', '4a', '5a', '6a']\n",
    "        }\n",
    "    }\n",
    "    print(f\"✅ Found EEG file for {target_subject_id}: {eeg_mff_path.name}\")\n",
    "else:\n",
    "    print(f\"⚠️ No matching EEG file found for {target_subject_id}\")\n",
    "\n",
    "# Analysis configuration\n",
    "analysis_config = {\n",
    "    'breakdown_std_threshold': 0.60,\n",
    "    'target_in_phase_events': 280,\n",
    "    'anti_phase_threshold_rad': 5 * np.pi / 6,\n",
    "    'keypoint_index': 8,\n",
    "    'sample_rate': 60.0,\n",
    "    'window_sec': 0.5,\n",
    "    'window_size_ratio': 0.5,\n",
    "    'initial_window_ratio': 1.0,\n",
    "    'grouping_window_ratio': 0.5,\n",
    "    'filter_lowcut': 0.5,\n",
    "    'filter_highcut': 10.0\n",
    "}\n",
    "\n",
    "# --- STEP 1: Initialize Analyzer ---\n",
    "print(f\"\\n--- STEP 1: Initializing Analyzer for {target_subject_id} ---\")\n",
    "analyzer = CoordinationAnalyzer(target_subject_id, analysis_config)\n",
    "print(\"✅ Analyzer initialized.\")\n",
    "\n",
    "# --- STEP 2: Load Behavioral Data ---\n",
    "print(f\"\\n--- STEP 2: Loading Behavioral Data for {target_subject_id} ---\")\n",
    "analyzer.load_behavioral_data(behavioral_file)\n",
    "print(\"✅ Behavioral data loaded.\")\n",
    "\n",
    "# --- STEP 3: Preprocess Signals ---\n",
    "print(f\"\\n--- STEP 3: Preprocessing Signals for {target_subject_id} ---\")\n",
    "analyzer.preprocess_signals()\n",
    "print(\"✅ Signals preprocessed.\")\n",
    "\n",
    "# --- STEP 4: Analyze Coordination ---\n",
    "print(f\"\\n--- STEP 4: Analyzing Coordination for {target_subject_id} ---\")\n",
    "analyzer.analyze_coordination()\n",
    "print(\"✅ Coordination analyzed.\")\n",
    "\n",
    "# --- STEP 5: Detect Events ---\n",
    "print(f\"\\n--- STEP 5: Detecting Events for {target_subject_id} ---\")\n",
    "analyzer.detect_events()\n",
    "print(\"✅ Events detected.\")\n",
    "\n",
    "# --- STOPPING POINT ---\n",
    "print(f\"\\n--- STOPPING POINT: Inspect and Edit analyzer.event_df ---\")\n",
    "print(f\"Location of event_df: analyzer.event_df\")\n",
    "print(f\"Shape of event_df: {analyzer.event_df.shape}\")\n",
    "print(f\"Columns: {list(analyzer.event_df.columns)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "587a3f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "time_s",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "frame",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "subject_id",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "950d1621-fc83-4524-980a-7486b429f85e",
       "rows": [
        [
         "0",
         "0.0",
         "0",
         "In-Phase Event",
         "Sbj06"
        ],
        [
         "1",
         "4.18",
         "251",
         "In-Phase Event",
         "Sbj06"
        ],
        [
         "2",
         "8.37",
         "502",
         "In-Phase Event",
         "Sbj06"
        ],
        [
         "3",
         "12.55",
         "753",
         "In-Phase Event",
         "Sbj06"
        ],
        [
         "4",
         "16.73",
         "1004",
         "In-Phase Event",
         "Sbj06"
        ],
        [
         "5",
         "20.73",
         "1244",
         "In-Phase Breakdown",
         "Sbj06"
        ],
        [
         "6",
         "20.92",
         "1255",
         "In-Phase Event",
         "Sbj06"
        ],
        [
         "7",
         "20.93",
         "1256",
         "Anti-Phase Event",
         "Sbj06"
        ],
        [
         "8",
         "21.5",
         "1290",
         "In-Phase Event",
         "Sbj06"
        ],
        [
         "9",
         "21.62",
         "1297",
         "In-Phase Breakdown",
         "Sbj06"
        ],
        [
         "10",
         "23.92",
         "1435",
         "In-Phase Breakdown",
         "Sbj06"
        ],
        [
         "11",
         "24.17",
         "1450",
         "Anti-Phase Event",
         "Sbj06"
        ],
        [
         "12",
         "24.6",
         "1476",
         "In-Phase Breakdown",
         "Sbj06"
        ],
        [
         "13",
         "24.63",
         "1478",
         "In-Phase Event",
         "Sbj06"
        ],
        [
         "14",
         "25.42",
         "1525",
         "In-Phase Breakdown",
         "Sbj06"
        ],
        [
         "15",
         "25.67",
         "1540",
         "Anti-Phase Event",
         "Sbj06"
        ],
        [
         "16",
         "27.78",
         "1667",
         "In-Phase Breakdown",
         "Sbj06"
        ],
        [
         "17",
         "27.78",
         "1667",
         "In-Phase Event",
         "Sbj06"
        ],
        [
         "18",
         "28.0",
         "1680",
         "Anti-Phase Event",
         "Sbj06"
        ],
        [
         "19",
         "28.97",
         "1738",
         "In-Phase Breakdown",
         "Sbj06"
        ],
        [
         "20",
         "29.2",
         "1752",
         "Anti-Phase Event",
         "Sbj06"
        ],
        [
         "21",
         "30.2",
         "1812",
         "Anti-Phase Event",
         "Sbj06"
        ],
        [
         "22",
         "31.57",
         "1894",
         "In-Phase Event",
         "Sbj06"
        ],
        [
         "23",
         "32.43",
         "1946",
         "Anti-Phase Event",
         "Sbj06"
        ],
        [
         "24",
         "33.27",
         "1996",
         "In-Phase Breakdown",
         "Sbj06"
        ],
        [
         "25",
         "33.98",
         "2039",
         "Anti-Phase Event",
         "Sbj06"
        ],
        [
         "26",
         "35.13",
         "2108",
         "In-Phase Event",
         "Sbj06"
        ],
        [
         "27",
         "35.52",
         "2131",
         "Anti-Phase Event",
         "Sbj06"
        ],
        [
         "28",
         "36.25",
         "2175",
         "In-Phase Breakdown",
         "Sbj06"
        ],
        [
         "29",
         "36.4",
         "2184",
         "Anti-Phase Event",
         "Sbj06"
        ],
        [
         "30",
         "37.62",
         "2257",
         "Anti-Phase Event",
         "Sbj06"
        ],
        [
         "31",
         "37.8",
         "2268",
         "In-Phase Breakdown",
         "Sbj06"
        ],
        [
         "32",
         "38.52",
         "2311",
         "In-Phase Event",
         "Sbj06"
        ],
        [
         "33",
         "38.53",
         "2312",
         "Anti-Phase Event",
         "Sbj06"
        ],
        [
         "34",
         "39.63",
         "2378",
         "In-Phase Event",
         "Sbj06"
        ],
        [
         "35",
         "39.95",
         "2397",
         "In-Phase Event",
         "Sbj06"
        ],
        [
         "36",
         "40.35",
         "2421",
         "In-Phase Event",
         "Sbj06"
        ],
        [
         "37",
         "40.67",
         "2440",
         "In-Phase Event",
         "Sbj06"
        ],
        [
         "38",
         "40.77",
         "2446",
         "Anti-Phase Event",
         "Sbj06"
        ],
        [
         "39",
         "41.17",
         "2470",
         "In-Phase Event",
         "Sbj06"
        ],
        [
         "40",
         "41.48",
         "2489",
         "In-Phase Event",
         "Sbj06"
        ],
        [
         "41",
         "41.52",
         "2491",
         "Anti-Phase Event",
         "Sbj06"
        ],
        [
         "42",
         "42.37",
         "2542",
         "In-Phase Event",
         "Sbj06"
        ],
        [
         "43",
         "42.83",
         "2570",
         "In-Phase Breakdown",
         "Sbj06"
        ],
        [
         "44",
         "43.78",
         "2627",
         "In-Phase Event",
         "Sbj06"
        ],
        [
         "45",
         "45.0",
         "2700",
         "In-Phase Event",
         "Sbj06"
        ],
        [
         "46",
         "46.22",
         "2773",
         "In-Phase Event",
         "Sbj06"
        ],
        [
         "47",
         "47.28",
         "2837",
         "In-Phase Breakdown",
         "Sbj06"
        ],
        [
         "48",
         "47.43",
         "2846",
         "Anti-Phase Event",
         "Sbj06"
        ],
        [
         "49",
         "47.5",
         "2850",
         "In-Phase Event",
         "Sbj06"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 363
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_s</th>\n",
       "      <th>frame</th>\n",
       "      <th>type</th>\n",
       "      <th>subject_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>In-Phase Event</td>\n",
       "      <td>Sbj06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.18</td>\n",
       "      <td>251</td>\n",
       "      <td>In-Phase Event</td>\n",
       "      <td>Sbj06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.37</td>\n",
       "      <td>502</td>\n",
       "      <td>In-Phase Event</td>\n",
       "      <td>Sbj06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.55</td>\n",
       "      <td>753</td>\n",
       "      <td>In-Phase Event</td>\n",
       "      <td>Sbj06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.73</td>\n",
       "      <td>1004</td>\n",
       "      <td>In-Phase Event</td>\n",
       "      <td>Sbj06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>524.38</td>\n",
       "      <td>31463</td>\n",
       "      <td>In-Phase Breakdown</td>\n",
       "      <td>Sbj06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>524.45</td>\n",
       "      <td>31467</td>\n",
       "      <td>In-Phase Event</td>\n",
       "      <td>Sbj06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>524.55</td>\n",
       "      <td>31473</td>\n",
       "      <td>In-Phase Event</td>\n",
       "      <td>Sbj06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>524.65</td>\n",
       "      <td>31479</td>\n",
       "      <td>In-Phase Event</td>\n",
       "      <td>Sbj06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>524.75</td>\n",
       "      <td>31485</td>\n",
       "      <td>In-Phase Event</td>\n",
       "      <td>Sbj06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>363 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     time_s  frame                type subject_id\n",
       "0      0.00      0      In-Phase Event      Sbj06\n",
       "1      4.18    251      In-Phase Event      Sbj06\n",
       "2      8.37    502      In-Phase Event      Sbj06\n",
       "3     12.55    753      In-Phase Event      Sbj06\n",
       "4     16.73   1004      In-Phase Event      Sbj06\n",
       "..      ...    ...                 ...        ...\n",
       "358  524.38  31463  In-Phase Breakdown      Sbj06\n",
       "359  524.45  31467      In-Phase Event      Sbj06\n",
       "360  524.55  31473      In-Phase Event      Sbj06\n",
       "361  524.65  31479      In-Phase Event      Sbj06\n",
       "362  524.75  31485      In-Phase Event      Sbj06\n",
       "\n",
       "[363 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.event_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db83e13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Drop rows with DataFrame index\n",
    "#analyzer.event_df = analyzer.event_df.drop(index=[5, 10, 15]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3da84f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- STEP 6a: Aligning with EEG for Sbj06 ---\n",
      "🧠 Adding enhanced stim_channel info for Sbj06...\n",
      "✅ Enhanced stim_channel added for Sbj06\n",
      "✅ EEG alignment complete for Sbj06\n",
      "✅ EEG alignment complete.\n",
      "\n",
      "--- STEP 6b: Saving MNE Events for Sbj06 ---\n",
      "✅ Saved MNE events: results_Enhanced_PD_Analysis\\Sbj06\\Sbj06_events_mne.fif\n",
      "✅ Saved event ID mapping: results_Enhanced_PD_Analysis\\Sbj06\\Sbj06_event_id.json\n",
      "✅ MNE events saved.\n",
      "\n",
      "--- STEP 6c: Creating Binary MNE Events for Sbj06 ---\n",
      "  ⚠️ Skipping binary creation for Sbj06. Missing files: ['Sbj06_events_enhanced.csv']\n",
      "\n",
      "--- STEP 7: Creating Plots for Sbj06 ---\n",
      "✅ Saved coordination analysis plot: Sbj06_coordination_analysis.png\n",
      "✅ Saved enhanced variability plot: Sbj06_enhanced_variability.png\n",
      "✅ Plots created.\n",
      "\n",
      "--- STEP 8: Saving Event and Trial Data for Sbj06 ---\n",
      "✅ Saved (potentially modified) events: results_Enhanced_PD_Analysis\\Sbj06\\Sbj06_events.csv\n",
      "✅ Saved trials: results_Enhanced_PD_Analysis\\Sbj06\\Sbj06_trials.csv\n",
      "\n",
      "--- STEP 8b: Creating Binary MNE Events for Sbj06 ---\n",
      "\n",
      "--- Creating Binary MNE Events for Subject: Sbj06 ---\n",
      "  ✅ Loaded original MNE events ((363, 3)) and ID mapping.\n",
      "     Original ID Mapping: {'In-Phase Event': 1, 'In-Phase Breakdown': 2, 'Anti-Phase Event': 3}\n",
      "  🔄 ID Transformation Map: {1: 0, 3: 1, 2: 1}\n",
      "  📊 Unique original IDs in data: [1 2 3]\n",
      "    Recoded 187 events: In-Phase Event (ID 1) -> In-Phase (ID 0)\n",
      "    Recoded 65 events: In-Phase Breakdown (ID 2) -> Out-of-Phase (ID 1)\n",
      "    Recoded 111 events: Anti-Phase Event (ID 3) -> Out-of-Phase (ID 1)\n",
      "  ✅ Modified MNE events array. Shape: (363, 3)\n",
      "  🆕 New MNE Event ID Mapping: {'In-Phase': 0, 'Out-of-Phase': 1}\n",
      "  💾 Saved BINARY MNE events (.fif): Sbj06_events_mne_binary-eve.fif\n",
      "  💾 Saved BINARY MNE events (.txt): Sbj06_events_mne_binary-eve.txt\n",
      "  💾 Saved NEW event ID mapping: Sbj06_event_id_binary.json\n",
      "  ✅ Successfully processed and saved binary files for Sbj06.\n",
      "  ✅ Binary MNE events created successfully for Sbj06.\n",
      "\n",
      "🎉 Processing for Sbj06 complete (up to manual editing point)!\n",
      "📁 Results saved to: results_Enhanced_PD_Analysis\\Sbj06\n"
     ]
    }
   ],
   "source": [
    "# --- STEP 6: Align with EEG (if applicable) and Save MNE Events ---\n",
    "# This step will use the (potentially modified) analyzer.event_df\n",
    "if eeg_config:\n",
    "    print(f\"\\n--- STEP 6a: Aligning with EEG for {target_subject_id} ---\")\n",
    "    tracker = EEGTrialTracker(target_subject_id, **eeg_config)\n",
    "    analyzer = tracker.load_and_align(analyzer)\n",
    "    print(\"✅ EEG alignment complete.\")\n",
    "\n",
    "    print(f\"\\n--- STEP 6b: Saving MNE Events for {target_subject_id} ---\")\n",
    "    tracker.save_events_to_mne_format(analyzer, output_dir_main)\n",
    "    print(\"✅ MNE events saved.\")\n",
    "    \n",
    "    # --- NEW STEP 6c: Create Binary MNE Events ---\n",
    "    print(f\"\\n--- STEP 6c: Creating Binary MNE Events for {target_subject_id} ---\")\n",
    "    try:\n",
    "        # Define paths for the current subject\n",
    "        subject_folder = Path(output_dir_main) / target_subject_id\n",
    "        binary_suffix = \"_binary\"\n",
    "        \n",
    "        # File paths\n",
    "        events_path = subject_folder / f\"{target_subject_id}_events.csv\"\n",
    "        if not events_path.exists():\n",
    "            events_path = subject_folder / f\"{target_subject_id}_events_enhanced.csv\"\n",
    "            \n",
    "        original_mne_events_path = subject_folder / f\"{target_subject_id}_events_mne.fif\"\n",
    "        original_event_id_path = subject_folder / f\"{target_subject_id}_event_id.json\"\n",
    "        \n",
    "        # Check if required files exist\n",
    "        required_files = [events_path, original_mne_events_path, original_event_id_path]\n",
    "        missing_files = [f for f in required_files if not f.exists()]\n",
    "        \n",
    "        if missing_files:\n",
    "            print(f\"  ⚠️ Skipping binary creation for {target_subject_id}. Missing files: {[f.name for f in missing_files]}\")\n",
    "        else:\n",
    "            # Load original MNE Events and ID mapping\n",
    "            original_mne_events = mne.read_events(str(original_mne_events_path))\n",
    "            with open(original_event_id_path, 'r') as f:\n",
    "                original_event_id_mapping = json.load(f)\n",
    "            print(f\"  ✅ Loaded original MNE events ({original_mne_events.shape}) and ID mapping.\")\n",
    "            \n",
    "            # Prepare for Binary Recoding\n",
    "            id_transformation_map = {}\n",
    "            \n",
    "            # Find the ID for 'In-Phase Event' and map it to 0\n",
    "            in_phase_id = original_event_id_mapping.get('In-Phase Event')\n",
    "            if in_phase_id is not None:\n",
    "                id_transformation_map[in_phase_id] = 0\n",
    "            else:\n",
    "                print(f\"  ⚠️ 'In-Phase Event' not found in original mapping for {target_subject_id}. Skipping binary recoding.\")\n",
    "                \n",
    "            # Find IDs for 'Anti-Phase Event' and 'In-Phase Breakdown' and map them to 1\n",
    "            anti_phase_id = original_event_id_mapping.get('Anti-Phase Event')\n",
    "            if anti_phase_id is not None:\n",
    "                id_transformation_map[anti_phase_id] = 1\n",
    "                \n",
    "            breakdown_id = original_event_id_mapping.get('In-Phase Breakdown')\n",
    "            if breakdown_id is not None:\n",
    "                id_transformation_map[breakdown_id] = 1\n",
    "                \n",
    "            if len(id_transformation_map) < 2: # Need at least In-Phase ID and one Out-of-Phase ID\n",
    "                print(f\"  ⚠️ Incomplete original mapping for {target_subject_id}. Found IDs: {id_transformation_map}. Skipping binary recoding.\")\n",
    "            else:\n",
    "                print(f\"  🔄 ID Transformation Map: {id_transformation_map}\")\n",
    "                \n",
    "                # Modify the Existing MNE Events Array\n",
    "                binary_mne_events_array = original_mne_events.copy()\n",
    "                original_ids = binary_mne_events_array[:, 2]\n",
    "                \n",
    "                # Recode IDs\n",
    "                unique_original_ids_in_data = np.unique(original_ids)\n",
    "                print(f\"  📊 Unique original IDs in data: {unique_original_ids_in_data}\")\n",
    "                \n",
    "                for orig_id in unique_original_ids_in_data:\n",
    "                    new_id = id_transformation_map.get(orig_id)\n",
    "                    if new_id is not None:\n",
    "                        indices_to_change = np.where(original_ids == orig_id)[0]\n",
    "                        binary_mne_events_array[indices_to_change, 2] = new_id\n",
    "                        # Get original type name for reporting\n",
    "                        old_type = [k for k, v in original_event_id_mapping.items() if v == orig_id][0]\n",
    "                        new_type = \"In-Phase\" if new_id == 0 else \"Out-of-Phase\"\n",
    "                        print(f\"    Recoded {len(indices_to_change)} events: {old_type} (ID {orig_id}) -> {new_type} (ID {new_id})\")\n",
    "                    else:\n",
    "                        print(f\"    ⚠️ No mapping for original ID {orig_id}. Events unchanged.\")\n",
    "                        \n",
    "                print(f\"  ✅ Modified MNE events array. Shape: {binary_mne_events_array.shape}\")\n",
    "                \n",
    "                # Define New Event ID Mapping\n",
    "                new_mne_event_id = {\n",
    "                    'In-Phase': 0,\n",
    "                    'Out-of-Phase': 1 # This now includes both Anti-Phase Events and Breakdowns\n",
    "                }\n",
    "                print(f\"  🆕 New MNE Event ID Mapping: {new_mne_event_id}\")\n",
    "                \n",
    "                # Save New Binary Files\n",
    "                # New filenames (using MNE's recommended naming convention)\n",
    "                binary_events_fif_path = subject_folder / f\"{target_subject_id}_events_mne{binary_suffix}-eve.fif\"\n",
    "                binary_events_txt_path = subject_folder / f\"{target_subject_id}_events_mne{binary_suffix}-eve.txt\" # Optional\n",
    "                new_event_id_json_path = subject_folder / f\"{target_subject_id}_event_id{binary_suffix}.json\"\n",
    "                \n",
    "                # Save the BINARY MNE events (binary .fif - Correct Format)\n",
    "                mne.write_events(str(binary_events_fif_path), binary_mne_events_array, overwrite=True)\n",
    "                print(f\"  💾 Saved BINARY MNE events (.fif): {binary_events_fif_path.name}\")\n",
    "                \n",
    "                # Save the BINARY MNE events (text .txt - Optional)\n",
    "                mne.write_events(str(binary_events_txt_path), binary_mne_events_array, overwrite=True)\n",
    "                print(f\"  💾 Saved BINARY MNE events (.txt): {binary_events_txt_path.name}\")\n",
    "                \n",
    "                # Save the NEW event ID mapping (JSON)\n",
    "                with open(new_event_id_json_path, 'w') as f:\n",
    "                    json.dump(new_mne_event_id, f, indent=2)\n",
    "                print(f\"  💾 Saved NEW event ID mapping: {new_event_id_json_path.name}\")\n",
    "                \n",
    "                print(f\"  ✅ Successfully created binary files for {target_subject_id}.\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"  ⚠️ Error creating binary MNE events for {target_subject_id}: {e}\")\n",
    "\n",
    "# --- STEP 7: Create Plots ---\n",
    "print(f\"\\n--- STEP 7: Creating Plots for {target_subject_id} ---\")\n",
    "output_path = Path(output_dir_main) / target_subject_id\n",
    "output_path.mkdir(parents=True, exist_ok=True)\n",
    "analyzer.create_plots(output_path)\n",
    "print(\"✅ Plots created.\")\n",
    "\n",
    "# --- STEP 8: Save Event and Trial Data ---\n",
    "print(f\"\\n--- STEP 8: Saving Event and Trial Data for {target_subject_id} ---\")\n",
    "if not analyzer.event_df.empty:\n",
    "    # Save the potentially modified event_df\n",
    "    event_file = output_path / f\"{target_subject_id}_events.csv\"\n",
    "    analyzer.event_df.to_csv(event_file, index=False)\n",
    "    print(f\"✅ Saved (potentially modified) events: {event_file}\")\n",
    "\n",
    "if hasattr(analyzer, 'trials_df') and analyzer.trials_df is not None and not analyzer.trials_df.empty:\n",
    "    trial_file = output_path / f\"{target_subject_id}_trials.csv\"\n",
    "    analyzer.trials_df.to_csv(trial_file, index=False)\n",
    "    print(f\"✅ Saved trials: {trial_file}\")\n",
    "\n",
    "# --- NEW STEP 8b: Create Binary MNE Events (using the new function) ---\n",
    "print(f\"\\n--- STEP 8b: Creating Binary MNE Events for {target_subject_id} ---\")\n",
    "success = create_binary_mne_events_for_subject(target_subject_id, output_dir_main, binary_suffix=\"_binary\")\n",
    "if success:\n",
    "    print(f\"  ✅ Binary MNE events created successfully for {target_subject_id}.\")\n",
    "else:\n",
    "    print(f\"  ⚠️ Failed to create binary MNE events for {target_subject_id}.\")\n",
    "\n",
    "print(f\"\\n🎉 Processing for {target_subject_id} complete (up to manual editing point)!\")\n",
    "print(f\"📁 Results saved to: {output_path}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1dd613b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- STEP 9: Creating Enhanced Trial Plots for Sbj06 ---\n",
      "Found trial data. Generating plots...\n",
      "\n",
      "🔄 Plotting first 50s (EEG time) of 10 trial(s) for Sbj06...\n",
      "   📊 Found 59 events for trial 1 within EEG time 46.19s - 96.19s\n",
      "   🎛️ Stim channels in this segment: ['1a', '2a', '3a', '4a', '5a', '6a']\n",
      "📈 Enhanced trial plot saved: Sbj06, Trial 1 | EEG Duration: 50.00s\n",
      "   🔴 Events in plotted segment: 59\n",
      "     • Stim 6a: 15 events\n",
      "     • Stim 3a: 12 events\n",
      "     • Stim 5a: 12 events\n",
      "     • Stim 4a: 10 events\n",
      "     • Stim 2a: 6 events\n",
      "     • Stim 1a: 4 events\n",
      "   📊 Found 20 events for trial 2 within EEG time 98.95s - 148.95s\n",
      "   🎛️ Stim channels in this segment: ['1a', '2a', '3a', '5a', '6a']\n",
      "📈 Enhanced trial plot saved: Sbj06, Trial 2 | EEG Duration: 50.00s\n",
      "   🔴 Events in plotted segment: 20\n",
      "     • Stim 1a: 11 events\n",
      "     • Stim 6a: 6 events\n",
      "     • Stim 2a: 1 events\n",
      "     • Stim 3a: 1 events\n",
      "     • Stim 5a: 1 events\n",
      "   📊 Found 32 events for trial 3 within EEG time 151.68s - 201.68s\n",
      "   🎛️ Stim channels in this segment: ['1a', '2a', '3a', '4a', '5a', '6a']\n",
      "📈 Enhanced trial plot saved: Sbj06, Trial 3 | EEG Duration: 50.00s\n",
      "   🔴 Events in plotted segment: 32\n",
      "     • Stim 1a: 10 events\n",
      "     • Stim 6a: 7 events\n",
      "     • Stim 5a: 7 events\n",
      "     • Stim 4a: 5 events\n",
      "     • Stim 2a: 2 events\n",
      "     • Stim 3a: 1 events\n",
      "   📊 Found 15 events for trial 4 within EEG time 204.42s - 254.42s\n",
      "   🎛️ Stim channels in this segment: ['1a', '2a', '4a', '5a', '6a']\n",
      "📈 Enhanced trial plot saved: Sbj06, Trial 4 | EEG Duration: 50.00s\n",
      "   🔴 Events in plotted segment: 15\n",
      "     • Stim 6a: 5 events\n",
      "     • Stim 1a: 4 events\n",
      "     • Stim 4a: 3 events\n",
      "     • Stim 5a: 2 events\n",
      "     • Stim 2a: 1 events\n",
      "   📊 Found 12 events for trial 5 within EEG time 257.15s - 307.15s\n",
      "   🎛️ Stim channels in this segment: ['1a', '3a', '5a', '6a']\n",
      "📈 Enhanced trial plot saved: Sbj06, Trial 5 | EEG Duration: 50.00s\n",
      "   🔴 Events in plotted segment: 12\n",
      "     • Stim 6a: 6 events\n",
      "     • Stim 3a: 3 events\n",
      "     • Stim 5a: 2 events\n",
      "     • Stim 1a: 1 events\n",
      "   📊 Found 28 events for trial 6 within EEG time 309.88s - 359.88s\n",
      "   🎛️ Stim channels in this segment: ['1a', '2a', '3a', '4a', '5a', '6a']\n",
      "📈 Enhanced trial plot saved: Sbj06, Trial 6 | EEG Duration: 50.00s\n",
      "   🔴 Events in plotted segment: 28\n",
      "     • Stim 1a: 10 events\n",
      "     • Stim 6a: 7 events\n",
      "     • Stim 4a: 3 events\n",
      "     • Stim 3a: 3 events\n",
      "     • Stim 5a: 3 events\n",
      "     • Stim 2a: 2 events\n",
      "   📊 Found 16 events for trial 7 within EEG time 362.62s - 412.62s\n",
      "   🎛️ Stim channels in this segment: ['1a', '2a', '3a', '5a', '6a']\n",
      "📈 Enhanced trial plot saved: Sbj06, Trial 7 | EEG Duration: 50.00s\n",
      "   🔴 Events in plotted segment: 16\n",
      "     • Stim 6a: 8 events\n",
      "     • Stim 3a: 3 events\n",
      "     • Stim 1a: 2 events\n",
      "     • Stim 5a: 2 events\n",
      "     • Stim 2a: 1 events\n",
      "   📊 Found 75 events for trial 8 within EEG time 415.35s - 465.35s\n",
      "   🎛️ Stim channels in this segment: ['1a', '2a', '3a', '4a', '5a', '6a']\n",
      "📈 Enhanced trial plot saved: Sbj06, Trial 8 | EEG Duration: 50.00s\n",
      "   🔴 Events in plotted segment: 75\n",
      "     • Stim 6a: 21 events\n",
      "     • Stim 4a: 17 events\n",
      "     • Stim 3a: 12 events\n",
      "     • Stim 1a: 12 events\n",
      "     • Stim 5a: 9 events\n",
      "     • Stim 2a: 4 events\n",
      "   📊 Found 35 events for trial 9 within EEG time 468.09s - 518.09s\n",
      "   🎛️ Stim channels in this segment: ['1a', '2a', '3a', '4a', '5a', '6a']\n",
      "📈 Enhanced trial plot saved: Sbj06, Trial 9 | EEG Duration: 50.00s\n",
      "   🔴 Events in plotted segment: 35\n",
      "     • Stim 4a: 12 events\n",
      "     • Stim 6a: 9 events\n",
      "     • Stim 5a: 8 events\n",
      "     • Stim 1a: 3 events\n",
      "     • Stim 3a: 2 events\n",
      "     • Stim 2a: 1 events\n",
      "   📊 Found 33 events for trial 10 within EEG time 520.82s - 570.82s\n",
      "   🎛️ Stim channels in this segment: ['1a', '2a', '3a', '4a', '5a', '6a']\n",
      "📈 Enhanced trial plot saved: Sbj06, Trial 10 | EEG Duration: 50.00s\n",
      "   🔴 Events in plotted segment: 33\n",
      "     • Stim 6a: 10 events\n",
      "     • Stim 3a: 7 events\n",
      "     • Stim 4a: 5 events\n",
      "     • Stim 5a: 5 events\n",
      "     • Stim 1a: 4 events\n",
      "     • Stim 2a: 2 events\n",
      "✅ Finished plotting enhanced trials for Sbj06 (EEG Time)\n",
      "✅ Enhanced trial plots created.\n"
     ]
    }
   ],
   "source": [
    "# --- STEP 9: Trial Visualization ---\n",
    "# This also uses the (potentially modified) event_df for marking events\n",
    "print(f\"\\n--- STEP 9: Creating Enhanced Trial Plots for {target_subject_id} ---\")\n",
    "# Check if trial data exists before plotting\n",
    "if hasattr(analyzer, 'trials_df') and analyzer.trials_df is not None and not analyzer.trials_df.empty:\n",
    "    print(f\"Found trial data. Generating plots...\")\n",
    "    plot_all_trials_for_subject(analyzer, output_dir=output_dir_main, max_trials=10, duration_limit=50)\n",
    "    print(f\"✅ Enhanced trial plots created.\")\n",
    "else:\n",
    "    print(f\"⚠️ No trial data found for {target_subject_id}. Skipping enhanced trial plots.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xtra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
