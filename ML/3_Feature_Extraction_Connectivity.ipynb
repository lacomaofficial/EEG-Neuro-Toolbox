{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6b4c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_multisubject_connectivity.py\n",
    "# Fully automatic ‚Äî adapted to your real structure and event keys.\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "from mne_connectivity import spectral_connectivity_epochs\n",
    "from nilearn import datasets\n",
    "from numpy.random import default_rng\n",
    "\n",
    "PROJECT_BASE = '/home/jaizor/jaizor/xtra'\n",
    "BASE_DIR = Path(PROJECT_BASE)\n",
    "\n",
    "\n",
    "class CleanConnectivityToCSV:\n",
    "    \"\"\"\n",
    "    Extract connectivity and save ONE clean CSV per band.\n",
    "    No .npy, no extra files. Just: (trials x connections)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, project_base, subject='sub-06'):\n",
    "        self.project_base = project_base\n",
    "        self.subject = subject\n",
    "        self.sfreq = 500.0\n",
    "        self.method = 'wpli2_debiased'\n",
    "        \n",
    "        self.bands = {\n",
    "            \"Theta\":      (4, 8),\n",
    "            \"Alpha\":      (8, 12),\n",
    "            \"Low_Beta\":   (13, 20),\n",
    "            \"High_Beta\":  (20, 30),\n",
    "            \"Low_Gamma\":  (30, 60),\n",
    "            \"High_Gamma\": (60, 120)\n",
    "        }\n",
    "\n",
    "        self.n_bootstraps = 50\n",
    "        self.chunk_size = 30\n",
    "        self.rng = default_rng(seed=42)\n",
    "        \n",
    "        self.component_names = self._load_difumo_names()\n",
    "        self.regions = self._define_brain_regions()\n",
    "        self.selected_indices = sorted(list(set(self.regions)))\n",
    "        \n",
    "        self.output_dir = f\"{project_base}/derivatives/features/{subject}\"\n",
    "        os.makedirs(self.output_dir, exist_ok=True)\n",
    "    \n",
    "    def _load_difumo_names(self):\n",
    "        print(\"üì• Loading DiFuMo 512 anatomical labels...\")\n",
    "        try:\n",
    "            atlas = datasets.fetch_atlas_difumo(dimension=512, resolution_mm=2)\n",
    "            col = 'difumo_names'\n",
    "            names = atlas.labels[col].astype(str).tolist()\n",
    "            print(f\"‚úÖ Loaded {len(names)} ROI names\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to load DiFuMo: {e}\")\n",
    "            names = [f\"Component_{i}\" for i in range(512)]\n",
    "        return names\n",
    "\n",
    "    def _define_brain_regions(self):\n",
    "        Motor_M1 = [40, 86, 198, 268, 305, 437, 458, 465]\n",
    "        Motor_SMA_Premotor = [17, 18, 288, 291, 296, 297, 302, 305, 314, 315, 335, 375, 379, 448]\n",
    "        Motor_Medial = [101, 102, 388, 409, 498]\n",
    "        Thalamus = [70, 73, 297, 334, 414, 420] \n",
    "        Basal_Ganglia = [30, 53, 224, 260, 405, 422, 109, 110, 315, 331, 467, 479, 55, 71, 307, 223]  \n",
    "        Cerebellum_Motor = [43, 47, 83, 84, 127, 183, 220, 221, 295, 304, 310, 311, 374, 378, 381, 403, 441, 490, 491]\n",
    "        Somatosensory = [44, 131, 210, 411, 413, 436]\n",
    "        Executive_Control = [3, 85, 104, 148, 184, 337, 377, 446, 447, 506, 507]\n",
    "        Interoception = [2, 387, 358, 389, 165, 469]\n",
    "        Error_Monitoring = [185, 219, 326, 473, 492]\n",
    "\n",
    "        return (Motor_M1 + Motor_SMA_Premotor + Motor_Medial + Thalamus + Basal_Ganglia + Executive_Control + Interoception + Error_Monitoring)\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"Load epochs for selected ROIs ‚Äî FIXED TO MATCH YOUR EVENT KEYS.\"\"\"\n",
    "        print(\"üì• Loading data...\")\n",
    "\n",
    "        # ‚úÖ Paths for your structure\n",
    "        data_file = f\"{self.project_base}/derivatives/lcmv/{self.subject}_bima_full_off/difumo_time_courses.npy\"\n",
    "        events_file = f\"{self.project_base}/derivatives/eeg/{self.subject}/bima_DBSOFF/{self.subject}_events_mne_binary-eve.fif\"\n",
    "        event_id_file = f\"{self.project_base}/derivatives/eeg/{self.subject}/bima_DBSOFF/{self.subject}_event_id_binary.json\"\n",
    "\n",
    "        # Load data\n",
    "        data = np.load(data_file)\n",
    "        if data.shape[0] > data.shape[1]:\n",
    "            data = data.T\n",
    "            \n",
    "        events = mne.read_events(events_file, verbose=False)\n",
    "        with open(event_id_file, 'r') as f:\n",
    "            event_id = json.load(f)\n",
    "        \n",
    "        print(f\"üîç event_id keys: {list(event_id.keys())}\")  # DEBUG\n",
    "\n",
    "        info = mne.create_info(ch_names=[f'C{i}' for i in range(512)], sfreq=self.sfreq, ch_types='misc')\n",
    "        raw = mne.io.RawArray(data, info, verbose=False)\n",
    "        \n",
    "        # ‚úÖ FIXED: Use actual keys from your JSON: \"InPhase\", \"OutofPhase\"\n",
    "        conditions = {\n",
    "            'InPhase': 'InPhase',\n",
    "            'OutofPhase': 'OutofPhase'\n",
    "        }\n",
    "        epoch_data = {}\n",
    "        \n",
    "        for raw_cond, save_cond in conditions.items():\n",
    "            if raw_cond in event_id:\n",
    "                try:\n",
    "                    epochs = mne.Epochs(raw, events, {raw_cond: event_id[raw_cond]},\n",
    "                                      tmin=0, tmax=1.5, preload=True, verbose=False, baseline=None, event_repeated='drop')\n",
    "                    data_cond = epochs.get_data()[:, self.selected_indices, :]\n",
    "                    epoch_data[save_cond] = data_cond\n",
    "                    print(f\"   ‚Ä¢ {len(data_cond)} epochs for {raw_cond}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"   ‚úó Failed to create epochs for {raw_cond}: {e}\")\n",
    "            else:\n",
    "                print(f\"   ‚ö†Ô∏è Condition '{raw_cond}' not found in event_id.\")\n",
    "\n",
    "        if not epoch_data:\n",
    "            print(\"‚ùå WARNING: No epochs created. Check event_id keys and events file.\")\n",
    "\n",
    "        return epoch_data\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Run analysis and save ONE clean CSV per band.\"\"\"\n",
    "        print(\"üöÄ Starting clean connectivity export...\")\n",
    "        \n",
    "        epoch_data = self.load_data()\n",
    "        if not epoch_data:\n",
    "            print(\"‚ùå Skipping subject ‚Äî no valid epochs.\")\n",
    "            return\n",
    "\n",
    "        n_nodes = len(self.selected_indices)\n",
    "        \n",
    "        for band_name, (fmin, fmax) in self.bands.items():\n",
    "            print(f\"\\nüåà Processing {band_name} band ({fmin}-{fmax} Hz)\")\n",
    "            \n",
    "            all_rows = []\n",
    "            \n",
    "            for condition, data_cond in epoch_data.items():\n",
    "                n_epochs = len(data_cond)\n",
    "                \n",
    "                for bootstrap_idx in range(self.n_bootstraps):\n",
    "                    try:\n",
    "                        size_to_sample = min(self.chunk_size, n_epochs)\n",
    "                        sample_idx = self.rng.choice(n_epochs, size=size_to_sample, replace=False)\n",
    "                        chunk_data = data_cond[sample_idx]\n",
    "                        \n",
    "                        con = spectral_connectivity_epochs(\n",
    "                            data=chunk_data,\n",
    "                            method=self.method,\n",
    "                            mode='multitaper',\n",
    "                            sfreq=self.sfreq,\n",
    "                            fmin=fmin,\n",
    "                            fmax=fmax,\n",
    "                            faverage=True,\n",
    "                            verbose=False,\n",
    "                            n_jobs=1\n",
    "                        )\n",
    "                        matrix = con.get_data(output='dense').squeeze()\n",
    "                        matrix = (matrix + matrix.T) / 2\n",
    "                        np.fill_diagonal(matrix, 0)\n",
    "                        \n",
    "                        row = {'condition': condition, 'bootstrap': bootstrap_idx}\n",
    "                        \n",
    "                        for i in range(n_nodes):\n",
    "                            for j in range(i + 1, n_nodes):\n",
    "                                name_i = self.component_names[self.selected_indices[i]]\n",
    "                                name_j = self.component_names[self.selected_indices[j]]\n",
    "                                conn_name = f\"{name_i} ‚Üî {name_j}\"\n",
    "                                row[conn_name] = matrix[i, j]\n",
    "                        \n",
    "                        all_rows.append(row)\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"  ‚úó Bootstrap {bootstrap_idx+1} failed: {str(e)}\")\n",
    "                        continue\n",
    "            \n",
    "            if not all_rows:\n",
    "                print(f\"‚ö†Ô∏è  No connectivity data generated for {band_name}.\")\n",
    "                continue\n",
    "\n",
    "            df = pd.DataFrame(all_rows)\n",
    "            file_path = f\"{self.output_dir}/ml_features_{band_name}.csv\"\n",
    "            df.to_csv(file_path, index=False)\n",
    "            print(f\"‚úÖ Saved {band_name}: {df.shape} ‚Üí {file_path}\")\n",
    "\n",
    "\n",
    "def find_all_subjects(base_dir: Path):\n",
    "    \"\"\"Find all subjects with complete data.\"\"\"\n",
    "    eeg_dir = base_dir / \"derivatives\" / \"eeg\"\n",
    "    if not eeg_dir.exists():\n",
    "        print(f\"‚ùå EEG directory not found: {eeg_dir}\")\n",
    "        return []\n",
    "\n",
    "    subjects = []\n",
    "    for item in eeg_dir.iterdir():\n",
    "        if item.is_dir() and item.name.startswith(\"sub-\"):\n",
    "            events_dir = item / \"bima_DBSOFF\"\n",
    "            if not events_dir.exists():\n",
    "                continue\n",
    "\n",
    "            events_file = events_dir / f\"{item.name}_events_mne_binary-eve.fif\"\n",
    "            event_id_file = events_dir / f\"{item.name}_event_id_binary.json\"\n",
    "\n",
    "            if not (events_file.exists() and event_id_file.exists()):\n",
    "                continue\n",
    "\n",
    "            # Check DiFuMo file\n",
    "            difumo_file = base_dir / \"derivatives\" / \"lcmv\" / f\"{item.name}_bima_full_off\" / \"difumo_time_courses.npy\"\n",
    "            if not difumo_file.exists():\n",
    "                continue\n",
    "\n",
    "            subjects.append(item.name)\n",
    "\n",
    "    # Sort by subject number\n",
    "    subjects.sort(key=lambda x: int(x.split('-')[1]))\n",
    "    return subjects\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"üîé Discovering subjects...\")\n",
    "\n",
    "    subjects = find_all_subjects(BASE_DIR)\n",
    "\n",
    "    if not subjects:\n",
    "        print(\"‚ùå No valid subjects found. Check paths:\")\n",
    "        print(\"   - derivatives/eeg/sub-XX/bima_DBSOFF/sub-XX_*.fif/.json\")\n",
    "        print(\"   - derivatives/lcmv/sub-XX_bima_full_off/difumo_time_courses.npy\")\n",
    "        exit(1)\n",
    "\n",
    "    print(f\"‚úÖ Found {len(subjects)} subjects: {subjects}\")\n",
    "\n",
    "    for subject in subjects:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"üß¨ PROCESSING SUBJECT: {subject}\")\n",
    "        print(f\"{'='*80}\")\n",
    "\n",
    "        extractor = CleanConnectivityToCSV(PROJECT_BASE, subject=subject)\n",
    "        extractor.run()\n",
    "\n",
    "    print(f\"\\nüéâ ALL {len(subjects)} SUBJECTS PROCESSED SUCCESSFULLY!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
