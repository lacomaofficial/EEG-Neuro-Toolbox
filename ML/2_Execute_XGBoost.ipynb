{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38c06f13",
   "metadata": {},
   "source": [
    "## Execute XGBoost Machine Learning Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a1770c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-08 14:55:48 | INFO     | Logging initialized - Log file: /home/jaizor/jaizor/xtra/derivatives/features/clean_professional_results/logs/analysis_log_20260108_145548.log\n",
      "2026-01-08 14:55:48 | INFO     | Connectivity Analyzer initialized\n",
      "2026-01-08 14:55:48 | INFO     | Loading 11 subjects for Theta band\n",
      "2026-01-08 14:55:48 | INFO     | Loaded 1100 samples √ó 2415 features for Theta\n",
      "2026-01-08 14:55:48 | INFO     | Training XGBoost model for Theta band\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Using 70 targeted ROIs for analysis.\n",
      "======================================================================\n",
      "Professional XGBoost Connectivity Analysis Pipeline\n",
      "======================================================================\n",
      "\n",
      "==================================================\n",
      "Analyzing Theta band\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-08 14:55:48 | INFO     | Training with CUDA\n",
      "2026-01-08 14:56:25 | INFO     | Computing feature stability for Theta (100 runs)\n",
      "2026-01-08 15:06:43 | INFO     | Stability analysis complete - Top feature: CAU-VA-lh ‚Üî pGP-lh\n",
      "2026-01-08 15:06:43 | INFO     | Theta Results:\n",
      "2026-01-08 15:06:43 | INFO     |   Accuracy: 0.927\n",
      "2026-01-08 15:06:43 | INFO     |   Precision: 0.935\n",
      "2026-01-08 15:06:43 | INFO     |   Recall: 0.918\n",
      "2026-01-08 15:06:43 | INFO     |   F1: 0.927\n",
      "2026-01-08 15:06:43 | INFO     |   Auc: 0.979\n",
      "2026-01-08 15:06:43 | INFO     |   CV Score: 0.905 ¬± 0.019\n",
      "2026-01-08 15:06:44 | INFO     | Plots and tables saved for Theta\n",
      "2026-01-08 15:06:44 | INFO     | Loading 11 subjects for Alpha band\n",
      "2026-01-08 15:06:44 | INFO     | Loaded 1100 samples √ó 2415 features for Alpha\n",
      "2026-01-08 15:06:44 | INFO     | Training XGBoost model for Alpha band\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Analyzing Alpha band\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-08 15:06:44 | INFO     | Training with CUDA\n",
      "2026-01-08 15:07:21 | INFO     | Computing feature stability for Alpha (100 runs)\n",
      "2026-01-08 15:17:58 | INFO     | Stability analysis complete - Top feature: L_IFJa_ROI ‚Üî R_6r_ROI\n",
      "2026-01-08 15:17:58 | INFO     | Alpha Results:\n",
      "2026-01-08 15:17:58 | INFO     |   Accuracy: 0.886\n",
      "2026-01-08 15:17:58 | INFO     |   Precision: 0.905\n",
      "2026-01-08 15:17:58 | INFO     |   Recall: 0.864\n",
      "2026-01-08 15:17:58 | INFO     |   F1: 0.884\n",
      "2026-01-08 15:17:58 | INFO     |   Auc: 0.964\n",
      "2026-01-08 15:17:58 | INFO     |   CV Score: 0.906 ¬± 0.024\n",
      "2026-01-08 15:17:59 | INFO     | Plots and tables saved for Alpha\n",
      "2026-01-08 15:17:59 | INFO     | Loading 11 subjects for Low_Beta band\n",
      "2026-01-08 15:17:59 | INFO     | Loaded 1100 samples √ó 2415 features for Low_Beta\n",
      "2026-01-08 15:17:59 | INFO     | Training XGBoost model for Low_Beta band\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Analyzing Low_Beta band\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-08 15:17:59 | INFO     | Training with CUDA\n",
      "2026-01-08 15:18:36 | INFO     | Computing feature stability for Low_Beta (100 runs)\n",
      "2026-01-08 15:29:19 | INFO     | Stability analysis complete - Top feature: L_9-46d_ROI ‚Üî L_i6-8_ROI\n",
      "2026-01-08 15:29:19 | INFO     | Low_Beta Results:\n",
      "2026-01-08 15:29:19 | INFO     |   Accuracy: 0.882\n",
      "2026-01-08 15:29:19 | INFO     |   Precision: 0.868\n",
      "2026-01-08 15:29:19 | INFO     |   Recall: 0.900\n",
      "2026-01-08 15:29:19 | INFO     |   F1: 0.884\n",
      "2026-01-08 15:29:19 | INFO     |   Auc: 0.969\n",
      "2026-01-08 15:29:19 | INFO     |   CV Score: 0.907 ¬± 0.024\n",
      "2026-01-08 15:29:20 | INFO     | Plots and tables saved for Low_Beta\n",
      "2026-01-08 15:29:20 | INFO     | Loading 11 subjects for High_Beta band\n",
      "2026-01-08 15:29:20 | INFO     | Loaded 1100 samples √ó 2415 features for High_Beta\n",
      "2026-01-08 15:29:20 | INFO     | Training XGBoost model for High_Beta band\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Analyzing High_Beta band\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-08 15:29:20 | INFO     | Training with CUDA\n",
      "2026-01-08 15:29:59 | INFO     | Computing feature stability for High_Beta (100 runs)\n",
      "2026-01-08 15:40:41 | INFO     | Stability analysis complete - Top feature: CAU-DA-lh ‚Üî CAU-DA-rh\n",
      "2026-01-08 15:40:41 | INFO     | High_Beta Results:\n",
      "2026-01-08 15:40:41 | INFO     |   Accuracy: 0.895\n",
      "2026-01-08 15:40:41 | INFO     |   Precision: 0.922\n",
      "2026-01-08 15:40:41 | INFO     |   Recall: 0.864\n",
      "2026-01-08 15:40:41 | INFO     |   F1: 0.892\n",
      "2026-01-08 15:40:41 | INFO     |   Auc: 0.973\n",
      "2026-01-08 15:40:41 | INFO     |   CV Score: 0.899 ¬± 0.032\n",
      "2026-01-08 15:40:41 | INFO     | Plots and tables saved for High_Beta\n",
      "2026-01-08 15:40:41 | INFO     | Loading 11 subjects for Low_Gamma band\n",
      "2026-01-08 15:40:42 | INFO     | Loaded 1100 samples √ó 2415 features for Low_Gamma\n",
      "2026-01-08 15:40:42 | INFO     | Training XGBoost model for Low_Gamma band\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Analyzing Low_Gamma band\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-08 15:40:42 | INFO     | Training with CUDA\n",
      "2026-01-08 15:41:21 | INFO     | Computing feature stability for Low_Gamma (100 runs)\n",
      "2026-01-08 15:52:08 | INFO     | Stability analysis complete - Top feature: L_1_ROI ‚Üî NAc-shell-rh\n",
      "2026-01-08 15:52:08 | INFO     | Low_Gamma Results:\n",
      "2026-01-08 15:52:08 | INFO     |   Accuracy: 0.905\n",
      "2026-01-08 15:52:08 | INFO     |   Precision: 0.901\n",
      "2026-01-08 15:52:08 | INFO     |   Recall: 0.909\n",
      "2026-01-08 15:52:08 | INFO     |   F1: 0.905\n",
      "2026-01-08 15:52:08 | INFO     |   Auc: 0.965\n",
      "2026-01-08 15:52:08 | INFO     |   CV Score: 0.903 ¬± 0.028\n",
      "2026-01-08 15:52:09 | INFO     | Plots and tables saved for Low_Gamma\n",
      "2026-01-08 15:52:09 | INFO     | Loading 11 subjects for High_Gamma band\n",
      "2026-01-08 15:52:09 | INFO     | Loaded 1100 samples √ó 2415 features for High_Gamma\n",
      "2026-01-08 15:52:09 | INFO     | Training XGBoost model for High_Gamma band\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Analyzing High_Gamma band\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-08 15:52:10 | INFO     | Training with CUDA\n",
      "2026-01-08 15:52:49 | INFO     | Computing feature stability for High_Gamma (100 runs)\n",
      "2026-01-08 15:58:48 | INFO     | Stability analysis complete - Top feature: R_4_ROI ‚Üî R_6d_ROI\n",
      "2026-01-08 15:58:48 | INFO     | High_Gamma Results:\n",
      "2026-01-08 15:58:48 | INFO     |   Accuracy: 0.886\n",
      "2026-01-08 15:58:48 | INFO     |   Precision: 0.929\n",
      "2026-01-08 15:58:48 | INFO     |   Recall: 0.836\n",
      "2026-01-08 15:58:48 | INFO     |   F1: 0.880\n",
      "2026-01-08 15:58:48 | INFO     |   Auc: 0.949\n",
      "2026-01-08 15:58:48 | INFO     |   CV Score: 0.899 ¬± 0.031\n",
      "2026-01-08 15:58:49 | INFO     | Plots and tables saved for High_Gamma\n",
      "2026-01-08 15:58:50 | INFO     | Comparison figure created\n",
      "2026-01-08 15:58:50 | INFO     | Comprehensive report saved: /home/jaizor/jaizor/xtra/derivatives/features/clean_professional_results/COMPREHENSIVE_ANALYSIS_REPORT.md\n",
      "2026-01-08 15:58:50 | INFO     | Paper exports complete - 1 files created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéâ ANALYSIS COMPLETE! Results in: /home/jaizor/jaizor/xtra/derivatives/features/clean_professional_results\n"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "# Core ML libraries\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix\n",
    ")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ LOAD SELECTED ROIs (MOTOR/BASAL/EXECUTIVE) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "ROI_FILE = Path(\"/atlas_gt/roi_labels_enhanced.csv\")\n",
    "roi_df = pd.read_csv(ROI_FILE)\n",
    "\n",
    "# Reconstruct TARGET_ROIS exactly as in bootstrap script\n",
    "motor_rois = roi_df[\n",
    "    (roi_df['functional_system'] == 'Motor') |\n",
    "    (roi_df['sub_system'].isin(['Primary', 'Premotor', 'Supplementary', 'Eye']))\n",
    "]['roi_name'].tolist()\n",
    "\n",
    "basal_rois = roi_df[\n",
    "    (roi_df['functional_system'] == 'BasalGanglia') |\n",
    "    (roi_df['region_full_name'].str.contains(r'Putamen|Caudate|Globus Pallidus|Nucleus Accumbens', case=False, na=False))\n",
    "]['roi_name'].tolist()\n",
    "\n",
    "executive_rois = roi_df[\n",
    "    (roi_df['functional_system'] == 'Frontoparietal') &\n",
    "    (roi_df['sub_system'].isin(['DLPFC', 'IFJ', 'IFS', 'VLPFC']))\n",
    "]['roi_name'].tolist()\n",
    "\n",
    "TARGET_ROIS = sorted(set(motor_rois + basal_rois + executive_rois))\n",
    "N_ROIS = len(TARGET_ROIS)\n",
    "ROI_NAMES = TARGET_ROIS\n",
    "\n",
    "print(f\"‚úÖ Using {N_ROIS} targeted ROIs for analysis.\")\n",
    "\n",
    "class ConnectivityAnalyzer:\n",
    "    \"\"\"Clean XGBoost connectivity analyzer with direct .npy loading.\"\"\"\n",
    "    \n",
    "    def __init__(self, output_dir=\"results\", random_state=42):\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.figures_dir = self.output_dir / \"figures\"\n",
    "        self.tables_dir = self.output_dir / \"tables\"\n",
    "        self.logs_dir = self.output_dir / \"logs\"\n",
    "        self.random_state = random_state\n",
    "        \n",
    "        for directory in [self.output_dir, self.figures_dir, self.tables_dir, self.logs_dir]:\n",
    "            directory.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        self._setup_logging()\n",
    "        self.band_results = {}\n",
    "        self.stability_results = {}\n",
    "        self.log(\"Connectivity Analyzer initialized\")\n",
    "    \n",
    "    def _setup_logging(self):\n",
    "        log_file = self.logs_dir / f\"analysis_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log\"\n",
    "        formatter = logging.Formatter('%(asctime)s | %(levelname)-8s | %(message)s', datefmt='%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "        self.logger = logging.getLogger('ConnectivityAnalyzer')\n",
    "        self.logger.setLevel(logging.INFO)\n",
    "        \n",
    "        file_handler = logging.FileHandler(log_file)\n",
    "        file_handler.setFormatter(formatter)\n",
    "        self.logger.addHandler(file_handler)\n",
    "        \n",
    "        console_handler = logging.StreamHandler()\n",
    "        console_handler.setFormatter(formatter)\n",
    "        self.logger.addHandler(console_handler)\n",
    "        \n",
    "        self.logger.info(f\"Logging initialized - Log file: {log_file}\")\n",
    "    \n",
    "    def log(self, message, level='info'):\n",
    "        getattr(self.logger, level)(message)\n",
    "    \n",
    "    def vectorize_upper_triangle(self, matrix):\n",
    "        \"\"\"Convert symmetric matrix to 1D upper triangle vector.\"\"\"\n",
    "        if matrix.shape != (N_ROIS, N_ROIS):\n",
    "            raise ValueError(f\"Expected ({N_ROIS}, {N_ROIS}) matrix, got {matrix.shape}\")\n",
    "        iu = np.triu_indices(N_ROIS, k=1)\n",
    "        return matrix[iu]\n",
    "    \n",
    "    def load_group_connectivity_data_from_npy(self, features_base_dir, band_name):\n",
    "        \"\"\"\n",
    "        Load all subjects' full + bootstrap matrices and create ML dataset.\n",
    "        Returns X, y, feature_names, metadata\n",
    "        \"\"\"\n",
    "        subject_dirs = [d for d in Path(features_base_dir).iterdir() if d.is_dir() and d.name.startswith('Sbj')]\n",
    "        if not subject_dirs:\n",
    "            self.log(f\"No subject directories found in {features_base_dir}\", 'error')\n",
    "            return None, None, None, None\n",
    "        \n",
    "        self.log(f\"Loading {len(subject_dirs)} subjects for {band_name} band\")\n",
    "        all_features = []\n",
    "        all_labels = []\n",
    "        all_metadata = []\n",
    "        feature_names = None\n",
    "        \n",
    "        for subj_dir in sorted(subject_dirs):\n",
    "            for condition, label in [('inphase', 0), ('outphase', 1)]:\n",
    "                # Load full matrix\n",
    "                full_path = subj_dir / f\"full_{condition}_{band_name}.npy\"\n",
    "                if full_path.exists():\n",
    "                    try:\n",
    "                        mat = np.load(full_path)\n",
    "                        feat = self.vectorize_upper_triangle(mat)\n",
    "                        if feature_names is None:\n",
    "                            iu = np.triu_indices(N_ROIS, k=1)\n",
    "                            feature_names = [f\"{ROI_NAMES[i]} ‚Üî {ROI_NAMES[j]}\" for i, j in zip(iu[0], iu[1])]\n",
    "                        all_features.append(feat)\n",
    "                        all_labels.append(label)\n",
    "                        all_metadata.append({'subject': subj_dir.name, 'type': 'full'})\n",
    "                    except Exception as e:\n",
    "                        self.log(f\"Failed to load {full_path}: {e}\", 'warning')\n",
    "                \n",
    "                # Load bootstrap matrices\n",
    "                boot_path = subj_dir / f\"bootstrap_{condition}_{band_name}.npy\"\n",
    "                if boot_path.exists():\n",
    "                    try:\n",
    "                        boot_tensor = np.load(boot_path)\n",
    "                        if boot_tensor.ndim != 3:\n",
    "                            self.log(f\"Invalid bootstrap shape in {boot_path}: {boot_tensor.shape}\", 'warning')\n",
    "                            continue\n",
    "                        for boot_idx in range(boot_tensor.shape[0]):\n",
    "                            feat = self.vectorize_upper_triangle(boot_tensor[boot_idx])\n",
    "                            if feature_names is None:\n",
    "                                iu = np.triu_indices(N_ROIS, k=1)\n",
    "                                feature_names = [f\"{ROI_NAMES[i]} ‚Üî {ROI_NAMES[j]}\" for i, j in zip(iu[0], iu[1])]\n",
    "                            all_features.append(feat)\n",
    "                            all_labels.append(label)\n",
    "                            all_metadata.append({\n",
    "                                'subject': subj_dir.name,\n",
    "                                'type': 'bootstrap',\n",
    "                                'bootstrap_id': boot_idx\n",
    "                            })\n",
    "                    except Exception as e:\n",
    "                        self.log(f\"Failed to load {boot_path}: {e}\", 'warning')\n",
    "        \n",
    "        if not all_features:\n",
    "            self.log(f\"No valid data loaded for {band_name}\", 'warning')\n",
    "            return None, None, None, None\n",
    "        \n",
    "        X = np.array(all_features)\n",
    "        y = np.array(all_labels)\n",
    "        self.log(f\"Loaded {X.shape[0]} samples √ó {X.shape[1]} features for {band_name}\")\n",
    "        return X, y, feature_names, all_metadata\n",
    "    \n",
    "    def _check_gpu(self):\n",
    "        try:\n",
    "            import subprocess\n",
    "            result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)\n",
    "            return result.returncode == 0\n",
    "        except:\n",
    "            return False\n",
    "    \n",
    "    def compute_feature_stability(self, X, y, feature_names, band_name, n_runs=100, top_k=15):\n",
    "        self.log(f\"Computing feature stability for {band_name} ({n_runs} runs)\")\n",
    "        le = LabelEncoder()\n",
    "        y_encoded = le.fit_transform(y)\n",
    "        \n",
    "        feature_counts = {name: 0 for name in feature_names}\n",
    "        all_importances = []\n",
    "        \n",
    "        for i in range(n_runs):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y_encoded, test_size=0.2, stratify=y_encoded,\n",
    "                random_state=self.random_state + i\n",
    "            )\n",
    "            \n",
    "            clf = XGBClassifier(\n",
    "                objective='binary:logistic',\n",
    "                eval_metric='logloss',\n",
    "                n_estimators=100,\n",
    "                max_depth=5,\n",
    "                learning_rate=0.1,\n",
    "                random_state=self.random_state + i,\n",
    "                n_jobs=1,\n",
    "                tree_method='hist',\n",
    "                device='cuda' if self._check_gpu() else 'cpu',\n",
    "                verbosity=0\n",
    "            )\n",
    "            \n",
    "            clf.fit(X_train, y_train)\n",
    "            \n",
    "            importance_df = pd.DataFrame({\n",
    "                'feature': feature_names,\n",
    "                'importance': clf.feature_importances_,\n",
    "                'run': i\n",
    "            }).sort_values('importance', ascending=False).head(top_k)\n",
    "            \n",
    "            all_importances.append(importance_df)\n",
    "            for feature in importance_df['feature']:\n",
    "                feature_counts[feature] += 1\n",
    "        \n",
    "        all_importances_df = pd.concat(all_importances, ignore_index=True)\n",
    "        stability_df = pd.DataFrame({\n",
    "            'feature': list(feature_counts.keys()),\n",
    "            'stability_score': [count / n_runs for count in feature_counts.values()],\n",
    "            'selection_frequency': list(feature_counts.values()),\n",
    "            'band': band_name\n",
    "        }).sort_values('stability_score', ascending=False)\n",
    "        \n",
    "        mean_importance = all_importances_df.groupby('feature')['importance'].mean()\n",
    "        stability_df['mean_importance'] = stability_df['feature'].map(mean_importance).fillna(0)\n",
    "        self.log(f\"Stability analysis complete - Top feature: {stability_df.iloc[0]['feature']}\")\n",
    "        return stability_df, all_importances_df\n",
    "    \n",
    "    def train_xgboost_model_from_arrays(self, X, y, feature_names, band_name, plot=True):\n",
    "        self.log(f\"Training XGBoost model for {band_name} band\", 'info')\n",
    "        le = LabelEncoder()\n",
    "        y_encoded = le.fit_transform(y)\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y_encoded, test_size=0.2, stratify=y_encoded,\n",
    "            random_state=self.random_state\n",
    "        )\n",
    "        \n",
    "        gpu_available = self._check_gpu()\n",
    "        device = 'cuda' if gpu_available else 'cpu'\n",
    "        self.log(f\"Training with {device.upper()}\")\n",
    "        \n",
    "        clf = XGBClassifier(\n",
    "            objective='binary:logistic',\n",
    "            eval_metric='logloss',\n",
    "            n_estimators=150,\n",
    "            max_depth=6,\n",
    "            learning_rate=0.1,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            random_state=self.random_state,\n",
    "            n_jobs=-1,\n",
    "            tree_method='hist',\n",
    "            device=device,\n",
    "            verbosity=0\n",
    "        )\n",
    "        \n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        y_proba = clf.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        metrics = {\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'precision': precision_score(y_test, y_pred),\n",
    "            'recall': recall_score(y_test, y_pred),\n",
    "            'f1': f1_score(y_test, y_pred),\n",
    "            'auc': roc_auc_score(y_test, y_proba)\n",
    "        }\n",
    "        \n",
    "        cv_scores = cross_val_score(\n",
    "            clf, X, y_encoded, cv=StratifiedKFold(n_splits=10, shuffle=True, random_state=self.random_state),\n",
    "            scoring='accuracy', n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        importance_df = pd.DataFrame({\n",
    "            'feature': feature_names,\n",
    "            'importance': clf.feature_importances_\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        stability_df, all_importances = self.compute_feature_stability(X, y, feature_names, band_name)\n",
    "        \n",
    "        self.log(f\"{band_name} Results:\")\n",
    "        for metric, value in metrics.items():\n",
    "            self.log(f\"  {metric.title()}: {value:.3f}\")\n",
    "        self.log(f\"  CV Score: {cv_scores.mean():.3f} ¬± {cv_scores.std():.3f}\")\n",
    "        \n",
    "        if plot:\n",
    "            self._plot_band_results(band_name, metrics, importance_df, stability_df, y_test, y_pred, le)\n",
    "        \n",
    "        result = {\n",
    "            'band': band_name,\n",
    "            'model': clf,\n",
    "            'metrics': metrics,\n",
    "            'cv_scores': cv_scores,\n",
    "            'importance': importance_df,\n",
    "            'stability': stability_df,\n",
    "            'all_importances': all_importances,\n",
    "            'label_encoder': le,\n",
    "            'test_data': (X_test, y_test, y_pred)\n",
    "        }\n",
    "        \n",
    "        self.band_results[band_name] = result\n",
    "        self.stability_results[band_name] = stability_df\n",
    "        return result\n",
    "    \n",
    "    def _plot_band_results(self, band_name, metrics, importance_df, stability_df, y_test, y_pred, label_encoder):\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        fig.suptitle(f'{band_name} Band - Analysis Results', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # 1. Confusion Matrix\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                   xticklabels=label_encoder.classes_,\n",
    "                   yticklabels=label_encoder.classes_, ax=axes[0,0])\n",
    "        axes[0,0].set_title('Confusion Matrix')\n",
    "        axes[0,0].set_ylabel('True Label')\n",
    "        axes[0,0].set_xlabel('Predicted Label')\n",
    "        \n",
    "        # 2. Top 10 Feature Importances\n",
    "        top_features = importance_df.head(10)\n",
    "        axes[0,1].barh(range(len(top_features)), top_features['importance'])\n",
    "        axes[0,1].set_yticks(range(len(top_features)))\n",
    "        axes[0,1].set_yticklabels([f[:30] + '...' if len(f) > 30 else f for f in top_features['feature']], fontsize=8)\n",
    "        axes[0,1].set_xlabel('XGBoost Importance')\n",
    "        axes[0,1].set_title('Top 10 Most Important Features')\n",
    "        axes[0,1].invert_yaxis()\n",
    "        \n",
    "        # 3. Feature Stability\n",
    "        stable_features = stability_df.head(10)\n",
    "        bars = axes[1,0].bar(range(len(stable_features)), stable_features['stability_score'])\n",
    "        axes[1,0].set_xlabel('Feature Rank')\n",
    "        axes[1,0].set_ylabel('Stability Score')\n",
    "        axes[1,0].set_title('Top 10 Most Stable Features')\n",
    "        axes[1,0].set_xticks(range(len(stable_features)))\n",
    "        axes[1,0].set_xticklabels([f\"F{i+1}\" for i in range(len(stable_features))])\n",
    "        for bar, score in zip(bars, stable_features['stability_score']):\n",
    "            bar.set_color(plt.cm.viridis(score))\n",
    "        \n",
    "        # 4. Performance Metrics\n",
    "        metric_names = list(metrics.keys())\n",
    "        metric_values = list(metrics.values())\n",
    "        bars = axes[1,1].bar(metric_names, metric_values, color='skyblue', alpha=0.8)\n",
    "        axes[1,1].set_ylabel('Score')\n",
    "        axes[1,1].set_title('Classification Metrics')\n",
    "        axes[1,1].set_ylim(0, 1)\n",
    "        for bar, value in zip(bars, metric_values):\n",
    "            axes[1,1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                          f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.figures_dir / f'{band_name}_analysis.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "        \n",
    "        # Save tables\n",
    "        stability_df.head(20).to_csv(self.tables_dir / f'{band_name}_stability.csv', index=False)\n",
    "        importance_df.head(20).to_csv(self.tables_dir / f'{band_name}_importance.csv', index=False)\n",
    "        self.log(f\"Plots and tables saved for {band_name}\")\n",
    "    \n",
    "    def compare_all_bands(self):\n",
    "        if not self.band_results: return\n",
    "        \n",
    "        summary_data = []\n",
    "        for band, res in self.band_results.items():\n",
    "            summary_data.append({\n",
    "                'Band': band,\n",
    "                'Accuracy': res['metrics']['accuracy'],\n",
    "                'Precision': res['metrics']['precision'],\n",
    "                'Recall': res['metrics']['recall'],\n",
    "                'F1_Score': res['metrics']['f1'],\n",
    "                'AUC': res['metrics']['auc'],\n",
    "                'CV_Mean': res['cv_scores'].mean(),\n",
    "                'CV_Std': res['cv_scores'].std(),\n",
    "                'Top_Feature_Stability': res['stability'].iloc[0]['stability_score']\n",
    "            })\n",
    "        \n",
    "        summary_df = pd.DataFrame(summary_data)\n",
    "        summary_df.to_csv(self.tables_dir / 'band_comparison_summary.csv', index=False)\n",
    "        self._create_comparison_figure(summary_df)\n",
    "        return summary_df\n",
    "    \n",
    "    def _create_comparison_figure(self, summary_df):\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "        fig.suptitle('Frequency Band Comparison', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # Performance metrics\n",
    "        metrics = ['Accuracy', 'Precision', 'Recall', 'F1_Score', 'AUC']\n",
    "        x = np.arange(len(summary_df))\n",
    "        width = 0.15\n",
    "        for i, m in enumerate(metrics):\n",
    "            axes[0,0].bar(x + i*width, summary_df[m], width, label=m, alpha=0.8)\n",
    "        axes[0,0].set_xticks(x + width*2)\n",
    "        axes[0,0].set_xticklabels(summary_df['Band'], rotation=45)\n",
    "        axes[0,0].legend(); axes[0,0].set_ylim(0.5, 1.0)\n",
    "        axes[0,0].set_title('Classification Performance')\n",
    "        \n",
    "        # CV stability\n",
    "        axes[0,1].errorbar(range(len(summary_df)), summary_df['CV_Mean'], yerr=summary_df['CV_Std'], marker='o')\n",
    "        axes[0,1].set_xticks(range(len(summary_df)))\n",
    "        axes[0,1].set_xticklabels(summary_df['Band'], rotation=45)\n",
    "        axes[0,1].set_title('Cross-Validation Stability')\n",
    "        axes[0,1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Feature stability\n",
    "        axes[1,0].bar(summary_df['Band'], summary_df['Top_Feature_Stability'], color='coral', alpha=0.7)\n",
    "        axes[1,0].set_xticklabels(summary_df['Band'], rotation=45)\n",
    "        axes[1,0].set_title('Most Stable Feature per Band')\n",
    "        \n",
    "        # Summary text\n",
    "        axes[1,1].axis('off')\n",
    "        best_band = summary_df.loc[summary_df['Accuracy'].idxmax(), 'Band']\n",
    "        text = f\"ANALYSIS SUMMARY\\n\\nBest Band: {best_band}\\nAccuracy: {summary_df['Accuracy'].max():.3f}\"\n",
    "        axes[1,1].text(0.1, 0.9, text, transform=axes[1,1].transAxes, fontsize=12,\n",
    "                      bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightblue\", alpha=0.8))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.figures_dir / 'band_comparison.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "        self.log(\"Comparison figure created\")\n",
    "    \n",
    "    def generate_comprehensive_report(self):\n",
    "        report = f\"# Professional XGBoost Connectivity Analysis Report\\nGenerated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\"\n",
    "        if self.band_results:\n",
    "            for band, res in self.band_results.items():\n",
    "                report += f\"### {band} Band\\nAccuracy: {res['metrics']['accuracy']:.4f}\\n\\n\"\n",
    "        report_path = self.output_dir / 'COMPREHENSIVE_ANALYSIS_REPORT.md'\n",
    "        with open(report_path, 'w') as f:\n",
    "            f.write(report)\n",
    "        self.log(f\"Comprehensive report saved: {report_path}\")\n",
    "        return report_path\n",
    "\n",
    "\n",
    "def export_for_paper(analyzer, output_dir=None):\n",
    "    paper_dir = Path(output_dir or analyzer.output_dir / \"paper_exports\")\n",
    "    paper_dir.mkdir(exist_ok=True)\n",
    "    if analyzer.band_results:\n",
    "        summary = pd.DataFrame([{\n",
    "            'Band': b,\n",
    "            'Accuracy': f\"{r['metrics']['accuracy']:.3f}\"\n",
    "        } for b, r in analyzer.band_results.items()])\n",
    "        summary.to_csv(paper_dir / 'performance_summary.csv', index=False)\n",
    "    analyzer.log(f\"Paper exports complete - {len(list(paper_dir.glob('*')))} files created\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"=\"*70)\n",
    "    print(\"Professional XGBoost Connectivity Analysis Pipeline\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # ‚ö†Ô∏è Updated: now loads from ml_features (bootstrap outputs)\n",
    "    FEATURES_BASE = '/home/jaizor/jaizor/xtra/derivatives/ml_features'\n",
    "    OUTPUT_DIR = '/home/jaizor/jaizor/xtra/derivatives/features/clean_professional_results'\n",
    "    \n",
    "    bands = [\"Theta\", \"Alpha\", \"Low_Beta\", \"High_Beta\", \"Low_Gamma\", \"High_Gamma\"]\n",
    "    \n",
    "    analyzer = ConnectivityAnalyzer(output_dir=OUTPUT_DIR, random_state=42)\n",
    "    \n",
    "    for band in bands:\n",
    "        print(f\"\\n{'='*50}\\nAnalyzing {band} band\\n{'='*50}\")\n",
    "        X, y, feature_names, metadata = analyzer.load_group_connectivity_data_from_npy(FEATURES_BASE, band)\n",
    "        if X is None: continue\n",
    "        \n",
    "        result = analyzer.train_xgboost_model_from_arrays(X, y, feature_names, band, plot=True)\n",
    "        # ‚ùå Brain plotting removed (no coordinates)\n",
    "    \n",
    "    if analyzer.band_results:\n",
    "        analyzer.compare_all_bands()\n",
    "        analyzer.generate_comprehensive_report()\n",
    "        export_for_paper(analyzer)\n",
    "        print(f\"\\nüéâ ANALYSIS COMPLETE! Results in: {OUTPUT_DIR}\")\n",
    "    else:\n",
    "        print(\"‚ùå No valid data found for any band\")\n",
    "    \n",
    "    return analyzer\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    analyzer = main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Xtra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
